{"meta":{"title":"지혁's Blog","subtitle":"공부한거 기록하는 블로그","description":"","author":"Jihyuk Jung","url":"http://jungjihyuk.github.io","root":"/"},"pages":[{"title":"projects","date":"2020-02-23T07:16:00.000Z","updated":"2020-02-23T07:16:00.620Z","comments":true,"path":"projects/index.html","permalink":"http://jungjihyuk.github.io/projects/index.html","excerpt":"","text":""}],"posts":[{"title":"Helper Function for Clean code (Python)","slug":"python-skills","date":"2020-02-03T15:00:00.000Z","updated":"2020-02-24T15:43:11.708Z","comments":true,"path":"2020/02/04/python-skills/","link":"","permalink":"http://jungjihyuk.github.io/2020/02/04/python-skills/","excerpt":"파이썬 코딩의 기술 책 Better way 4 정리","text":"Python 코드의 가독성을 높여보자 #상황 1. URL에서 쿼리 문자열을 디코드해야 할 때 URL에서 인코딩, 디코딩의 의미는 보안에서의 의미와 살짝 다르다. 인코딩 http://www.google.com/떡볶이 먹고싶다!! =&gt; http://www.google.com/search?sxsrf=ACYBGNTgapWszfC06soR1IlVyLsC2w_7EQ% 3A1580777854450&amp;source=hp&amp;ei=fsE4Xri1GdWRr7wPvM2UOA&amp;q=떡볶이+먹고싶다!! 주소에 한글/공백/특수기호가 들어가면 안되기 때문에 가능하도록 변환하는 작업 디코딩은 그 반대 Boolean 표현식123456789101112from urllib.parse import parse_qsmy_values = parse_qs('red=5&amp;blue=0&amp;green=',keep_blank_values=True)# 값 전체 (dictionary로 저장)print(my_values): &#123;'red': ['5'], 'green':[''],'blue':['0']&#125;# 각각의 값을 뽑을 때red = my_values.get('red',[''])[0] or 0green = my_values.get('green',[''])[0] or 0opacity = my_values.get('opacity',[''])[0] or 0 평가 =&gt; 이 표현식은 읽기도 불편하고 필요한 작업을 수행하지도 못하는 좋지 못한 코딩 Boolean 표현식 변형12345678red = my_values.get('red',[''])[0] or 0green = my_values.get('green',[''])[0] or 0opacity = my_values.get('opacity',[''])[0] or 0 ∥ ∨red = int(my_values.get('red',[''])[0] or 0)green = int(my_values.get('green',[''])[0] or 0)opacity = int(my_values.get('opacity',[''])[0] or 0) if/else 조건식(삼항 표현식)123456789101112from urllib.parse import parse_qsmy_values = parse_qs('red=5&amp;blue=0&amp;green=',keep_blank_values=True)red = my_values.get('red',[''])red = int(red[0]) if red[0] else 0green = my_values.get('green',[''])green = int(green[0]) if green[0] else 0opacity = my_values.get('opacity',[''])opacity = int(opacity[0]) if opacity[0] else 0 평가 =&gt; 삼항 표현식은 코드를 짧게 유지하면서도 명확하게 표현 할 수 있는 장점이 있지만 복잡한 로직일 경우 남발하면 안된다. 여러줄에 걸친 if/else 문1234567891011121314151617green = my_values.get('green',[''])if green[0]: green = int(green[0])else: green = 0red = my_values.get('red',[''])if red[0]: red = int(red[0])else: red = 0opacity = my_values.get('opacity',[''])if opacity[0]: opacity = int(opacity[0])else: opacity = 0 평가 =&gt; 직관적이고 이해하기 편하나 코드의 길이가 길어 속도가 느려질 수 있다. 그리고 오히려 복잡한 수학 문제 같은 경우 코드가 길면 이해하기 더 힘들 수 있다. Helper Function1234567891011 def get_first_int(values, key, default=0): found = values.get(key, ['']) if found[0]: found = int(found[0]) else: found = default return foundgreen = get_first_int(my_values, 'green')red = get_first_int(my_values, 'red')opacity = get_first_int(my_values, 'opacity') 평가 =&gt; 복잡한 표현식보다 호출 코드가 훨씬 명확해진다. 하지만 아주 간단한 문제인데도 불구하고 너무 헬퍼 함수를 쓰는 것도 그리 좋지 않다. 최종 평가 123456상황에 잘 맞게 적절하게 코드를 짜야 한다!그리고표현식이 복잡해지기 시작하면 최대한 빨리 해당 표현식을 작은 조각으로 분할하고로직을 헬퍼 함수로 옮기는 방안을 고려해야 한다.무조건 짧은 코드를 만들기보다는 가독성을 선택하는 편이 나을때가 많다.","categories":[{"name":"Language","slug":"Language","permalink":"http://jungjihyuk.github.io/categories/Language/"},{"name":"Python","slug":"Language/Python","permalink":"http://jungjihyuk.github.io/categories/Language/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jungjihyuk.github.io/tags/python/"},{"name":"clean code","slug":"clean-code","permalink":"http://jungjihyuk.github.io/tags/clean-code/"},{"name":"helper function","slug":"helper-function","permalink":"http://jungjihyuk.github.io/tags/helper-function/"}]},{"title":"Yield와 send 함수를 알아보자 (Python)","slug":"python-yield-send","date":"2020-02-02T15:00:00.000Z","updated":"2020-02-24T15:43:21.316Z","comments":true,"path":"2020/02/03/python-yield-send/","link":"","permalink":"http://jungjihyuk.github.io/2020/02/03/python-yield-send/","excerpt":"generator yield와 send함수","text":"Generator의 yield와 send에 대해 알아보자! Generator, Yield, Send가 도대체 뭐야? 우선 Generator는 generator(iterator를 반환하기 위한 객체)를 생성해주는 함수! 그럼 iterator는 무엇이냐! iterator는 반복할 수 있는 객체의 요소를 리턴할 때 호출 한 시점에 값을 리턴하며 값을 지우고 그 상태를 유지해준다. 그러면 Yield는 무슨 관계가 있는데? yield는 generator를 만들때 함수 안에 yield를 삽입하면 yield를 만나는 순간 iterator 처럼 행동한다. Generator 작동 순서 Step 1: Generator 메소드 호출 (Generator 객체 생성)Step 2: 생성된 generator를 next함수로 호출Step 3: yield까지 실행Step 4: 첫번째 yield에서 중단(suspend)Step 5: 호출자에게 expression_list 값을 반환(return)Step 6: 중단된 지점에서 모든 상태가 보존(지역 변수들의 현재 연결들, 명령 포인터, 내부 연산 스택, 모든 예외처리)Step 7: 1~5 step 반복 ※ next함수 vs send함수 next함수를 통해 호출되면 return은 None, send함수를 통해 호출되면 return은 메소드로 전달된 값{: .notice} Generator랑 Coroutine과의 관계는? 둘이 같은건가? 우선 컴퓨터 프로그램에서 routine이라는 말을 자주 찾아 볼 수 있는데, 이때의 routine은 “어떤 일을 담당하는 하나의 정리된 일” 이라고 한다.프로그램은 여러가지 routine을 조합하여 만들어지며, main routine과 sub routine으로 나눌 수 있다. main routine은 프로그램의 주요한 부분이고 전체의 개략적인 동작 절차를 표시하도록 만들어진다. sub routine은 사용빈도가 높고 자주 사용하는 부분을 모아 별도로 묶어 놓은 것으로 메인루틴을 보조한다. (메소로 묶음)(서브루틴을 사용하면 함수호출시에만 저장된 메모리로 이동하기 때문에 메모리를 효율적으로 사용할 수 있다)이제 진짜로 알아보려고 했던 Co-routine은 sub-routine과 비슷하다. 자주 쓰는 기능들을 별도의 공간에 모아 두었다는 점에서 서브루틴과 동일하지만, 코루틴은 yield까지 수행하고 상태를 중지한 후메인루틴으로 돌아가 마치 동시에 실행되는 것처럼 작동한다. (co에서 볼 수 있듯 메인루틴과 협력관계임)따라서 코루틴은 메인루틴에 종속적이지 않아 데이터를 주고 받을 수 있다! (이러한 특성때문에 send가 가능한 것임) 결국 Generator로 생성된 generator객체(iterator)는 co-routine과 같은 역할을 한다고 보면된다! Example12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788def double(number): while True: number *= 2 yield numberd = double(3)d.send(None) # 처음에 왜 None을 넣어야 모르겠음 .... ㅠㅠ: 6d.send(1): 12d.send(10): 24def double2(number): while True: number *= 2 number = yield numberd2 = double2(4)d2.send(None): 8d2.send(1): 2d2.send(100): 200def check1(): while True: x = yield yield x == numbernumber = 123c1 = check1()c1.send(None)c1.send(123): Truec1.send(None)c1.send(1234): Falsedef check2(): x = yield yield x == number2number2 = 1234c2 = check2()c2.send(None)c2.send(1234):Truec2.send(1234): StopIterationdef check3(): yield (yield) == number3number3 = 2c3 = check3()c3.send(None)c3.send(123): Falsec3.send(2): StopIterationdef check4(): while True: yield (yield) == number4number4 = 777c4 = check4()c4.send(None)c4.send(123): Falsec4.send(7777) # interger 객체 7777은 return 값이 None이기 때문에 None을 넣었을 때와 같음c4.send(777) : Truefor x in range(4): n = c4.send(777) print(n): None True None True None 출처: co-routine, co-routine2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IT 용어","categories":[{"name":"Language","slug":"Language","permalink":"http://jungjihyuk.github.io/categories/Language/"},{"name":"Python","slug":"Language/Python","permalink":"http://jungjihyuk.github.io/categories/Language/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jungjihyuk.github.io/tags/python/"},{"name":"generator","slug":"generator","permalink":"http://jungjihyuk.github.io/tags/generator/"},{"name":"yield","slug":"yield","permalink":"http://jungjihyuk.github.io/tags/yield/"},{"name":"send","slug":"send","permalink":"http://jungjihyuk.github.io/tags/send/"}]},{"title":"CodeSignal Arcade 문제 풀이2","slug":"codesignal2","date":"2020-01-06T15:00:00.000Z","updated":"2020-02-24T15:42:26.289Z","comments":true,"path":"2020/01/07/codesignal2/","link":"","permalink":"http://jungjihyuk.github.io/2020/01/07/codesignal2/","excerpt":"Python, Database, 문제해결 프로그래밍","text":"Index123451. Intro &#x3D;&gt; 문제해결 프로그래밍, 알고리즘 문제2. DataBase &#x3D;&gt; SQL 문제3. The Core &#x3D;&gt; 아직 안풀어봄4. Python &#x3D;&gt; Python 문법 문제5. Graphs &#x3D;&gt; 아직 안풀어봄 Navigation Intro &nbsp;DataBase &nbsp;The Core &nbsp;Python &nbsp;Graphs &nbsp; Intro # DataBase (MySQL 문법) # The Core # Python Unique Characters 문장에서 사용된 Characters type 문자를 중복없이 순서대로 리스트에 나열하는 함수 Example1234567document = \"Todd told Tom to trot to the timber\"uniqueCharacters(document) = [' ', 'T', 'b', 'd', 'e', 'h', 'i', 'l', 'm', 'o', 'r', 't']' ' &lt; 'T' =&gt; True'T' &lt; 't' =&gt; True# 오름차순 정렬 My Answer1234567# 오름차순일 때def uniqueCharacters(document): return sorted(list(set(document))) # sorted(set(document)) sorted 함수를 쓰면 리스트로 반환# 내림차순일 때def uniqueCharacters(document): return sorted(list(set(document)), reverse=True) Correct Scholarships 예시 설명을 참고 해주세요. Example1234567891011121314151617bestStudents = [3, 5]scholarships = [3, 5, 7]allStudents = [1, 2, 3, 4, 5, 6, 7]correctScholarships(bestStudents, scholarships, allStudents) = TruebestStudents = [3]scholarships = [1, 3, 5]allStudents = [1, 2, 3]correctScholarships(bestStudents, scholarships, allStudents) = FalsebestStudents = [3, 5]scholarships = [3, 5]allStudents = [3, 5]correctScholarships(bestStudents, scholarships, allStudents) = False My Answer123# Hidden test 1개 빼고 전부 통과..def correctScholarships(bestStudents, scholarships, allStudents): return set(bestStudents) | set(scholarships) != set(allStudents) and not ((set(bestStudents) | set(scholarships)) - set(allStudents)) Another Answer12345def correctScholarships(bestStudents, scholarships, allStudents): return len(scholarships) &lt; len(allStudents) and sum([x in allStudents for x in scholarships]) == len(scholarships) and sum([x in scholarships for x in bestStudents])==min(len(bestStudents), len(scholarships))def correctScholarships(bestStudents, scholarships, allStudents): return set(bestStudents) &lt;= set(scholarships) &lt; set(allStudents) Startup Name 스타트업 회사를 차린다고 가정할 때 인기있는 경쟁사의 회사 이름 3개 중 중요한 철자를 골라내는 함수 결국 3개 집합 전체에서 3개 집합의 대칭차집합을 뺀 부분을 골라내는 함수 Example12345companies = [\"coolcompany\", \"nicecompany\", \"legendarycompany\"]startupName(companies) = ['e', 'l']companies = [\"nameone\", \"nametwo\", \"namethree\"] startupName(companies) = ['o', 't'] Another Answer123456def startupName(companies): cmp1 = set(companies[0]) cmp2 = set(companies[1]) cmp3 = set(companies[2]) res = (set(companies[0]) | set(companies[1]) | set(companies[2])) - (set(companies[0])^set(companies[1])^set(companies[2])) return list(sorted(list(res))) Words Recognition 두 단어에서 공통적인 알파벳을 뺀 나머지 부분을 추출하는 함수 Example1234word1 = \"program\"word2 = \"develop\"wordsRecognition(word1, word2) = ['agmr', 'delv'] My Answer12345def wordsRecognition(word1, word2): def getIdentifier(w1, w2): return ''.join(sorted((set(w1) ^ set(w2)) - set(w2))) return [getIdentifier(word1, word2), getIdentifier(word2, word1)] Another Answer1234567891011def wordsRecognition(word1, word2): def getIdentifier(w1, w2): return ''.join(sorted(set(w1) - set(w2))) return [getIdentifier(word1, word2), getIdentifier(word2, word1)]def wordsRecognition(word1, word2): def getIdentifier(w1, w2): return \"\".join(sorted(frozenset(w1)-frozenset(w2))) return [getIdentifier(word1, word2), getIdentifier(word2, word1)] Tip list or set to string =&gt; join{: .notice} Transpose Dictionary Dictionary형태의 데이터 타입의 키, 값이 “설명”, “확장자 명”으로 되어 있는데 이를 “확장자 명”, “설명”으로 구성된 리스트로 바꿔주는 함수 Example123456789scriptByExtension = &#123; \"validate\": \"py\", \"getLimits\": \"md\", \"generateOutputs\": \"json\"&#125;transposeDictionary(scriptByExtension) = [[\"json\",\"generateOutputs\"], [\"md\",\"getLimits\"], [\"py\",\"validate\"]] My Answer12def transposeDictionary(scriptByExtension): return sorted([[y, x] for x, y in scriptByExtension.items()]) Another Answer12def transposeDictionary(scriptByExtension): return sorted(zip(scriptByExtension.values(), scriptByExtension.keys())) Doodled Password 비밀번호 낙서? / queue의 FIFO 특성을 deque로 구현하는 함수. / 인덱스 수 만큼 First out Last in(맨 앞 요소)를 반복한다 설명 잘 못하겠으니 밑에 예시를 참고해 주세요 Example1234567digits = [1, 2, 3, 4, 5]doodledPassword(digits) = [[1, 2, 3, 4, 5], [2, 3, 4, 5, 1], [3, 4, 5, 1, 2], [4, 5, 1, 2, 3], [5, 1, 2, 3, 4]] My Answer1234567from collections import dequedef doodledPassword(digits): n = len(digits) res = [deque(digits) for _ in range(n)] [[res[x].insert(len(res)-1, res[x].popleft()) for y in range(x)] for x in range(1, len(res))] return [list(d) for d in res] Another Answer123456789101112131415161718192021222324from collections import dequedef doodledPassword(digits): n = len(digits) res = [deque(digits) for _ in range(n)] map(lambda i: res[i].rotate(-i), range(n)) return [list(d) for d in res]from collections import dequedef doodledPassword(digits): n = len(digits) res = [deque(digits) for _ in range(n)] deque(map(lambda x,y: x.rotate(y), res, range(n,0,-1)), 0) return [list(d) for d in res]from collections import dequedef doodledPassword(digits): n = len(digits) res = [deque(digits) for _ in range(n)] deque(map(lambda x: x[1].rotate(-x[0]), enumerate(res)), 0) return [list(d) for d in res] Frequency Analysis 암호문으로 변경하는 encrypt 함수. 평문에서 가장 빈도수가 높은 문자로 치환한다. Example123encryptedText = \"$~NmiNmim$/NVeirp@dlzrCCCCfFfQQQ\"frequencyAnalysis(encryptedText) = 'C' My Answer1234567from collections import Counterdef frequencyAnalysis(encryptedText): return Counter(encryptedText).most_common(1)[0][0]def frequencyAnalysis(encryptedText): return list(set(encryptedText))[[encryptedText.count(x) for x in list(set(encryptedText))].index(max([encryptedText.count(x) for x in list(set(encryptedText))]))] Another Answer1234from collections import Counterdef frequencyAnalysis(encryptedText): return sorted(encryptedText, key=encryptedText.count, reverse=True)[0] Cyclic Name 문자열이 주어지면 원하는 길이로 문자열이 순환하는 문자열 반환하는 함수 Example1234name = 'jihyuk'n = 12cyclicName(name, n) = 'jihyukjihyuk' My Answer1234567891011from itertools import cycledef cyclicName(name, n): gen = (x for x in cycle(name)) res = [next(gen) for _ in range(n)] return ''.join(res)def cyclicName(name, n): gen = cycle(name) res = [next(gen) for _ in range(n)] return ''.join(res) cycle 함수로 만든 객체는 generator 이다 Memory Pills 리스트의 요소중 길이가 짝수인 요소 다음부터 3개 요소를 추출하는 함수. 단, 추출된 요소가 3개 미만일 때 부족한 요소는 “”로 채운다. Example1234567pills = [\"Notforgetan\", \"Antimoron\", \"Rememberin\", \"Bestmedicen\", \"Superpillsus\"]=&gt; 11 , 9 , 10 , 11 , 12# 따라서 10뒤부터 11, 12에 해당하는 요소와 \"\"를 반환하면 된다.memoryPills(pills) = [\"Bestmedicen\", \"Superpillsus\", \"\"] Another Answer12345678910111213from itertools import dropwhiledef memoryPills(pills): gen = dropwhile(lambda x: len(x)%2!=0, pills + [\"\"]*3) next(gen) return [next(gen) for _ in range(3)]from itertools import dropwhile, cycle, chaindef memoryPills(pills): gen = chain(dropwhile(lambda x: len(x)%2 &gt; 0,pills),cycle([\"\"])) next(gen) return [next(gen) for _ in range(3)] Float Range 시작, 끝, 간격을 입력값으로 주면(정수, 실수 둘다 가능) 시작부터 끝이전까지 간격을 순회로 하는 리스트를 반환하는 함수 Example1floatRange(-0.9, 0.45, 0.2) = [-0.9, -0.7, -0.5, -0.3, -0.1, 0.1, 0.3] My Answer12345from itertools import takewhile, countdef floatRange(start, stop, step): gen = takewhile(lambda x: x &lt; stop, count(start, step)) return list(gen) Another Answer12345from itertools import islicedef floatRange(start, stop, step): gen =islice(map(lambda x:float(x)/100000.0,list(range(int(start*100000),int(stop*100000),int(step*100000)))),int((stop-start)/step)+1) return list(gen) Rock Paper Scissors N명의 사람이 있다고 했을 때 모든 사람이 모든 사람들과 2번씩 경기를 할 수 있도록 명단을 짜주는 함수 Example123players = [\"trainee\", \"warrior\", \"ninja\"]rockPaperScissors(players) = My Answer1234from itertools import permutationsdef rockPaperScissors(players): return sorted(list(permutations(players, 2)) Kth Permutation n개의 순열 조합 중 n번째 순열을 뽑는 함수 Example1234numbers = [1, 2, 3, 4, 5]k = 4kthPermutation(numbers, k) = [1, 2, 4, 5, 3] My Answer1234from itertools import permutationsdef kthPermutation(numbers, k): return list(permutations(numbers, len(numbers)))[k-1] Another Answer1234from itertools import islice, permutationsdef kthPermutation(numbers, k): return next(islice(permutations(numbers), k - 1, None)) # None대신 k도 가능 Crazyball n개의 리스트에서 k개를 뽑아 조합하는 함수. (combination) Example1234567players = [\"Ninja\", \"Warrior\", \"Trainee\", \"Newbie\"]k = 3crazyball(players, k) = [['Ninja', 'Warrior', 'Trainee'], ['Ninja', 'Warrior', 'Newbie'], ['Ninja', 'Trainee', 'Newbie'], ['Warrior', 'Trainee', 'Newbie']] My Answer1234from itertools import combinationsdef crazyball(players, k): return list(combinations(sorted(players), k)) Twins Score 두 개의 리스트를 입력값으로 받아 같은 인덱스끼리 합하여 하나의 리스트로 반환하는 함수 Example1234b = [22, 13, 45, 32]m = [28, 41, 13, 32]twinsScore(b, m) = [50, 54, 58, 64] My Answer123456import numpy as npdef twinsScore(b, m): return list(np.array(b)+np.array(m))def twinsScoer(b,m): return [x[0]+x[1] for x in list(zip(b,m))] Another Answer12345def twinsScore(b, m): return map(sum, zip(b,m))def twinsScore(b, m): return [u + v for u, v in zip(b, m)] Pressure Gauges 두 개의 리스트를 입력 받으면 각각의 인덱스에 맞게 짝지어 작은 값을 1행 리스트에 큰 값을 2행 리스트에 묶어 반환하는 함수 Example12345morning = [3, 5, 2, 6]evening = [1, 6, 6, 6]pressureGauges(morning, evening) = [[1, 5, 2, 6], [3, 6, 6, 6]] My Answer12345def pressureGauges(morning, evening): return [list(map(min, zip(morning,evening))), list(map(max, zip(morning,evening)))]def pressureGauges(morning, evening): return [[min(x) for x in zip(morning, evening)], [max(x) for x in zip(morning, evening)]] Another Answer12345def pressureGauges(morning, evening): return list(zip(*map(sorted, zip(morning, evening))))def pressureGauges(morning, evening): return [list(map(op, zip(morning, evening))) for op in [min, max]] zip과 *의 조합으로 여러개 리스트를 받을 때 각각의 인덱스에 해당하는 요소끼리 합칠 수 있다. 12345678910111213a = [1,2,3,4]b = [1,2,3,4]c = [[1,2],[3,4],[5,6]]d = [[1,2,10],[3,4,11],[5,6,12]]list(zip(a,b))=&gt; [(1, 1), (2, 2), (3, 3), (4, 4)]list(zip(*c))=&gt; [(1, 3, 5), (2, 4, 6)]list(zip(*d))=&gt; [(1, 3, 5), (2, 4, 6), (10, 11, 12)] Correct Lineup 짝수인 리스트를 입력 받으면 앞에서 부터 두 요소씩 짝을 지어 순서를 뒤 바꾸는 함수 Example123athletes = [1, 2, 3, 4, 5, 6]correctLineup(athletes) = [2, 1, 4, 3, 6, 5] My Answer12def correctLineup(athletes): return [a[b] for a in [[y,x] for x, y in zip(athletes[::2], athletes[1::2])] for b in range(2)] Another Answer1234567891011121314def correctLineup(athletes): return [athletes[i^1] for i in range(len(athletes))]def correctLineup(athletes): return [athletes[i+(-1)**i] for i in range(len(athletes))]def correctLineup(athletes): return [athletes[i+1] if i%2 == 0 else athletes[i-1] for i in range(0,len(athletes)) ]def correctLineup(athletes): return list(sum(zip(athletes[1::2], athletes[0::2]), ()))def correctLineup(athletes): return reduce(lambda x,y: x+y, zip(athletes[1::2], athletes[::2])) Group Dating 입력 받은 두 리스트에서 같은 인덱스의 값이 다를 경우 짝을 지어주는 함수 Example1234567891011121314male = [5, 28, 14, 99, 17]female = [5, 14, 28, 99, 16]groupDating(male, female) = [[28, 14, 17], [14, 28, 16]]male = [1,2,3,4]female = [1,2,3,4]groupDating(male, female) = [[],[]]male = [12]female = [43]groupDating(male, female) = [[12], [43]] My Answer12def groupDating(male, female): return [[],[]] if male==female else list(zip(*[[x[0],x[1]] for x in list(zip(male, female)) if x[0]!=x[1]])) Another Answer12345678def groupDating(male, female): return [[x for x, y in zip(male, female) if x!=y], [y for x, y in zip(male, female) if x!=y]]def groupDating(male, female): return zip(*[[m, f] for (m, f) in zip(male, female) if m != f])def groupDating(male, female): return list(zip(*[x for x in list(zip(male,female)) if x[0]!=x[1]])) Fix Tree 리스트를 입력 받으면 제대로된 트리 모양으로 바꿔주는 함수 Example123456789101112131415tree = [\" * \", \" * \", \"*** \", \" *****\", \" *******\", \"*********\", \" *** \"]fixTree(tree) = [\" * \", \" * \", \" *** \", \" ***** \", \" ******* \", \"*********\", \" *** \"] My Answer12def fixTree(tree): return [\" \"*int((len(x) - len(x.strip()))/2) + x.strip() + \" \"*int((len(x) - len(x.strip()))/2) for x in tree] Another Answer12345678def fixTree(tree): return [x.strip().center(len(x))for x in tree]def fixTree(tree): return list(map(lambda s: s.strip().center(len(s)), tree))def fixTree(tree): return map(lambda x: ' ' * (x.count(' ') / 2) + '*' * x.count('*') + ' ' * (x.count(' ') / 2), tree) center라는 좋은 함수가 있었구만! Pref Sum 리스트를 하나의 수열이라고 했을 때, 즉 점화식 또는 일반항 이라고 보고 이에대한 부분합을 구하는 함수 Example12345a = [1, 2, 3]b = [1, 5, 10, -5]prefSum(a) = [1, 3, 6]prefSum(a) = [1, 6, 16, 11] My Answer1234567# hidden test 1개 통과 못함... 뭘 못 통과한걸까!?def prefSum(a): return [sum([a[x] for x in range(y+1)]) for y in range(len(a))]from functools import reducedef prefSum(a): return [reduce(lambda x,y:x+y,a[:i]) for i in range(1,len(a)+1)] Another Answer123456789101112131415161718from itertools import accumulatedef prefSum(a): return list(accumulate(a))from functools import reducedef prefSum(a): return reduce(lambda x,y:x+[sum([y]+x[-1:])],a,[])from functools import reducedef prefSum(a): return reduce(lambda p, n: p + [p[-1] + n], a, [0])[1:]import numpydef prefSum(a): return numpy.cumsum(a)def prefSum(a): return list(__import__('itertools').accumulate(a)) # 요딴 방법으로도 가능하군! 새로 알게된 것들: numpy의 cumsum , itertools의 accumlate Math Practice 리스트를 입력값으로 받으면 더하고 곱하고를 반복하면서 하나의 값으로 만드는 함수. (자세한건 예시 확인) Example1234567numbers = [1,2,3,4,5,6]mathPractice(numbers) = ((1 + 2)*3 + 4)*5 + 6 = 71numbers2 = [9, 19, 2, 2, 7, 3, 0, 0, 6, 11, 14, 18, 11, 7, 9, 6, 8, 4, 13, 11]mathPractice(numbers2) = 1778151 My Answer123test5에서 통과하지 못함.. 이유는 리스트 인덱스 15번째에서 더해야 하는데 곱해서 중간에 값이 뻥튀기 됨..def mathPractice(numbers): return reduce(lambda x,y: x*y if numbers.index(y)%2==0 else x+y, numbers) Another Answer12345678def mathPractice(numbers): return reduce(lambda x, (i,y): x+y if i%2 else x*y, enumerate(numbers), 1)def mathPractice(numbers): return reduce(lambda z,(x,y):z*x+y, zip(numbers[::2],numbers[1::2]+[0]), 1)def mathPractice(numbers): return functools.reduce(lambda s, a: s+numbers[a] if a%2==1 else s*numbers[a], range(1, len(numbers)), numbers[0]) Fibonacci List 피보나치 수열 응용 함수 Example12345678n = 6fibonacciList(n) = [[], [0], [0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0]] Another Answer123def fibonacciList(n): return [[0] * x for x in reduce(lambda a, b: a+[a[-2]+a[-1]], range(n-2), [0,1])] # [0,1] =&gt; 첫 항을 보여주고 타입을 설정하기 위한 부분 (빈 리스트를 넣어도 똑같이 작동한다) Fibonacci 관련 문제는 여러번 다양한 문제로 연습 해보자 Primes Sum 범위 안의 숫자 중에서 소수만 뽑아 더하는 함수 Example1234a = 10b = 20primesSum(a,b) = 11 + 13 + 17 + 19 = 60 My Answer12def primesSum(a, b): return sum([sum([0 if y == 1 or 0 in [0 if y%x==0 else x for x in range(2, y-1)] else y]) for y in range(a,b+1)]) Another Answer123456789101112def primesSum(a, b): return sum(filter(lambda x: all(x % i for i in range(2, int(x**0.5) + 1)), range(max(2, a), b+1)))import mathdef primesSum(a, b): return sum([n for n in range(a, b+1) if n &gt; 1 and all([n % b for b in range(2, int(math.sqrt(n))+ 1)])])def primesSum(a, b): return sum([x for x in range(max(a,2),b+1) if not 0 in [x%z for z in range(2, int(x**0.5+1))]])def primesSum(a, b): return sum([a for a in range(a, b+1) if not (a &lt; 2 or any(a % x == 0 for x in range(2, int(a ** 0.5) + 1))) ]) Fibonacci Generator 숫자 n을 입력하면 피보나치 수열에서 n번째 항까지 출력하는 함수 Example123n = 7fibonacciGenerator(n) = [0, 1, 1, 2, 3, 5, 8] My Answer123456789def fibonacciGenerator(n): def fib(): last = (0, 1) while True: yield last[0] last = last[0] + last[1], last[0] gen = fib() return [next(gen) for _ in range(n)] Check Password 비밀번호를 몇번째 만에 성공하는지 확인하는 함수 Example1234567891011121314attempts = [\"hello\", \"world\", \"I\", \"like\", \"coding\"]password = \"like\"checkPassword(attempts, password) = 4attempts = [\"hello\", \"world\", \"I\", \"like\", \"coding\"]password = \"qwerty123\"checkPassword(attempts, password) = -1attempts = [\"codesignal\"]password = \"codesignal\"checkPassword(attempts, password) = 1 Another Answer123456789101112131415161718192021222324252627282930313233343536373839def checkPassword(attempts, password): def check(): while True: x = yield yield x == password checker = check() for i, attempt in enumerate(attempts): next(checker) if checker.send(attempt): return i + 1 return -1def checkPassword(attempts, password): def check(): while True: yield (yield) == password checker = check() for i, attempt in enumerate(attempts): next(checker) if checker.send(attempt): return i + 1 return -1def checkPassword(attempts, password): def check(): while True: yield True if attempt==password else False checker = check() for i, attempt in enumerate(attempts): next(checker) if checker.send(attempt): return i + 1 return -1 Super Prize n의 배수 번째 손님의 구매금액을 d로 나누었을 때 나누어 떨어지면 상금을 주는 알고리즘을 갖는 객체를 생성하시오 Example12345678910111213purchases: [41, 51, 91, 72, 71, 30, 28, 35, 55, 62, 65, 45, 100, 54, 83, 69, 66, 43]n: 2d: 5superPrize(purchases, n, d): [6, 8, 12]# 총 18명의 손님중 2n 즉 2, 4, 6, 8, 10, 12, 14, 16, 18번째 손님의 구매금액을 5로 나누었을 때# 나누어 떨어지는 손님에게 상금을 지급한다.purchases[1::2] = [51, 72, 30, 35, 62, 45, 54, 69, 43][x % 5 for x in purchases[1::2]] = [1, 2, 0, 0, 2, 0, 4, 4, 3]3, 4, 6번째가 나누어 떨어지고 인덱스가 절반으로 줄었으니까6, 8, 12번째의 손님이 상금을 차지하게 된다. My Answer12345678910111213141516171819202122class Prizes(object): def __init__(self, purchases, n ,d): self.purchases = purchases self.n = n self.d = d self.i = n - 1 def __iter__(self): return self def __next__(self): while self.i &lt; len(self.purchases): i = self.i self.i += self.n if self.purchases[i] % self.d == 0: return i + 1 else: raise StopIterationdef superPrize(purchases, n, d): return list(Prizes(purchases, n, d)) Another Answer1234567891011121314151617181920212223242526272829303132class Prizes(object): def __init__(self, p, n, d): self.p = p self.n = n self.d = d def __iter__(self): for i, x in enumerate(self.p): if i%self.n == self.n-1 and x%self.d == 0: yield i+1def superPrize(purchases, n, d): return list(Prizes(purchases, n, d))class Prizes(object): def __init__(self,purchases,n,d): self.winners = [(i+1)*n for i,x in enumerate(purchases[n-1::n]) if x%d == 0] def __iter__(self): return iter(self.winners)def superPrize(purchases, n, d): return list(Prizes(purchases, n, d))class Prizes(object): def __new__(_, p, n, d): return [(i+1)*n for i, v in enumerate(p[n-1::n]) if v%d == 0]def superPrize(purchases, n, d): return list(Prizes(purchases, n, d)) Try Functions 하나의 값을 여러가지 함수로 평가한 결과 리스트를 반환하는 함수 Example1234functions = [\"math.sin\", \"math.cos\", \"lambda x: x * 2\", \"lambda x: x ** 2\"]x = 1tryFunctions(x, functions) = [(0.8414709848078965, 0.5403023058681398, 2, 1)] My Answer12def tryFunctions(x, functions): return list(zip(*[map(x, list([1])) for x in func])) *내가 만든 함수의 문제: * 입력값으로 받는 함수리스트가 문자열로 구성되어 있으면 사용할 수 없다. 리스트 안에 있는 문자열을 함수 타입으로 만들고 싶었으나 함수 타입으로 만들어주는 최상위 클래스같은건 없기에 실패..{: .notice} Another Answer12def tryFunctions(x, functions): return [eval(f)(x) for f in functions)] eval 함수 언젠간 요긴하게 쓸거같았는데..! eval을 exec로 착각하는 바람에 결국 답을 봐버렸다.. Simple Composition &amp; Functions Composition 단일 합성함수의 연산 결과를 반환하는 함수 n개 중첩 합성함수의 연산 결과를 반환하는 함수 Example123456789101112# 단일 합성함수f = \"math.log10\", g = \"abs\" , x = -100simpleComposition(f, g, x) = math.log10(abs(-100)) = 2# 중첩 합성함수functions = [\"abs\", \"math.sin\", \"lambda x: 3 * x / 2\"]x = 3.1415functionsComposition(functions, x) = abs(math.sin(3*3.1415/2)) = 1 My Answer123456789101112131415161718# 단일 함성함수def compose(f, g): return lambda x : f(g(x))def simpleComposition(f, g, x): return compose(eval(f), eval(g))(x)def simpleComposition2(f, g, x): return eval(f)(eval(g)(x)) # 중첩 합성함수from functools import reducedef compose(functions): return reduce(lambda f,g : lambda x: f(g(x)), functions)def functionsComposition(functions, x): return compose(map(eval, functions))(x) Another Answer123456# 중첩 합성함수def compose(functions): return functions[0] if len(functions) == 1 else compose([lambda x: functions[0](functions[1](x))] + functions[2:])def functionsComposition(functions, x): return compose(map(eval, functions))(x) Graphs","categories":[{"name":"Language","slug":"Language","permalink":"http://jungjihyuk.github.io/categories/Language/"},{"name":"Python","slug":"Language/Python","permalink":"http://jungjihyuk.github.io/categories/Language/Python/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://jungjihyuk.github.io/tags/algorithm/"},{"name":"코딩연습","slug":"코딩연습","permalink":"http://jungjihyuk.github.io/tags/%EC%BD%94%EB%94%A9%EC%97%B0%EC%8A%B5/"},{"name":"python","slug":"python","permalink":"http://jungjihyuk.github.io/tags/python/"},{"name":"database","slug":"database","permalink":"http://jungjihyuk.github.io/tags/database/"},{"name":"CodeSignal2","slug":"CodeSignal2","permalink":"http://jungjihyuk.github.io/tags/CodeSignal2/"}]},{"title":"Stack, Queue, Deque","slug":"datastructure","date":"2020-01-06T15:00:00.000Z","updated":"2020-02-24T15:13:24.932Z","comments":true,"path":"2020/01/07/datastructure/","link":"","permalink":"http://jungjihyuk.github.io/2020/01/07/datastructure/","excerpt":"스택, 큐, 덱에 대해 알아보자","text":"Stack 스택은 한쪽 끝에서만 원소를 넣거나 뺄 수 있는 자료구조이다. 식후 커피를 제공하는 음식점에 가보면 기다란 원통형으로 된 종이컵 수거통이라고 생각하면 바로 이해가 될 것이다.LIFO(Last In First Out) 구조 Queue 한쪽 끝에서 원소를 넣고 반대쪽 끝에서 원소를 뺄 수 있는 자료구조이다. 티켓팅을 하거나 줄을 설때 일반적으로 먼저온사람이 먼저 작업을 처리하는데 이와 같은 방식이다. FIFO(First In First Out) 구조 Deque 양쪽 끝에서 원소를 넣고 뺄 수 있는 자료구조이다. 스택, 큐, 덱 자료구조 설명 출처 =&gt; &gt; 출처","categories":[{"name":"Data Structure","slug":"Data-Structure","permalink":"http://jungjihyuk.github.io/categories/Data-Structure/"}],"tags":[{"name":"자료구조","slug":"자료구조","permalink":"http://jungjihyuk.github.io/tags/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/"},{"name":"stack","slug":"stack","permalink":"http://jungjihyuk.github.io/tags/stack/"},{"name":"queue","slug":"queue","permalink":"http://jungjihyuk.github.io/tags/queue/"},{"name":"deque","slug":"deque","permalink":"http://jungjihyuk.github.io/tags/deque/"}]},{"title":"Java 문법","slug":"java","date":"2019-11-09T15:00:00.000Z","updated":"2020-02-24T15:41:58.668Z","comments":true,"path":"2019/11/10/java/","link":"","permalink":"http://jungjihyuk.github.io/2019/11/10/java/","excerpt":"Java 헷갈리는 문법, 필요한 문법 공부 정리하기","text":"Main Method (with public, static, void)Calculator class 123456789101112131415161718192021222324252627282930313233public class Calculator &#123; public static int num1 = 1; public int num2 = 2; public static int Calculator(int a, int b) &#123; return a + b; &#125; public int Calculator2(int a, int b) &#123; return a + b; &#125; private static int Calculator3(int a, int b) &#123; return a + b; &#125; public static void Add() &#123; System.out.println(\"This is Add Function\"); &#125; public static void main(String[] args) &#123; int a = 3; int b = 4; int result = Calculator.Calculator(a, b); int result2 = Calculator(10,20); int result3 = Calculator(Integer.parseInt(args[0]),Integer.parseInt(args[1])); System.out.println(\"a + b = \" + result); System.out.println(\"10 + 20 = \" + result2); System.out.println(\"입력 받는 값 합 = \" + result3); &#125;&#125; main_test class 123456789101112131415161718192021222324252627282930313233import test.Calculator;public class main_test &#123; public static void main(String[] args) &#123; Calculator cal = new Calculator(); // 변수 System.out.println(cal.num1); System.out.println(cal.num2); System.out.println(Calculator.num1); //System.out.println(Calculator.num2); //Add Calculator.Add(); //Calculator int result = Calculator.Calculator(11, 11); System.out.println(result); //Calculator2 //int result2 = Calculator.Calculator2(22, 22); //Calculator3 //int result3 = Calculator.Calculator3(33, 33); //Main String[] num = new String [2]; num[0] = \"1000\"; num[1] = \"4\"; Calculator.main(num); &#125;&#125; 1. Java는 어플리케이션이 실행되면 가장 먼저 Main Method가 실행됩니다. (약속이기 때문에 그냥 받아들입시다)2. Public은 말 그대로 공공성을 띄고 있어 어느 곳에서도 접근 할 수 있다는 의미 입니다.3. Static은 정적임을 뜻하는데, 프로그램이 실행될 때 Java메모리에 할당되며, 프로그램이 종료 될 때 해제가 됩니다.(static이 가장 먼저 정의 됩니다)4. void는 쉽게 말해 return값이 없음을 의미합니다. 그저 실행만 한다고 생각하면 됩니다. ClassName name = new ClassName(); 사진 출처: naver blog Array1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class Array_test &#123; public static void main(String[] args) &#123; // int int[] array1 = new int[8]; for (int i=0; i&lt;array1.length; i++) &#123; System.out.print(array1[i]+\" \"); &#125; System.out.println(\"\\n-----------------------\"); //string String[] array2 = new String[] &#123;\"a\",\"b\"&#125;; for (int i = 0; i &lt; array2.length; i++) &#123; System.out.print(array2[i]+\" \"); &#125; System.out.println(\"\\n-----------------------\"); //배열을 생성해 할당하면 배열의 주소가 들어간다 String[] array3 = new String[5]; array3[0] = \"Jung\"; array3[1] = \"jihyuk\"; for (int j = 2; j&lt;array3.length;j++) &#123; array3[j] = Integer.toString(j); &#125; for(int i = 0; i&lt;array3.length; i++) &#123; System.out.print(array3[i] + \" \"); &#125; System.out.println(\"\\n-----------------------\"); //char //char array4[] = new char[]; char array4[] = new char[] &#123;'a','b','c','d','e'&#125;; char[] array5 = new char[] &#123;'a','b','c','d','e'&#125;; for (int n=0; n&lt;array4.length; n++) &#123; System.out.print(array4[n]+\" \"); &#125; System.out.println(\" \"); for (int n=0; n&lt;array5.length; n++) &#123; System.out.print(array5[n]+\" \"); &#125; System.out.println(\" \"); char array6[] = new char[5]; String s1 = \"abcdef\"; char[] array7 = s1.toCharArray(); for (int m = 0; m&lt;array7.length; m++) &#123; System.out.print(array7[m]+\" \"); &#125; String s2 = \"\"; for (int k = 0; k&lt;array7.length; k++) &#123; s2+=Character.toString(array7[k]); &#125; System.out.println(\"\\n\"+s2); char [] array8 = &#123;'a','b','c'&#125;; String s3 = String.valueOf(array8); System.out.println(s3); String s4 = new String(array8,0,3); System.out.println(s4); //byte &#125;&#125;","categories":[{"name":"Language","slug":"Language","permalink":"http://jungjihyuk.github.io/categories/Language/"},{"name":"Java","slug":"Language/Java","permalink":"http://jungjihyuk.github.io/categories/Language/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://jungjihyuk.github.io/tags/Java/"}]},{"title":"밑바닥부터 시작하는 딥러닝","slug":"deeplearning","date":"2019-11-02T15:00:00.000Z","updated":"2020-02-24T15:40:44.553Z","comments":true,"path":"2019/11/03/deeplearning/","link":"","permalink":"http://jungjihyuk.github.io/2019/11/03/deeplearning/","excerpt":"'Deep Learning from Scratch - 밑바닥부터 시작하는 딥러닝 -'책 정리하기","text":"Index1231. Chapter 2 &quot;Perceptron&quot;2. Chapter 3 &quot;신경망&quot;3. Chapter 4 &quot;신경망 학습&quot; Navigation Perceptron &nbsp;신경망 &nbsp;신경망 학습 &nbsp; Chapter 2 “Perceptron” AND Gate Python으로 구현하기12345678910111213141516171819202122232425262728293031# 내가 만든def and1(x1:int, x2:int)-&gt;int: return x1*x2def and3(x1:int, x2:int)-&gt;int: x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 temp = np.sum(x*w) + b return (lambda x:1 if 1/(1 + np.exp(-x)) &gt; 0.5 else 0)(temp)# 책 내용 변형def and2(x1:int, x2:int)-&gt;int: w1, w2, threshold = 0.5, 0.5, 0.7 temp = x1*w1 + x2*w2 if temp &gt; threshold: return 1 else: return 0%%timeitand1(0,0)138 ns ± 11.7 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)%%timeitand2(0,0)413 ns ± 53 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)%%timeitand3(0,1)12.8 µs ± 389 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) OR Gate Python으로 구현하기1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 내가 만든 def or1(x1:int, x2:int)-&gt;int: return (lambda x1, x2: 1 if x1+x2 &gt; 0 else 0)(x1, x2)def or4(x1:int, x2:int)-&gt;int: x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.1 temp = np.sum(w*x) + b return (lambda x: 1 if 1/(1 + np.exp(-x)) &gt; 0.5 else 0)(temp)# 책 내용 변형def or2(x1:int, x2:int)-&gt;int: w1, w2, threshold = 0.5, 0.5, 0.2 temp = x1*w1 + x2*w2 if temp &gt; threshold: return 1 else: return 0import numpy as npdef or3(x1:int, x2:int)-&gt;int: x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.2 temp = np.sum(w*x) + b if temp &gt; 0: return 1 else: return 0%%timeitor1(0,0) 385 ns ± 68.5 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)%%timeitor1(0,1)418 ns ± 43.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)%%timeitor2(0,0)501 ns ± 40 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)%%timeitor2(0,1)379 ns ± 43.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)%%timeitor3(0,0)9.47 µs ± 583 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)%%timeitor3(0,1)9.74 µs ± 588 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)%%timeitor4(0,0)13.9 µs ± 1.57 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each) XOR Gate Python으로 구현하기123456789101112131415161718192021222324252627282930def and1(x1:int, x2:int)-&gt;int: x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 temp = np.sum(x*w) + b return (lambda x:1 if 1/(1 + np.exp(-x)) &gt; 0.5 else 0)(temp)def or1(x1:int, x2:int)-&gt;int: x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.1 temp = np.sum(w*x) + b return (lambda x: 1 if 1/(1 + np.exp(-x)) &gt; 0.5 else 0)(temp)def nand(x1:int, x2:int)-&gt;int: x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) b = 0.7 temp = np.sum(x*w) + b return (lambda x:1 if 1/(1 + np.exp(-x)) &gt; 0.5 else 0)(temp)def xor(x1:int, x2:int)-&gt;int: s1 = nand(x1,x2) s2 = or1(x1,x2) result = and1(s1,s2) return result%%timeitxor(0,1)40.7 µs ± 4.55 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each) Chapter 3 “신경망” 활성화 함수 신호의 총 합을 출력 신호로 변환하는 함수 단층 퍼셉트론에서 사용하는 Step Function1234567891011import numpy as npimport matplotlib.pyplot as pltdef step(x): y = x &gt; 0 return y.astype(np.int)x = np.arange(-10, 10, 1)y = step(x)plt.plot(x, y)plt.show() Sigmoid Function12345678910import numpy as npimport matplotlib.pyplot as pltdef sigmoid(x): return 1 / (1 + np.exp(-x))x = np.arange(-10, 10, 1)y = sigmoid(x)plt.plot(x, y)plt.show() Relu Function12345678910import numpy as npimport matplotlib.pyplot as pltdef relu(x): return np.maximum(0, x)x = np.arange(-10, 10, 1)y = relu(x)plt.plot(x, y)plt.show() Hyperbolic Tangent Function sigmoid보다 output 값의 범위가 넓어 vanishing gradient 문제가 발생할 가능성이 있는 모델에서 사용한다.하지만 여전히 층이 많이 깊어지면 vanishing gradient 문제를 피할 수는 없다. 그림 출처 12345678910111213import numpy as npimport matplotlib.pyplot as pltdef sigmoid(x): return 1 / (1 + np.exp(-x))def tanh(x): return 2*sigmoid(2*x) - 1x = np.arange(-10, 10, 0.1)y = tanh(x)plt.plot(x, y)plt.show() 선형 VS 비선형 중첩의 원리가 적용되면 선형! 적용되지 않으면 비선형! 입력값 각각을 함수에 대입한 결과의 합과12345678910y &#x3D; ax1 + bx2 일때if x1, x2 &#x3D;&gt; 1, 2y1 &#x3D; a + 2bif x1, x2 &#x3D;&gt; 5, 10y2 &#x3D; 5a + 10by &#x3D; y1 + y2 &#x3D; 6a + 12b 입력값의 합을 함수에 대입한 결과가 서로 같다면1234y &#x3D; ax1 + bx2 일때if x1, x2 &#x3D;&gt; (1+5), (2+10)y &#x3D; 6a + 12b 바로! 중첩의 원리가 적용되는 것! 신경망에서는 활성화함수로 비선형 함수를 사용하는 이유는?1234567활성화 함수를 f(x) &#x3D; ax 라고 했을 때Layer가 3개인 다층 신경망을 식으로 나타내면y &#x3D; f(f(f(x)))가 됩니다그런데 이는 y &#x3D; a*a*a*x와 같고 하나의 선형 함수로 표현할 수 있기 때문에층을 아무리 깊게 해도 아무 의미가 없게 됩니다. 행렬 곱연산 VS dot VS matmul **행렬 곱연산(Element wise, 일반적인 행렬 곱셈과 다름)** 12345678910111213141516171819202122232425262728n = np.array([1,2])m = np.array([[[1,2],[3,4]]])n*m: array([[[1, 4], [3, 8]]])m*n: array([list([1, 2, 3, 4, 5]), list([3, 4, 5, 6, 3, 4, 5, 6])], dtype=object)n = np.array([1,2])m = np.array([[1,2,3,4,5],[3,4,5,6]])n*m: array([list([1, 2, 3, 4, 5]), list([3, 4, 5, 6, 3, 4, 5, 6])], dtype=object)m*n: array([list([1, 2, 3, 4, 5]), list([3, 4, 5, 6, 3, 4, 5, 6])], dtype=object)n = np.array([1,2])m = np.array([[[1,2,3],[3,4,5]]])n*m: ValueError: operands could not be broadcast together with shapes (2,) (1,2,3) dot(Element wise의 합, 내적) 123456789101112131415161718192021222324252627282930313233343536373839import numpy as npg = np.array([[1,2],[1,2]])h = np.array([2,3])np.dot(g,h): array([8, 8])i = np.array([[1],[2],[3]])j = np.array([1,2,3]).reshape(1,3)np.dot(i,j): array([[1, 2, 3], [2, 4, 6], [3, 6, 9]])# 3차원부터 matmul과 차이난다A = np.arange(24).reshape(2,3,4)B = np.arange(24).reshape(2,4,3)np.dot(A,B): array([[[[ 42, 48, 54], [ 114, 120, 126]], [[ 114, 136, 158], [ 378, 400, 422]], [[ 186, 224, 262], [ 642, 680, 718]]], [[[ 258, 312, 366], [ 906, 960, 1014]], [[ 330, 400, 470], [1170, 1240, 1310]], [[ 402, 488, 574], [1434, 1520, 1606]]]]) matmul(@, 행렬 곱셈(matrix multiplication)) 1234567891011121314151617181920212223242526272829303132333435363738394041424344g = np.array([[1,2],[1,2]])h = np.array([2,3])np.matmul(g,h): array([8, 8])i = np.array([[1],[2],[3]])j = np.array([1,2,3]).reshape(1,3)np.matmul(i,j): array([[1, 2, 3], [2, 4, 6], [3, 6, 9]])# 3차원부터 dot과 차이가 난다A = np.arange(24).reshape(2,3,4)B = np.arange(24).reshape(2,4,3)np.matmul(A,B): array([[[ 42, 48, 54], [ 114, 136, 158], [ 186, 224, 262]], [[ 906, 960, 1014], [1170, 1240, 1310], [1434, 1520, 1606]]])g @ h: array([8,8])i @ j: array([[1, 2, 3], [2, 4, 6], [3, 6, 9]])A @ B: array([[[ 42, 48, 54], [ 114, 136, 158], [ 186, 224, 262]], [[ 906, 960, 1014], [1170, 1240, 1310], [1434, 1520, 1606]]]) dot과 matmul dot은 내적을, matmul은 행렬의 곱을 의미하는데 3차원, 3차원 연산부터 값이 서로 상의 하게 나온다. 내적의 의미는 서로 다른 두 벡터의 방향성을 알 수 있는 연산값이지만 행렬의 곱의 의미는 무엇일까..? 왜 3차원 부터 다른것일까? 아는 사람은 메일 주세요 ㅠ{: .notice} 내적(inner product) 방향이 있는 서로 다른 두 벡터가 있을 때 한 벡터를 기준으로 같은 방향이 되도록 다른 한 벡터를 정사영시켜 기준 벡터의 크기와 정사영시켜 생긴 벡터의 크기의 곱이다. 즉, 한쪽 방향으로의 크기의 곱! 내적을 구하면 두 벡터의 방향이 얼마나 일치하는지 알 수 있다! 다층 신경망 구현하기(3층 신경망 또는 2층 신경망) version 11234567891011121314151617181920212223242526import numpy as npdef sigmoid(x): return 1 / (1 + np.exp(-x))def identity_function(x): return xX = np.array([1.0, 0.5])W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])B1 = np.array([0.1,0.2,0.3])L1 = np.dot(X, W1) + B1Z1 = sigmoid(L1)W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])B2 = np.array([0.1, 0.2])L2 = np.dot(Z1, W2) + B2Z2 = sigmoid(L2)W3 = np.array([[0.1, 0.3], [0.2, 0.4]])B3 = np.array([0.1, 0.2])A3 = np.dot(Z2, W3) + B3Y = identity_function(A3) version 21234567891011121314151617181920212223242526272829303132333435363738import numpy as npdef sigmoid(x): return 1 / (1 + np.exp(-x))def identity_function(x): return xdef init_network(): network = &#123; &#125; network['W1'] = np.random.random((2, 3)) network['b1'] = np.random.random((1, 3)) network['W2'] = np.random.random((3, 2)) network['b2'] = np.random.random((2)) network['W3'] = np.random.random((2, 2)) network['b3'] = np.random.random((2)) return networkdef forward(network, X): W1, W2, W3 = network['W1'], network['W2'], network['W3'] b1, b2, b3 = network['b1'], network['b2'], network['b3'] L1 = np.dot(X, W1) + b1 # hidden layer z1 = sigmoid(L1) L2 = np.dot(L1, W2) + b2 # hidden layer z2 = sigmoid(L2) L3 = np.dot(L2, W3) + b3 # output layer y = identity_function(L3) return ynetwork = init_network()x = np.array([0.1, 0.5])y = forward(network, x)print(y) 출력층 설계하기 우선 학습의 결과값으로 유한개의 결과가 나오는가 무한개의 결과가 나오는가 판별해야 합니다 유한개의 결과가 나온다면 분류 문제 (몇개로 분류되는지도 생각해봐야 함) 무한개의 결과가 나온다면 회귀 문제 결과값을 달리 해야 하기 때문에 출력층에서 사용하는 활성화 함수도 분류 문제인지, 회귀 문제인지에 따라 달라져야 합니다. 기계학습은 학습과 추론 두 단계를 거친다(backward propagation &amp; forward propagation)1234567891011121314추론 &#x3D;&gt; 지금의 사고방식(가설함수, 모델)로 예측하는 것학습 &#x3D;&gt; 예측한 값과 현실의 답(실제값)의 차이를 줄여나가면서 기존의 사고방식(가설함수의 가중치 및 하이퍼파라미터)을 업데이트문제를 해결할 때사람은 어떤 현상을 보고 패턴을 찾고, 문제에 대한 질문을 생각하고, 답을 찾으며 경험과 직관으로 답을 찾는 반면기계는 어떤 현상을 인식하기 위해 데이터를 입력 받고, 패턴을 찾기 위해 데이터에서 중요한 데이터를 찾는 과정인특징을 추출하고 그 특징의 패턴을 찾아 모델을 만듭니다.그런데 어떠한 데이터를 벡터로 변환해야 할때변환을 위해 사용되는 특징은 여전히 사람이 설계해야 합니다.따라서 문제에 따라서 사람이 적절한 특징을 생각해내야 합니다.&#x3D;&gt; 문제를 해결하려는 도메인의 지식이 중요한 이유! 사람 VS 기계학습 VS 딥러닝 딥러닝은 기계학습의 일종이지만 학습을 하는데 있어서 조금 차이를 보입니다. 12345ex) 숫자 5를 학습하는 법사람 &#x3D;&gt; 경험, 직관, 신념, 사고방식 등... &#x3D;&gt; 숫자 5구나!?기계학습 &#x3D;&gt; 사람이 생각한 특징(전처리 등..) &#x3D;&gt; SVM, KNN 등 알고리즘 사용 &#x3D;&gt; 숫자 5구나!?딥러닝 &#x3D;&gt; 기계가 데이터를 통해 특징 추출까지 직접 함 &#x3D;&gt; 숫자 5구나!? 분류 이중 분류라면 step function이나 sigmoid 다중 분류라면 softmax (step, sigmoid, softmax이외에 다른 함수가 될 수도 있다)ex) 0 ~ 9사이의 숫자중 어느 하나를 분류해야하는 문제가 있다고 한다면 출력층의 노드의 수는 10개가 되고 2개 이상의 분류이기 때문에 softmax같은 활성화 함수를 활용해 10개의 출력을 하되 마지막에는 가장 확률이 높은 값 하나만을 출력하면 된다 **step, sigmoid는 많이 다뤘으므로 softmax를 알아보자** 123456def softmax(x): op = np.max(x) # 오버플로우가 발생 방지 x = x - op exp = [np.exp(i) for i in x] sum_exps = sum(exp) return [j/sum_exps for j in exp] softmax 계산시 오퍼플로우 문제 softmax에 709이상의 입력값을 대입하면 오버플로우 현상이 발생한다. 따라서 오버플로우를 방지하기 위해서 입력값중 가장 큰 값을 뽑아 대입하는 값에 각각을 빼주고 계산하게 되면 각각의 값에 전부 같은 값을 빼주었기 때문에 softmax의 결과는 달라지지 않고 출력됨을 확인할 수 있다. softmax는 발생확률 값을 리턴하기 때문에 출력값의 총 합이 1이되기만 하면 된다.{: .notice} MNIST 데이터 셋으로 추론 처리 구현하기(분류) test data로 이미 학습된 모델(pickle) 정확도 확인하기 (test data의 예측값과 test data의 실제값 비교) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import pickleimport numpy as npimport sys, ossys.path.append(os.pardir) # 부모 디렉터리의 파일을 가져올 수 있도록 설정from dataset.mnist import load_mnistdef sigmoid(x): return 1 / (1 + np.exp(-x))def softmax(x): op = np.max(x) x = x - op exp = [np.exp(i) for i in x] sum_exps = sum(exp) return [j/sum_exps for j in exp]def get_data(): # flatten =&gt; 1차원 or 3차원 / normalize =&gt; 0 ~ 1 사이 정규화 할지 (x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False) return x_test, y_testdef init_network(): with open(\"sample_weight.pkl\", \"rb\") as f: network = pickle.load(f) return networkdef predict(network, x): W1, W2, W3 = network['W1'], network['W2'], network['W3'] b1, b2, b3 = network['b1'], network['b2'], network['b3'] L1 = np.dot(x, W1) + b1 z1 = sigmoid(L1) L2 = np.dot(L1, W2) + b2 z2 = sigmoid(L2) L3 = np.dot(L2, W3) + b3 y = softmax(L3) return yx, y = get_data()network = init_network()accuracy_cnt = 0for i in range(len(x)): t = predict(network, x[i]) p = np.argmax(t) if (p == y[i]): accuracy_cnt += 1print(\"Accuracy: \" + str(float(accuracy_cnt) / len(x))) MNIST 다운로드 회귀배치 (Batch) 하나로 묶은 입력 데이터를 배치(Batch)라고 합니다. MNIST데이터는 숫자 이미지 데이터로 이미지 크기가 28 X 28 =&gt; 784라고 했을 때 1234567이미지 데이터 1장일 때 Input W1 W2 W3 Output형상 1 X 784 784 X 50 50 X 100 100 X 10 1 X 10이미지 데이터 100장일 때 Input W1 W2 W3 Output형상 100 X 784 784 X 50 50 X 100 100 X 10 100 X 10 배치 처리의 장점 1. numpy가 벡터연산을 효율적으로 처리하기 때문에 한번에 많은 데이터를 입력하더라도 빠른 시간에 처리할 수 있다. 2.신경망에서 데이터 전송이 병목으로 작용하는 경우가 자주 있는데, 배치 처리를 함으로써 버스에 주는 부하를 줄일 수 있다.{: .notice} 배치 처리 구현 (위 MNIST 예제와 동일) 123456789101112x, y = get_data()network = init_network()batch_size = 100accuracy_cnt = 0for i in range(0, len(x), batch_size): x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis = 1) # axis = 1하는 이유는? accuracy_cnt += np.sum(p == y[i:i+batch_size])print(\"Accuracy: \" + str(float(accuracy_cnt) / len(x))) Batch VS Mini Batch VS Stochastic Gradient Descent1234Batch는 여러 데이터를 한 묶음으로 하여 1 Iteration에 사용되는 data set의 모음Mini Batch는 전체 데이터에서 특정 Batch Size로 나누어 학습시키는 방법 - Batch보다 빠르고 SGD보다는 낮은 오차율을 갖는다Stochastic Gradient Descent는 데이터를 한 개씩 뽑아서 처리하고 모든 데이터에 반복하는 방법이다. Chapter 4 “신경망 학습” ## 학습하기 Lose Function(Cost Function) 신경망 학습에서는 현재 상태를 하나의 지표로 표현하고 그 지표를 가장 좋게 만들어주는 가중치 매개 변수의 값을 탐색해나갑니다. 이때 현재 상태와 다음 상태를 비교하여 최적의 상태를 만들기 위한 수단으로 손실 함수를 사용하게 됩니다. Mean Squared Error(평균 제곱 오차)12def mse(y, t): return 0.5 * np.sum((y-t) **2) Cross Entropy Error(교차 엔트로피 오차)123456789def cee(y, t): delta = 1e-7 return -np.sum(t*np.log(y + delta))def cee(y, t): delta = 1e-7 return -np.sum(t*np.log(y + delta) - (1-t)*np.log(1-y + delta))# delta를 더하는 이유는 예측값이 0일 때 연산 결과가 -inf로 나오는 것을 방지하기위해 아주 작은 값을 더했습니다. 해석적 미분 VS 수치 미분해석적 미분 해석적으로 미분 오차를 포함하지 않는 진정한 미분 값을 구할 수 있다 1. 전미분 2. 편미분 수치 미분 아주 작은 차분으로 미분하는 것 수치 미분에는 오차가 포함된다 반올림 오차 반올림 오차는 소수점 8자리 이하가 생략되어 최종 계산에 오차가 생기게 하는 경우를 말한다 1234import numpy as npnp.float32(1e-50): 0.0 차분 중앙 차분 수치 미분의 예 123456789101112131415161718192021222324252627282930313233import numpy as npimport matplotlib.pyplot as plt# 중앙 차분def numerical_diff(f, x): h = 1e-4 return(f(x+h) - f(x-h)) / (2*h)# f(x) = 0.01x^2 + 0.1xdef func(x): return 0.01*x**2 + 0.1*x# f(x), f(x)' 그래프 그리기def func_draw(x1, y1,x2,y2): plt.xlabel(\"x\") plt.ylabel(\"f(x)\") plt.plot(x1,y1, x2,y2, '-r') plt.show()# f(x)' 기울기, y 절편 구하기 def gen(x,y,f): grad = numerical_diff(f, x) b = y - grad*x return grad, b x = np.arange(0.0,20.0,0.1)y = func(x)# (x=5, y=0.75)function_1 = gen(5, func(5), func)[0]*x + gen(5, func(5), func)[1]# (x=10, y=2)function_2 = gen(10, func(10), func)[0]*x + gen(10, func(10), func1)[1] func_draw(x, y, x, function_1) func_draw(x, y, x, function_2) 학습 알고리즘 구현하기 123456789101112131415[학습] &#x3D;&gt; 데이터(Feature)의 중요도에 관여하는 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정[1 단계] &gt; 미니 배치: 훈련 데이터 중 일부를 무작위로 가져옵니다. 선별한 데이터를 미니배치라 부르며, 미니배치의 loss function 값을 줄이는 것이 목표입니다.[2 단계] &gt; 기울기 산출: 미니 배치의 loss function 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구합니다.[3 단계] &gt; 매개변수 갱신: 가중치 매개변수의 값을 0에 가까워 지도록 갱신합니다. 그 기울기가 0에 가까워지면 정답 - 예측값이 작아짐을 의미하여 학습이 충분히 되었음을 의미합니다.[4 단계] &gt; 1~3 단계를 반복한다","categories":[{"name":"AI","slug":"AI","permalink":"http://jungjihyuk.github.io/categories/AI/"},{"name":"Deep Learning","slug":"AI/Deep-Learning","permalink":"http://jungjihyuk.github.io/categories/AI/Deep-Learning/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jungjihyuk.github.io/tags/python/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://jungjihyuk.github.io/tags/deep-learning/"}]},{"title":"CodeSignal Arcade 문제 풀이","slug":"codesignal","date":"2019-10-08T15:00:00.000Z","updated":"2020-02-24T15:42:17.508Z","comments":true,"path":"2019/10/09/codesignal/","link":"","permalink":"http://jungjihyuk.github.io/2019/10/09/codesignal/","excerpt":"Python, Database, 문제해결 프로그래밍","text":"Index123451. Intro &#x3D;&gt; 문제해결 프로그래밍, 알고리즘 문제2. DataBase &#x3D;&gt; SQL 문제3. The Core &#x3D;&gt; 아직 안풀어봄4. Python &#x3D;&gt; Python 문법 문제5. Graphs &#x3D;&gt; 아직 안풀어봄 Navigation Intro &nbsp;DataBase &nbsp;The Core &nbsp;Python &nbsp;Graphs &nbsp; Intro CenturyFromYear 연도를 입력 받으면 몇 세기인지 출력하는 함수 만들기 Example12345For year &#x3D; 1905, the output should becenturyFromYear(year) &#x3D; 20For year &#x3D; 1700, the output should becenturyFromYear(year) &#x3D; 17 ### My Answer 1234567def centuryFromYear(year): if year % 100 != 0: year = year / 100 return int(year + 1) else: year = year / 100 return int(year) Another Answer (Python)12def centuryFromYear(year): return (year + 99) // 100 Another Answer (JS)123function checkPalindrome(inputString) &#123; return inputString == inputString.split('').reverse().join('');&#125; CheckPalindrome 회문인지 체크하는 함수, 앞으로 읽어도 뒤로 읽어도 똑같은 문자열이면 True 반환, 아니면 False 반환 Example12345For inputString &#x3D; &quot;aabbaa&quot;, the output should be checkPalindrome(inputString) &#x3D; tureFor inputString &#x3D; &quot;abac&quot;, the output should be checkPalindrome(inputString) &#x3D; falseFor inputString &#x3D; &quot;a&quot;, the output should be checkPalindrome(inputString) &#x3D; true My Answer12345def checkPalindrome(inputString): if inputString == inputString[::-1]: return True else: return False Another Answer (Python)12def checkPalindrome(inputString): return inputString == inputString[::-1] Another Answer (C++)123bool checkPalindrome(string is) &#123; return is == string(is.rbegin(),is.rend());&#125; AdjacentElementsProduct 인접한 요소의 곱이 가장 큰 값 반환 Example12For inputArray &#x3D; [3, 6, -2, -5, 7, 3], the output should beadjacentElementsProduct(inputArray) &#x3D; 21 My Answer1234567def adjacentElementsProduct(inputArray): temp = -99999999999 for i in range(len(inputArray)-1): result = inputArray[i] * inputArray[i+1] if temp &lt; result: temp = result return temp Another Answer (Python)12def adjacentElementsProduct(inputArray): return max([inputArray[i] * inputArray[i+1] for i in range(len(inputArray)-1)]) Another Answer (JS)123456789101112131415# 1function adjacentElementsProduct(inputArray) &#123; var prod = inputArray[0] * inputArray[1]; for (var i = 1; i&lt;inputArray.length - 1;i++) &#123; prod = Math.max(prod, inputArray[i] * inputArray[i+1]); &#125; return prod&#125;# 2function adjacentElementsProduct(arr) &#123; return Math.max(...arr.slice(1).map((x,i)=&gt;[x*arr[i]]))&#125; Another Answer (Java)12int adjacentElementsProduct(int[] inputArray) &#123; return IntStream.range(1, inputArray.length).map(i-&gt;inputArray[i]*inputArray[i-1]).max().getAsInt();&#125; ShapeArea My Answer123import mathdef shapeArea(n): return 2 * math.pow(n - 1, 2) + 2 * (n - 1) + 1 Another Answer (Python)12def shapeArea(n): return n**2 + (n-1)**2 Another Answer (JS)123function shapeArea(n) &#123; return n*n + (n-1)*(n-1);&#125; Another Answer (C++)123int shapeArea(int n) &#123; return 1 + 2 * n * (n-1);&#125; # DataBase (MySQL 문법) MonthlyScholarships 1년치 장학금이 기제되어 있는 DB에서 각 id별로 매달 장학금을 계산해서 id와 scholarship을 조회하라 ExampleTableResult My Answer1234CREATE PROCEDURE monthlyScholarships()BEGIN SELECT id, scholarship/12 as scholarship FROM scholarships;END ProjectsTeam 중복되는 이름은 제거하고 이름을 오름차순으로 정렬하여 조회하라 ExampleTable Result My Answer1234CREATE PROCEDURE projectsTeam()BEGIN SELECT DISTINCT name FROM projectLog ORDER BY name;END AutomaticNotifications role 칼럼의 admin, premium을 제외한 행의 email을 조회하라 ExampleTable Result MyAnswer12345CREATE PROCEDURE automaticNotifications() SELECT email FROM users WHERE role NOT IN (\"admin\", \"premium\") ORDER BY email; # The Core # Python Collections Truthness Python에서 True와 False의 의미를 알 수 있는 문제 Example123456xs = [()]res = [False] * 2if xs: res[0] = Trueif xs[0]: res[1] = True My Answer123456xs = [()]res = [False] * 2if xs: res[0] = Trueif xs[0]: res[1] = False xs 리스트는 첫번째 요소로 tuple을 갖기 때문에 존재론적 관점에서 True, 리스트의 첫번째 요소인 tuple의 첫번째 요소는 아무것도 없기 때문에 존재론적 관점에서 False이다 Efficient Comparison 효과적인 비교 방법을 찾는 문제 ### Example 1231. if L &lt; x**y &lt;=R:2. if x**y &gt; L and x**y &lt;=R:3. if x**y in range(L+1, R+1): My Answer1234567891011121314151617181920212223242526272829303132def func1(x,y,L,R): if L &lt; x**y &lt;=R: return True else: return Falsedef func2(x,y,L,R): if x**y &gt; L and x**y &lt;=R: return True else: return False def func3(x,y,L,R): if x**y in range(L+1, R+1): return True else: return False%%timeitfunc1(2,3, 0,10): 480 ns ± 34.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)%%timeitfunc2(2,3, 0,10): 763 ns ± 23.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)%%timeitfunc3(2,3, 0,10): 806 ns ± 45.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) func1이 가장 빠르다 Count Bits 숫자 n을 입력하면 bit수를 출력하는 함수 ### Example 123n = 50countBits(n) = 650(10진수) = 110010(2진수) =&gt; 6개 비트로 구성 My Answer123456789def countBits(n): cnt = 1 rest = 0 while(n!=1): rest = n/2 n = int(rest) cnt +=1 return cnt 함수가 잘 작동하고 정답처리가 되긴 했지만 자꾸 return문만 써서 간결하게 하라고 해서 다음 단계로 넘어가지 못했음.. Another Answer (Python)12def countBits(n): return n.bit_length() 저런 내장 함수가 있는지 몰랐네… Modulus 숫자 n이 정수형이면 return 1 아니면 return -1 ### Example 12345n = 15modulus(n) = 1n = 23.12modulus(n) = -1 My Answer12345def modulus(n): if isinstance(n, int): return n % 2 else: return -1 Another Answer (Python)12345def modulus(n): if n==int(n) : return n % 2 else: return -1 Base Conversion n진법으로 표기된 String을 16진수로 변환하기 Example123456n = '1302'x = 51302(5) =&gt; 202(10) =&gt; cabaseConversion('1302',5) = 'ca' My Answer12345678def baseConversion(n:str, x:int)-&gt;int: result = 0 for i, n in enumerate(n[::-1]): result += int(n) * pow(x, i) return hex(result)[2:]def baseConversion(n, x): return hex(int(n,x))[2:] int 함수는 숫자를 넣었을 때 정수형으로 변환하지만, 문자열 형태의 숫자와 변환하고자 하는 진법의 수를 입력하면 원하는 진법을 변환해주기도 한다 Another Answer (Python)12def baseConversion(n, x): return format(int(n, x), 'x') ListBeautifier 어떠한 리스트가 들어와도 리스트의 맨 앞 요소와 맨 뒤 요소가 같거나 빈 리스트를 반환하도록 하는 함수 Example1234567a = [3, 4, 2, 4, 38, 4, 5, 3, 2]b = [1,4,-5]c = [1,2]listBeautifier(a) = [4, 28, 4]listBeatuifier(b) = [4]listBeatuifier(c) = [] My Answer1234567891011121314151617181920212223def listBeautifier1(a): res = a[:] while res and res[0] != res[-1]: res = res[1:-1] return resdef listBeautifier2(a): res = a[:] while res and res[0] != res[-1]: a, *res, b = res return res%%timeitlistBeautifier1(a): 2.32 µs ± 193 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)%%timeitlistBeautifier2(a): 3.05 µs ± 237 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)# slicing이 아주 살짝 더 빠르다 Slicing과 Unpacking으로 쉽게 풀 수 있다! Fix Message 대소문자 고쳐주는 함수 (가장 앞 단어의 첫번째 철자를 대문자로 그리고 나머지는 소문자로) Example123message = \"you'll NEVER believe what that 'FrIeNd' of mine did!!1\"fixMessage(message) = \"You'll never believe what that 'friend' of mine did!!1\" My Answer12def fixMessage(message): return message.lower().capitalize() Another Answer12def fixMessage(message): return message.upper()[0] + message[1:].lower() Cat Walk 내가 자리를 비운 사이 고양이가 내 키보드 위에 올라가 스페이스바를 마구 눌러서 띄어쓰기 간격이 너무 많이 벌어졌다. 늘어난 띄어쓰기 공간을 하나로 줄여라 (이런 말도 안되는..ㅎ) Example123line = \"def m e gaDifficu ltFun ction(x):\"catwalk(line) = \"def m e gaDifficu ltFun ction(x):\" My Answer12345678910111번def catWalk(code): a = '' for i in code.rsplit(): a += i + ' ' return a.rstrip() # rstrip 함수는 원래 값은 변하지 않고 함수 호출시에만 결과값 리턴2번from functools import reducedef catWalk(code): return reduce(lambda x,y:x+' '+y, [i for i in code.rsplit()]) 내 머리속에서 이런 코드가 나오다니..ㅎ 근데 제출이 안되네 ㅠ Another Answer1233번def catWalk(code): return \" \".join(code.split()) 이런 쉬운 함수가 있었다니..ㅎ 속도 차이12345678910111213%%timeitcatWalk(line)# 1번3.13 µs ± 205 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)# 2번4.51 µs ± 233 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)# 3번1.2 µs ± 39.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)# 결론: 이미 만들어져 있는게 젤 빠르다.. Convert Tabs 문자열 안에 Tab(\\t)이 들어 있다면 n번의 space로 변환하는 함수 Example12345678code = \"\\t\\t\\t\\t\\t\"convertTabs(code, 1) = \" \"code = \"def add(x, y)\\f\\treturn x + y\"convertTabs(code, 4) = \"def add(x, y)\\f return x + y\"code = \" for x in range(20)\"convertTabs(code, 100) = \" for x in range(20)\" My Answer12def convertTabs(code, x): return code.replace('\\t', ' '*x) Feedback Review 원하는 크기 이하의 문자열 단위로 쪼개주는 함수 Example1234567feedback = \"This is an example feedback\"size = 8feedbackReview(feedback, size) = [\"This is\", \"an\", \"example\", \"feedback\"] Another Answer123456789import textwrapdef feedbackReview(feedback, size): return textwrap.wrap(feedback, size)import redef feedbackReview(feedback, size): return re.findall('(?:\\s|^)(\\S(?:.&#123;0,%d&#125;\\S)?)(?=\\s|$)' % (size-2),feedback) Is Word Palindrome 회문인지 확인하는 함수, 앞으로 읽어도 뒤로 읽어도 같은지 확인하는 함수 Example12345word = \"aibohphobia\"isWordPalindrome(word) = true;word = \"hehehehehe\"isWordPalindrome(word) = false My Answer12def isWordPalindrome(word): return word == word[::-1] Permutation Cipher 이름은 순열암호화 인데 사실상 시저 암화랑 같음. 평문하고 키를 넘겨주면 시저암호 처럼 암호화 해주는 함수 Example123456789password = \"iamthebest\"key = \"zabcdefghijklmnopqrstuvwxy\"permutationCipher(password, key) = \"hzlsgdadrs\"abcdefghijklmnopqrstuvwxyz|| | || | ||vv v vv v vvzabcdefghijklmnopqrstuvwxy My Answer123def permutationCipher(password, key): table = str.maketrans(\"abcdefghijklmnopqrstuvwxyz\", key) return password.translate(table) Another Answer1234567891011def permutationCipher(password, key): table = &#123;ord('a') + i : ord(k) for i, k in enumerate(key)&#125; return password.translate(table)def permutationCipher(password, key): table = ' '*97+key return str(password).translate(table)def permutationCipher(password, key): table = string.maketrans(string.lowercase, key) return str(password).translate(table) Competitive Eating 설명 못하겠음… 예시 확인 ㄱㄱ Example123t = 3.1415, width = 10, precision = 2,competitiveEating(t, width, precision) = \" 3.14 \" Another Answer12345678def competitiveEating(t, width, precision): return '&#123;:^&#123;&#125;.&#123;&#125;f&#125;'.format(t,width,precision)def competitiveEating(t, width, precision): return \"&#123;0:.&#123;1&#125;f&#125;\".format(t,precision).center(width)def competitiveEating(t, width, precision): return ('&#123;:^&#123;w&#125;.&#123;p&#125;f&#125;').format(t,w=width,p=precision) Get Commit 유저 이름과 0, ?, +, !가 포함된 암호화 commit 문자중 4가지 symbol을 제거한 문자열을 추출하라 Example123commit = \"0??+0+!!someCommIdhsSt\"getCommit(commit) = \"someCommIdhsSt\" My Answer12def getCommit(commit): return commit.replace('0','').replace('?','').replace('!','').replace('+','') 너무 일차원적인 답변이지만 잘 된다..ㅎ Another Answer1234567891011121314151617def getCommit(commit): return commit.lstrip('0?+!')def getCommit(commit): return commit.strip('0?+!') def getCommit(commit): return \"\".join(filter(lambda x: x not in \"0?+!\", commit))def getCommit(commit): return re.sub('[0?+!]', '', commit)def getCommit(commit): return \"\".join([c for c in commit if c.islower() or c.isupper()])def getCommit(commit): return re.match(r\"^[0\\?\\+!]*(.*)$\", commit).group(1) Lists Concatenation 두 리스트를 연결하는 함수. Example1234lst1 = [2, 2, 1]lst2 = [10, 11]listsConcatenation(lst1, lst2) = [2, 2, 1, 10, 11] My Answer123456789def listsConcatenation(lst1, lst2): res = lst1 res.extend(lst2) return resdef listsConcatenation(lst1, lst2): res = lst1 [res.append(i) for i in lst2] return res Another Answer1234def listsConcatenation(lst1, lst2): res = lst1 res += lst2 return res Two Teams 리스트에 있는 요소에서 [홀수번째 요소 합 - 짝수번째 요소 합 구하는] 함수 Example1234students = [1, 11, 13, 6,14]twoTeams(students) = 11(1 + 13 + 14) - (11 + 6) = 11 My Answer12def twoTeams(students): return sum(students[::2]) - sum(students[1::2]) Another Answer12def twoTeams(students): return sum( (-1)**i*I for i,I in enumerate(students)) Remove Tasks 리스트에서 n번째 요소 제거한 리스트 반환하는 함수 Example1234k = 3toDo = [1237, 2847, 27485, 2947, 1, 247, 374827, 22]removeTasks(k, toDo) = [1237, 2847, 2947, 1, 374827, 22] My Answer123def removeTasks(k, toDo): del toDo[k-1::k] return toDo Print List 설명은 패스 ~ 예시를 참고해주세요~ Example123lst = [1, 2, 3, 4, 5]printList(lst) = \"This is your list: [1, 2, 3, 4, 5]\" My Answer12def printList(lst): return 'This is your list: ' + str(lst) Another Answer12345def printList(lst): return f'This is your list: &#123;lst&#125;'def printList(lst): return \"This is your list: &#123;&#125;\".format(lst) Repeat Char 문자열과 숫자를 입력받아 입력받은 숫자만큼 반복하는 문자열을 반환하는 람다 Example1234ch = '*'n = 10repeatChar(ch, n) = '**********' My Answer1repeatChar = lambda ch, n : ch *n Get Points 채점 해주는 함수. n번째 문제가 맞으면 n점 획득, 틀리면 패널티 점수 차감. Example1234answer = [True, False, True, False, True, True]p = 3getPoints(answer, p) = 12 =&gt; 1 -3 + 3 -3 + 5 + 6 My Answer1234567def getPoints(answers, p): questionPoints = lambda x,y : x+1 if(y==True) else -p res = 0 for i, ans in enumerate(answers): res += questionPoints(i, ans) return res Another Answer1234567def getPoints(answers, p): questionPoints = lambda i,ans: [-p,i+1][ans] res = 0 for i, ans in enumerate(answers): res += questionPoints(i, ans) return res Sort Students 성씨를 기준으로 오름차순 정렬하는 함수. (단, 성이 같으면 이름으로) Example123name = [\"John Smith\", \"Jacky Mon Simonoff\", \"Lucy Smith\", \"Angela Zimonova\"]sortStudents(name) = ['Jacky Mon Simonoff', 'John Smith', 'Lucy Smith', 'Angela Zimonova'] Another Answer12345678def sortStudents(students): # 특정한 데이터를 기준으로 정렬할 수 있도록 함수를 지정할 수 있다 students.sort(key=lambda name: name.split(\" \")[-1]) return studentsdef sortStudents(students): students.sort(key= lambda s : s[len(s)-(s[::-1]).find(\" \"):] ) return students Is Test Solvable 리스트에 있는 숫자들을 다 더하는데, 각 숫자는 각 자리수의 합을 구한 후 더한다. 그리고 그 총합이 n으로 나누어지는지 확인해주는 함수를 만든다. Example123456ids = [529665, 909767, 644200]k = 3(5+2+9+6+6+5) + (9+0+9+7+6+7) + (6+4+4+2+0+0) = 8787/3 = 0=&gt; True My Answer1234567def isTestSolvable(ids, k): digitSum = lambda x : sum([int(i) for i in list(str(x))]) sm = 0 for questionId in ids: sm += digitSum(questionId) return sm % k == 0 Another Answer123456789101112131415def isTestSolvable(ids, k): digitSum = lambda x: x%10+digitSum(x//10) if x else 0 sm = 0 for questionId in ids: sm += digitSum(questionId) return sm % k == 0def isTestSolvable(ids, k): digitSum = lambda r: sum(map(int,str(r))) sm = 0 for questionId in ids: sm += digitSum(questionId) return sm % k == 0 Create Spiral Matrix 나선형 행렬을 구하는 함수. (맨 오른쪽 아래부터 시작) Example12345n = 3createSpiralMatrix(n) = [[5, 4, 3], [6, 9, 2], [7, 8, 1]] My Answer123456789101112131415161718192021222324252627282930313233343536373839# 1번def createSpiralMatrix(n): dirs = [(-1, 0), (0, -1), (1, 0), (0, 1)] curDir = 0 curPos = (n - 1, n - 1) res = [[0 for j in range(n)] for i in range(n)] for i in range(1, n * n + 1): res[curPos[0]][curPos[1]] = i nextPos = curPos[0] + dirs[curDir][0], curPos[1] + dirs[curDir][1] if not (0 &lt;= nextPos[0] &lt; n and 0 &lt;= nextPos[1] &lt; n and res[nextPos[0]][nextPos[1]] == 0): curDir = (curDir + 1) % 4 nextPos = curPos[0] + dirs[curDir][0], curPos[1] + dirs[curDir][1] curPos = nextPos return res# 2번import numpy as npdef createSpiralMatrix(n): dirs = [(-1, 0), (0, -1), (1, 0), (0, 1)] curDir = 0 curPos = (n - 1, n - 1) res = np.zeros([n,n]) for i in range(1, n * n + 1): res[curPos[0]][curPos[1]] = i nextPos = curPos[0] + dirs[curDir][0], curPos[1] + dirs[curDir][1] if not (0 &lt;= nextPos[0] &lt; n and 0 &lt;= nextPos[1] &lt; n and res[nextPos[0]][nextPos[1]] == 0): curDir = (curDir + 1) % 4 nextPos = curPos[0] + dirs[curDir][0], curPos[1] + dirs[curDir][1] curPos = nextPos return res 2번도 가능. 그러나 해당 문제에서 numpy 사용 금지.1번에서 처음에 [[j for j in range(n)] for i in range(n)]를 했지만 계속 인덱스 오류가 남. (이유는 모르겠음..) Another Answer1234567891011121314151617def createSpiralMatrix(n): dirs = [(-1, 0), (0, -1), (1, 0), (0, 1)] curDir = 0 curPos = (n - 1, n - 1) res = [[0]*n for x in range(n)] for i in range(1, n * n + 1): res[curPos[0]][curPos[1]] = i nextPos = curPos[0] + dirs[curDir][0], curPos[1] + dirs[curDir][1] if not (0 &lt;= nextPos[0] &lt; n and 0 &lt;= nextPos[1] &lt; n and res[nextPos[0]][nextPos[1]] == 0): curDir = (curDir + 1) % 4 nextPos = curPos[0] + dirs[curDir][0], curPos[1] + dirs[curDir][1] curPos = nextPos return res Construct Shell 오른쪽으로 90도 회전한 산 모양 리스트를 반환하는 함수 Example1234567n = 3constructShell(n) = [[0], [0, 0], [0, 0, 0], [0, 0], [0]] My Answer12def constructShell(n): return [[0 for j in range(2*n-i)] if i &gt; n else [0]*i for i in range(1, 2*n)] Another Answer12345678def constructShell(n): return [[0]*min(i,2*n-i) for i in range(1,2*n)]def constructShell(n): return [[0] * (i - 2 * max(0, i-n) ) for i in range(1, 2 * n)]def constructShell(n): return [[0] * (n-abs(i)) for i in range(-n+1, n)] Word Power 단어를 넣으면 알파벳 순서에 맞게 숫자로 치환하여 각각의 철자의 합을 구하는 함수. Example1234word = 'hello'h =&gt; 8 e =&gt; 5 l =&gt; 12 o =&gt; 15wordPower(word) = 8 + 5 + 12 + 12 + 15 = 52 My Answer123def wordPower(word): num = &#123;b: a+1 for a, b in enumerate('abcdefghijklmnopqrstuvwxyz')&#125; return sum([num[ch] for ch in word]) Another Answer1234567def wordPower(word): num = &#123;c: ord(c) - 96 for c in word&#125; return sum([num[ch] for ch in word])def wordPower(word): num = dict(zip('abcdefghijklmnopqrstuvwxyz', range(1, 27))) return sum([num[ch] for ch in word]) Cool Pairs 두 리스트의 요소간 결합으로 만들어지는 숫자 쌍이 (x,y)라 했을 때 (x*y)%(x+y)==0 인 쌍의 갯수를 반환하는 함수 단, 숫자 쌍의 합이 같은 경우가 2개 이상일 때는 하나로 취급한다. Example1234567a = [4, 5, 6, 7, 8]b = [8, 9, 10, 11, 12]# (4,12), (6,12), (8,8)의 경우가 발생# 그러나 합으로 봤을 때는 16, 18인 경우 두 가지!coolPairs(a,b) = 2 My Answer123def coolPairs(a, b): uniqueSums = &#123;(x+y) for x in a for y in b if (x*y)%(x+y)==0&#125; return len(uniqueSums) Multiplication Table 숫자 n을 입력하면 NxN 행렬을 반환한다. (단, 1행은 1단 2행은 2단 …n행은 n단의 숫자로 구성) Example1234567n = 5multiplicationTable(5) = [[1, 2, 3, 4, 5], [2, 4, 6, 8, 10], [3, 6, 9, 12, 15], [4, 8, 12, 16, 20], [5, 10, 15, 20, 25]] My Answer12def multiplicationTable(n): return [[a for a in range(b,b*n+1,b)] for b in range(1,n+1)] Another Answer12345def multiplicationTable(n): return [range(i, n*i + 1, i) for i in xrange(1,1+n) ]def multiplicationTable(n): return [[x*y for x in range(1,n+1)] for y in range(1,n+1)] Chess Teams 두 개의 리스트를 입력값으로 받으면 각각의 리스트에서 요소 하나씩 뽑아 리스트로 짝지어 리턴해주는 함수 Example1234smarties = [\"Jane\", \"Bob\", \"Peter\"]cleveries = [\"Oscar\", \"Lidia\", \"Ann\"]chessTeams(smarties, cleveries) = [['Jane', 'Oscar'], ['Bob', 'Lidia'], ['Peter', 'Ann']] My Answer12def chessTeams(smarties, cleveries): return list(map(lambda x, y : [x,y], smarties, cleveries)) Another Answer12def chessTeams(smarties, cleveries): return list(zip(smarties,cleveries)) College Courses 수강한 과목중에 빼야 하는 과목 이름의 길이만 알때 그 과목을 빼는 함수 Example1234n = 7courses = [\"Art\", \"Finance\", \"Business\", \"Speech\", \"History\", \"Writing\", \"Statistics\"]collegeCourses(x, courses) = [\"Art\", \"Business\", \"Speech\", \"Statistics\"] My Answer12345def collegeCourses(x, courses): def shouldConsider(course): return len(course) != x return list(filter(shouldConsider, courses)) Create Histograme 요일마다 과제 수행정도를 보여주는 히스토그램을 만드는 함수.. (사실 그냥 별찍기) Example12345678910ch = '*'assignments = [12, 12, 14, 3, 12, 15, 14]createHistogram(ch, assignments) = [\"************\", \"************\", \"**************\", \"***\", \"************\", \"***************\", \"**************\"] My Answer12345def createHistogram(ch, assignments): return list(map(lambda x: ch*x, assignments))def createHistogram(ch, assignments): return [ch * x for x in assignments] Least Common Denominator 최소공통분모 구하는 함수 Example123456789denominators = [2, 3, 4, 5, 6]leastCommonDenominator(denominators) = 60# 풀이2 x 3 4 5 6----- x ----- x ----- x ----- 1 2 1 6 =&gt; (2와 3의 최대공약수, 2x3과 4의 최대 공약수.....) Graphs","categories":[{"name":"Language","slug":"Language","permalink":"http://jungjihyuk.github.io/categories/Language/"},{"name":"Python","slug":"Language/Python","permalink":"http://jungjihyuk.github.io/categories/Language/Python/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://jungjihyuk.github.io/tags/algorithm/"},{"name":"CodeSignal","slug":"CodeSignal","permalink":"http://jungjihyuk.github.io/tags/CodeSignal/"},{"name":"코딩연습","slug":"코딩연습","permalink":"http://jungjihyuk.github.io/tags/%EC%BD%94%EB%94%A9%EC%97%B0%EC%8A%B5/"},{"name":"python","slug":"python","permalink":"http://jungjihyuk.github.io/tags/python/"},{"name":"database","slug":"database","permalink":"http://jungjihyuk.github.io/tags/database/"}]},{"title":"Tensorflow를 활용한 신경망 구현하기","slug":"tensorflow","date":"2019-10-05T15:00:00.000Z","updated":"2020-02-24T15:43:28.353Z","comments":true,"path":"2019/10/06/tensorflow/","link":"","permalink":"http://jungjihyuk.github.io/2019/10/06/tensorflow/","excerpt":"기본적인 것부터 딥러닝 살펴보기","text":"신경망 구조 **Multi Layer Neural Networks** ![multi layer](https://user-images.githubusercontent.com/33630505/66271736-b7573a00-e89c-11e9-9563-726d98aee646.JPG) Back Propagation에 필요한 수식 Tensorflow텐서의 흐름 &nbsp; =&gt; &nbsp;벡터 데이터의 흐름Tensorflow는 벡터 데이터가 흘러 그 데이터를 처리하고 인간의 뇌처럼 작동하는 AI기술인 Deep Learning의 Framework이다. Tensorflow 작동 방식 텐서플로우는 기본적으로 그래프 기반으로 작동되는 프레임워크 이다. 출처: tensorflow 12345678910111. 그래프 생성2. 그래프 실행그래프 생성 단계에서는 연산 과정을 그래프 형태로 표현한다.밑에 그림에서 볼 수 있듯이Computational Graph는 Node와 Edge로 이루어진 자료 구조이다.Node에는 Operator, Variable, Constant등을 정의하고, node간의 연결인edge를 통해 tensor data를 주고받으면서 계산을 할 수 있도록 프로그래밍 한다.그래프 생성이 끝나면 Session 객체를 통해 생성한 그래프를 실행 할 수 있다. 출처: gitbooks Tensorflow로 구현하기Tensorflow import Tensorflow를 import하면 그 시점에 비어 있는 기본 graph가 만들어지며, 앞으로 작성될 node들은 이 기본 graph에 자동으로 연결된다 1import tensorflow as tf Data set x는 입력 데이터, y는 결과 데이터 총 데이터 갯수 4개 input 값 1개, output 값 1개 12x_data = [1,2,3,4]y_data = [5,8,11,14] Tensor for Data set placeholder는 데이터를 입력받는 비어있는 변수그래프를 구성하고 그래프가 실행되는 시점에 입력 데이터를 넣어주는데 활용된다그리고 placeholder는 shape인수를 유동적으로 지정할 수 있다 12345x = tf.placeholder(tf.float32)y = tf.placeholder(tf.float32)type(x) # y도 동일: tensorflow.python.framework.ops.Tensor Weight &amp; Bias 학습 과정에서 모델의 매개변수로 가중치, 편향치가 입력되는데 이 가중치, 편향치가 최적화되기 위해 Variable이라는 객체를 사용한다 가중치가 최적화되는 반복 과정에서 현재의 변수가 다음 반복 과정에 영향을 줄 수 있어야 하기 때문에 Variable 객체를 사용한다 12W = tf.Variable([1], dtype=tf.float32) # 가중치, 편향치 모두 경험적으로 1로 세팅했다b = tf.Variable([1], dtype=tf.float32) Variable은 학습을 통해 변화하는 배열 값을 저장하기 위한 operation. 출처: https://webofthink.tistory.com/68 [Web of Think]** Placeholder vs Variable 둘다 변수이긴 변수 인데 variable은 연산이 수행되면서 값이 변하고 다음 연산에 그 값을 유지하고 있어야 하기 때문에 정말 ‘변하는 수’ 같은 느낌이고placeholder는 데이터를 담을 공간을 의미하는 변수인거 같다 (확실하지 않음..) 112345678910111213set(dir(W)) &amp; set(dir(x)) # 공통점으로 dtype, shape, name 등이 있는걸로 봐서 tensor 객체인것은 공통점: &#123;'device', 'dtype', 'eval', 'get_shape', 'graph', 'name', 'op', 'set_shape', 'shape'&#125;# special method는 제외했음 2123456789101112131415161718192021222324set(dir(W)) - set(dir(x)) # Variable에만 있는 함수와 변수들: &#123;'SaveSliceInfo', 'assign', 'assign_add', 'assign_sub', 'batch_scatter_update', 'constraint', 'count_up_to', 'from_proto', 'initial_value', 'initialized_value', 'initializer', 'load', 'read_value', 'scatter_add', 'scatter_nd_add', 'scatter_nd_sub', 'scatter_nd_update', 'scatter_sub', 'scatter_update', 'to_proto', 'trainable', 'value'&#125; 312345set(dir(x)) - set(dir(W)) # placeholder에만 있는 함수와 변수들: &#123;'OVERLOADABLE_OPERATORS', 'consumers', 'value_index'&#125; hypothesis 가설값(추측값) = 가중치 X 입력값 + 편향치 가중치를 찾기 위한 함수 혹은 모델 1hypothesis = W * x + b cost function (추측값 - 정답)의 제곱의 평균, 즉 내가 추측한 값과 정답 사이의 상관관계를 보기위한 함수이 비용 함수의 목표는 추측값과 정답의 오차를 줄이는 데에 있다앞으로 이 비용 함수의 편미분 값은 가중치 조정 알고리즘에 사용된다 1cost = tf.reduce_mean(tf.square(hypothesis-y)) optimizer 경사하강법을 사용하기 위한 알고리즘 이 경사하강법은 비용 함수에서 오차를 최소로 만들기 위해 사용하는 편미분 알고리즘 123optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)# 학습률은 보통 0.1 또는 0.01을 사용한다# 학습률에 관한 자세한 내용은 추후에 더 공부해보자 가중치 조절 알고리즘 cost function이 인자로 전달되고 optimizer의 minimize함수를 통해 구현된다이 알고리즘의 목표는 오차가 최소가 되는 지점의 weight와 bias를 구하는 것이다조정된 가중치 = 가중치 - 학습률 * cost fucntion의 편미분값 1train_op = optimizer.minimize(cost) session 그래프를 구성한 후 실제 수행을 할때 다양한 실행환경(CPU, GPU, 분산처리)하에서 처리하기 위해Client에서 session을 만들어 전달하는 역할을 한다 123sess = tf.Session()sess.run(tf.global_variables_initializer()) # tensor를 선언하고 초기화 하지 않았기 때문에 # 초기화를 한 후 실행해야 한다 Epoch 100으로 학습시키기12345678910111213141516171819202122for step in range(100): _, cost_val = sess.run([train_op, cost], feed_dict=&#123;x: x_data, y: y_data&#125;) print(\"Epoch: \",step, \"loss: \",cost_val,\" weight: \", sess.run(W),\" bias: \", sess.run(b)): Epoch: 0 loss: 41.0 weight: [4.5] bias: [2.2] Epoch: 1 loss: 18.415 weight: [2.1499999] bias: [1.4100001] Epoch: 2 loss: 8.274352 weight: [3.72] bias: [1.9530001] Epoch: 3 loss: 3.721009 weight: [2.6634998] bias: [1.6024001] Epoch: 4 loss: 1.6762912 weight: [3.3670502] bias: [1.8501701] Epoch: 5 loss: 0.7579173 weight: [2.8913898] bias: [1.696611] Epoch: 6 loss: 0.34527153 weight: [3.2059994] bias: [1.8115939] Epoch: 7 loss: 0.15970731 weight: [2.9912033] bias: [1.7462754] Epoch: 8 loss: 0.076116346 weight: [3.1312609] bias: [1.8014188] Epoch: 9 loss: 0.038325354 weight: [3.0336602] bias: [1.7755046] Epoch: 10 loss: 0.021112926 weight: [3.0954175] bias: [1.8035736] .... .... .... .... Epoch: 97 loss: 3.7696707e-05 weight: [3.004957] bias: [1.985426] Epoch: 98 loss: 3.5472734e-05 weight: [3.0048087] bias: [1.9858623] Epoch: 99 loss: 3.3379514e-05 weight: [3.0046647] bias: [1.9862854] loss가 0에 가깝긴 하지만 가중치, 편향치가 3.0046647, 1.9862854인걸로 보아 학습이 살짝 모자라다 학습된 모델로 결과 예측하기 (Epoch 100)12345sess.run(hypothesis, feed_dict=&#123;x:5&#125;) # 3*5 + 2 = 17sess.run(hypothesis, feed_dict=&#123;x:6&#125;) # 3*6 + 2 = 20: array([17.00961], dtype=float32) array([20.014275], dtype=float32) Epoch 1000으로 학습시키기12345678910111213141516171819202122sess2 = tf.Session()sess2.run(tf.global_variables_initializer()): Epoch: 0 loss: 41.0 weight: [4.5] bias: [2.2] Epoch: 1 loss: 18.415 weight: [2.1499999] bias: [1.4100001] Epoch: 2 loss: 8.274352 weight: [3.72] bias: [1.9530001] Epoch: 3 loss: 3.721009 weight: [2.6634998] bias: [1.6024001] Epoch: 4 loss: 1.6762912 weight: [3.3670502] bias: [1.8501701] Epoch: 5 loss: 0.7579173 weight: [2.8913898] bias: [1.696611] Epoch: 6 loss: 0.34527153 weight: [3.2059994] bias: [1.8115939] Epoch: 7 loss: 0.15970731 weight: [2.9912033] bias: [1.7462754] Epoch: 8 loss: 0.076116346 weight: [3.1312609] bias: [1.8014188] Epoch: 9 loss: 0.038325354 weight: [3.0336602] bias: [1.7755046] Epoch: 10 loss: 0.021112926 weight: [3.0954175] bias: [1.8035736] .... .... .... Epoch: 995 loss: 7.9580786e-13 weight: [3.000001] bias: [1.9999975] Epoch: 996 loss: 7.9580786e-13 weight: [3.000001] bias: [1.9999975] Epoch: 997 loss: 7.9580786e-13 weight: [3.000001] bias: [1.9999975] Epoch: 998 loss: 7.9580786e-13 weight: [3.000001] bias: [1.9999975] Epoch: 999 loss: 7.9580786e-13 weight: [3.000001] bias: [1.9999975] 학습된 모델로 결과 예측하기 (Epoch 1000)12345sess2.run(hypothesis, feed_dict=&#123;x:5&#125;) # 3*5 + 2 = 17sess2.run(hypothesis, feed_dict=&#123;x:6&#125;) # 3*6 + 2 = 20: array([17.000002], dtype=float32) array([20.000004], dtype=float32)","categories":[{"name":"AI","slug":"AI","permalink":"http://jungjihyuk.github.io/categories/AI/"},{"name":"Deep Learning","slug":"AI/Deep-Learning","permalink":"http://jungjihyuk.github.io/categories/AI/Deep-Learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://jungjihyuk.github.io/tags/deep-learning/"},{"name":"tensorflow","slug":"tensorflow","permalink":"http://jungjihyuk.github.io/tags/tensorflow/"},{"name":"neural network","slug":"neural-network","permalink":"http://jungjihyuk.github.io/tags/neural-network/"}]},{"title":"Iris Data로 전처리부터 기계학습, 딥러닝까지","slug":"iris","date":"2019-09-10T15:00:00.000Z","updated":"2020-02-24T15:41:44.920Z","comments":true,"path":"2019/09/11/iris/","link":"","permalink":"http://jungjihyuk.github.io/2019/09/11/iris/","excerpt":"나만의 전처리 방식과 여러가지 알고리즘 비교 분석","text":"Pipeline123456789101112131415161718192021222324252627282930313233343536373839404142430. Data 수집 - File Download - API - Crawling &amp; Scraping1. 도메인 지식 확보 - Docs를 읽어본다 (주어 졌을때만) - 이미 내가 알고 있는 전문 분야를 활용한다 - 구글링 - 책2. Data 불러오기 - Pandas Dataframe으로 불러오기 - (비정형 데이터인 경우는 찾아봐야함..)3. Data 파악하기 - head로 대략적인 데이터 살피기 - Tidy Data인지 확인하기 - info로 데이터 정보 확인하기 - missing data 확인하기 - dtype 확인하기4. Data 조작하기 - Wide Format인 경우 melt 하기 - missing data 처리하기 - dtype 확인하고 encoding 하기 - train - test set 분리하기 - 부적절한 data 값 수정하기5. Data 분석하기 (EDA) - describe로 대략적인 값의 특성 확인하기 - 그래프 그려 보기 - 왜도, 첨도 확인하기 - 데이터의 숨겨진 의미 파악하기 - 데이터 양이 충분한지 파악하기 (중심 극한 정리) - Feature 갯수가 데이터의 양에 비해 많은지 확인하기 (오캄의 면도날)6. Data 전처리하기 - Feature Selection - Feature Scaling - Dimensionality Reduction7. 모델링 하기 - 기계학습 or 딥러닝 - 지도학습 or 비지도학습 or 강화학습 - 자연어 or 이미지 or 음성 처리 - 모델링 순서 - 알고리즘 비교하기 - 하이퍼 파라미터 찾기 (GridSearchCV)8. 성능 테스트 도메인 지식 확보하기 Data를 내려받아 쓰는 경우 Docs가 있다면 잘 읽어보고 데이터를 이해한다 Docs가 없고 도메인 지식이 없을 경우 구글링을 하거나 책을 통해 공부한다 웬만하면 내가 관심있는 분야를 선정한다 데이터 불러오기 Pandas DataFrame에 맞게 불러온다 seaborn에서 불러올 때1234import pandas as pdimport seaborn as snsiris = sns.load_dataset('iris') file에서 불러올 때123import pandas as pdiris = pd.read_csv('iris.csv', engine='python') # 필요에 따라 옵션이 달라질 수 있다. api로 불러올 때12 Data 파악하기HEAD123456import pandas as pdimport seaborn as snsiris = sns.load_dataset('iris')iris.head(5) Tidy Data인지 확인하기 데이터 양에 비해 Wide Format인지 아직 판단하기 이르지만 언뜻 봐서 melt할만한 Column은 없어보인다. Wide Format 데이터의 양에 비해 Column이 많은 DataFrame, 즉 가로로 넓은 형태의 데이터 형태를 말한다.{: .notice} info로 데이터 정보 확인하기123456import pandas as pdimport seaborn as snsiris = sns.load_dataset('iris')iris.info() info로 알 수 있는 것들 123451. 데이터 갯수 &#x3D;&gt; 150개 (데이터 양이 적다. 하지만 예제 데이터이니 일단 한번 끝까지 해보자)2. Feature 갯수 &#x3D;&gt; 4개 (Data 150개에 4개 Feature면 적당한가? 아직 모름)3. Dtype &#x3D;&gt; Feature 4개 모두 float64 , target data인 species는 object (기계학습 할때 int나 float형으로 바꿔야 겠다)4. Memory size &#x3D;&gt; 6.0+KB (작다. 불러오는데 큰 문제 없음. memory size가 몇 이하여야 하는지는 잘 모름)5. Missing Data &#x3D;&gt; 없음 미싱데이터 시각화 하기 info로 미싱데이터를 확인 했지만 혹시 어정쩡하게 미싱 데이터가 있거나 미싱데이터의 분포를 쉽게 확인하려면 그래프를 그리자 123456import missingno as minoimport pandas as pdimport seaborn as snsiris = sns.load_dataset('iris')mino.matrix(iris) Label Encoding info를 확인 했을 때 species data를 숫자형으로 바꿔야 된다고 판단 했었고 target 데이터의 값이 문자이면 학습을 할 수 없기 때문에 숫자로 인코딩 해준다 (인코딩과 동시에 dtype 자동변경) Scikit LabelEncoder 활용하기123456789101112131415161718import pandas as pdimport seaborn as snsfrom sklearn.preprocessing import LabelEncoderiris = sns.load_dataset('iris')target = iris.iloc[:,-1]le = LabelEncoder()le.fit_transform(target): array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])target = pd.DataFrame(le.fit_transform(target)) target.rename(&#123;0:'target'&#125;, axis=1, inplace=True) Replace 활용하기1234567import pandas as pdimport seaborn as snsiris = sns.load_dataset('iris')target = iris.iloc[:,-1]target.replace(&#123;'setosa':0,'versicolor':1,'virginica':2&#125;, inplace=True) Label Encoding의 장점과 단점표 Train-Test Set 분리하기 Train, Test set을 분리할 때는 보유한 데이터의 숫자를 감안해서 쪼갠다 데이터의 갯수가 만개 이하일 때는 보통 Train : Test 비율 80 : 20 또는 75 : 25로 분할한다 그러나 그 이상으로 데이터가 많을 경우 최대한 Train 데이터 비율을 늘려 사용한다. 출처: Brunch 123456789from sklearn.model_selection import train_test_split# 관례상 행렬은 대문자, 벡터는 소문자로 표기X_train, X_test, y_train, y_test = train_test_split(data, target)len(X_train): 112len(X_test): 38 데이터 분석하기 데이터의 숨은 의미를 찾아보자! 수치로 데이터 형태, 분포, 경향 확인하기1234567import pandas as pdimport seaborn as snsiris = sns.load_dataset('iris')data = iris.iloc[:,:-1]data.describe() describe 그래프로 보기 describe는 숫자로 나오기 때문에 한눈에 파악하기 힘들다 따라서 그래프로 확인! 12345678import pandas as pdimport seaborn as snsiris = sns.load_dataset('iris')data = iris.iloc[:,:-1]data.boxplot() sepal_width 데이터에서 outlier, 즉 소수의 데이터가 데이터 분포에서 멀리 떨어져 있는 경우가 포착되었다. 하지만 데이터의 갯수도 적고 크게 벗어난 갖이 아니므로 그냥 냅두자 데이터간 산점도 그래프 그리기1234567import pandas as pdimport seaborn as snsiris = sns.load_dataset('iris') # hue는 색상 =&gt; 보통 target data를 서로 다른 색을 구분지어 칠하고 싶을때 사용sns.pairplot(iris, hue='species') 왜도, 첨도 그래프 그리기12345678910111213141516171819202122232425262728293031323334import pandas as pdimport seaborn as snsimport matplotlib.pyplot as pltiris = sns.load_dataset('iris')data = iris.iloc[:,:-1]data.skew() # 왜도: sepal_length 0.314911 sepal_width 0.318966 petal_length -0.274884 petal_width -0.102967 dtype: float64data.kurt() # 첨도: sepal_length -0.552064 sepal_width 0.228249 petal_length -1.402103 petal_width -1.340604 dtype: float64 f, axes = plt.subplots(2, 2, figsize=(7, 7), sharex=True)sns.distplot(data.iloc[:,0], color=\"skyblue\", ax=axes[0,0])sns.distplot(data.iloc[:,1], color=\"olive\", ax=axes[0,1])sns.distplot(data.iloc[:,2], color=\"gold\", ax=axes[1,0])sns.distplot(data.iloc[:,3], color=\"teal\", ax=axes[1,1])for i, ax in enumerate(axes.reshape(-1)): ax.text(x=0.97, y=0.97, transform=ax.transAxes, s=\"Skewness: %f\" % data.iloc[:,i].skew(),\\ fontweight='demibold', fontsize=10, verticalalignment='top', horizontalalignment='right',\\ backgroundcolor='white', color='xkcd:poo brown') ax.text(x=0.97, y=0.91, transform=ax.transAxes, s=\"Kurtosis: %f\" % data.iloc[:,i].kurt(),\\ fontweight='demibold', fontsize=10, verticalalignment='top', horizontalalignment='right',\\ backgroundcolor='white', color='xkcd:dried blood')plt.tight_layout() 왜도 왜도는 데이터가 대칭이 아닌 정도를 나타낸다. 만약 왜도의 값이 음수이면 오른쪽으로 치우친 정도를 나타내고 왜도의 값이 양수이면 왼쪽으로 치우친 정도를 나타낸다.{: .notice} 첨도 첨도는 데이터가 중간값 분포의 정도를 나타낸다. 보통 첨도의 값이 3보다 작으면 완만한 분포를 나타내고 첨도의 값이 3보다 크면 뾰족한 분포를 나타낸다. 지금 데이터에서는 음수면 완만 양수면 뾰족이라고 생각하면 된다.{: .notice} Data 전처리하기 연습용 데이터라 딱히 전처리할게 없음.. 그래도 학습용으로 추후에 추가할 것. 모델링 하기 iris data는 정형데이터에 target data 갯수가 유한개 이므로 classification 방법 중 가장 무난한 logistic regression으로 분류를 시작해보자 Scikit으로 기계학습 하는 순서12341. 활용할 모델 이름 import2. 인스턴스화3. fit4. predict LogisticRegression12345678910from sklearn.linear_model import LogisticRegressionlr = LogisticRegression()lr.fit(X_train, y_train): LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='warn', n_jobs=None, penalty='l2', random_state=None, solver='warn', tol=0.0001, verbose=0, warm_start=False) 성능 검사하기 Cross_val_score를 통해 대략적인 성능을 확인해보자 Cross_val_score12345from sklearn.model_selection import cross_val_scorecross_val_score(lr, X_test, y_test, cv=10).mean(): 0.835 # Accuracy 결과 분석 Logistic regression으로 분류하고 cross_val_score를 확인해본 결과 0.835라는 정확도가나왔기 때문에 iris data는 앞으로 도전해볼 모델도 분류 모델임을 먼저 시도해보는 것이 좋을 것이라고 판단된다.{: .notice} K-Means123456789101112from sklearn.neighbors import KNeighborsClassifierknn = KNeighborsClassifier()knn.fit(X_train, y_train): KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform')cross_val_score(knn, X_test, y_test, cv=10).mean() : 1 SVM123456789101112from sklearn.svm import SVCsvc = SVC()svc.fit(X_train, y_train): SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto_deprecated', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)cross_val_score(svc, X_test, y_test, cv=10).mean(): 0.9800000000000001 Naive Bayes123456789from sklearn.naive_bayes import GaussianNBgnb = GaussianNB()gnb.fit(X_train, y_train): GaussianNB(priors=None, var_smoothing=1e-09)cross_val_score(gnb, X_test, y_test, cv=10).mean(): 0.96 학습 모델로 새로운 값 예측 해보기12345678910111213141516171819# 학습된 값들 lr.predict([[5.1, 3.5, 1.4, 0.2]]) # setosa: array([0], dtype=int64)lr.predict([[6.7, 3.1, 4.7, 1.5]]) # versicolor: array([1], dtype=int64)lr.predict([[7.7, 2.8, 6.7, 2.]]) # virginica: array([2], dtype=int64)# 새로운 값으로 예측하기lr.predict([[4, 3, 1, 0.1]]) : array([0], dtype=int64)lr.predict([[6, 3, 5, 1]]): array([1], dtype=int64)lr.predict([[7, 1, 5, 3]]): array([2], dtype=int64) Train - Test - split으로 정확도 보기1234567891011121314151617181920212223242526272829303132333435import seaborn as snsfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import confusion_matrixiris = sns.load_dataset('iris')iris.species = iris.species.map(&#123;'setosa': 0, 'versicolor':1,'virginica':2&#125;)knn = KNeighborsClassifier()iris_data = iris[iris.columns[:-1]]iris['species']knn.fit(iris_data, iris['species'])X_train, X_test, y_train , y_test = train_test_split(iris[iris.columns[:-1]], iris.species)knn.fit(X_train, y_train)knn.predict(X_test): array([1, 1, 2, 2, 0, 1, 1, 1, 2, 1, 0, 0, 2, 0, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 0, 1, 0, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 2], dtype=int64)knn.predict(X_test) == y_test.values: array([ True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True])confusion_matrix(y_test, knn.predict(X_test)): array([[13, 0, 0], [ 0, 13, 1], [ 0, 0, 11]], dtype=int64)","categories":[{"name":"AI","slug":"AI","permalink":"http://jungjihyuk.github.io/categories/AI/"},{"name":"Machine Learning","slug":"AI/Machine-Learning","permalink":"http://jungjihyuk.github.io/categories/AI/Machine-Learning/"}],"tags":[{"name":"iris","slug":"iris","permalink":"http://jungjihyuk.github.io/tags/iris/"},{"name":"EDA","slug":"EDA","permalink":"http://jungjihyuk.github.io/tags/EDA/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://jungjihyuk.github.io/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://jungjihyuk.github.io/tags/Deep-Learning/"}]},{"title":"Bootstrap4","slug":"bootstrap","date":"2019-08-06T15:00:00.000Z","updated":"2020-02-24T15:40:10.998Z","comments":true,"path":"2019/08/07/bootstrap/","link":"","permalink":"http://jungjihyuk.github.io/2019/08/07/bootstrap/","excerpt":"부트스트랩 활용하기","text":"부트스트랩 시작하기CSS1&lt;link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\" integrity=\"sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\" crossorigin=\"anonymous\"&gt; js123&lt;script src=\"https://code.jquery.com/jquery-3.3.1.slim.min.js\" integrity=\"sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;&lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\" integrity=\"sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;&lt;script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" crossorigin=\"anonymous\"&gt;&lt;/script&gt; 예시1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang=\"ko\"&gt; &lt;!-- Html 문서 페이지를 음성으로 읽어주는 기능을 사용할때 lang에 명시된 언어로 읽어준다 --&gt;&lt;head&gt; &lt;!-- 로봇이나 기계에게 제공하는 정보를 담는 태그, 사람이 직접 보지 않는 부분 --&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;지혁이네&lt;/title&gt; &lt;!-- device별로 1대1로 크기를 매칭시켜 보여줄때 쓰는 태그, Cross browsing 기법--&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"&gt; &lt;!-- 장점: 웹 브라우저가 request 할때 / core 주소당 한개씩 처리?? (속도가 빠르다) --&gt; &lt;!-- 단점: 참조하는 사이트가 서버 오류가 발생하면 같이 영향을 받아 오류가 발생할 수 있다 --&gt; &lt;link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\" integrity=\"sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\" crossorigin=\"anonymous\"&gt;&lt;/head&gt;&lt;body&gt; &lt;script src=\"https://code.jquery.com/jquery-3.3.1.slim.min.js\" integrity=\"sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\" crossorigin=\"anonymous\"&gt;&lt;/script&gt; &lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\" integrity=\"sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1\" crossorigin=\"anonymous\"&gt;&lt;/script&gt; &lt;script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; Cross browsing 웹표준 기술을 적용하여 서로 다른 OS 또는 플랫폼(브라우저)에서도 인터넷이 이상 없이 구현되는 기술을 말한다.{: .notice} Layout121. container2. container-fluid","categories":[{"name":"Web","slug":"Web","permalink":"http://jungjihyuk.github.io/categories/Web/"},{"name":"Bootstrap4","slug":"Web/Bootstrap4","permalink":"http://jungjihyuk.github.io/categories/Web/Bootstrap4/"}],"tags":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://jungjihyuk.github.io/tags/FrontEnd/"},{"name":"bootstrap","slug":"bootstrap","permalink":"http://jungjihyuk.github.io/tags/bootstrap/"},{"name":"css","slug":"css","permalink":"http://jungjihyuk.github.io/tags/css/"},{"name":"js","slug":"js","permalink":"http://jungjihyuk.github.io/tags/js/"}]},{"title":"NLP(자연어 처리)","slug":"nlp","date":"2019-07-19T15:00:00.000Z","updated":"2020-02-24T15:42:45.905Z","comments":true,"path":"2019/07/20/nlp/","link":"","permalink":"http://jungjihyuk.github.io/2019/07/20/nlp/","excerpt":"은근 재미있는 자연어 처리를 공부해보자","text":"NLP(Natural Language Processing) 사람들이 사용하는 언어의 의미를 분석해서 컴퓨터가 처리할 수 있도록 하는 일 한국어는 특히나 단어가 형태소로 이루어져 있기 때문에 컴퓨터에 학습시키가 쉽지 않다 예를 들어 ‘눈’이라는 단어는 내리는 눈, 사람의 눈, 사물을 보고 판단하는 힘, 태풍의 중심 등 여러가지 의미가 있기 때문에 문장간의 문맥도 파악 할 수 있어야 한다 따라서 같은 데이터임에도 다양한 의미를 내포하기 때문에 NLP에서는 Data를 Corpus라고 부른다 Corpus 말뭉치, 언어 데이터를 한데 모은 것 corpus는 단순히 Big language data가 아니다 Corpus가 되기 위한 조건123451. 언어의 특성을 잘 담아 낼 수 있도록 다양한 패턴의 데이터가 필요하다2. 여러가지 상황에서 쓰이는 균형잡힌 데이터여야 한다3. 구어체를 포함해야 한다4. 데이터가 유의미한 규모로 확보되어야 하고 그 데이터가 대표성을 지녀야 한다5. 데이터 수집시 원형을 유지했다라는 보장이 있어야 한다 출처: 위키피디아, &nbsp; tistory Corpus의 종류12341. 용도에 따라 : 균형 말뭉치(balanced&#x2F;core corpus), 학습 말뭉치(training corpus), 학습자 말뭉치(learner&#39;s corpus), 방언 말뭉치(dialect corpus)2. 가공 정도에 따라 : 원시 말뭉치(raw corpus), 주석 말뭉치(tagged&#x2F;annotated corpus), 분석 말뭉치(analyzed corpus)3. 시대에 따라 : 공시적 말뭉치(synchronic corpus), 역사 말뭉치(historical&#x2F;diachronic corpus)4. 변화여부에 따라 : 정적 말뭉치(static corpus), 동적 말뭉치(dynamic&#x2F;monitor corpus Corpus 생성 Tip 단어 입력시 다양한 문장 생성해주는 사이트 : https://www.english-corpora.org/coca/{: .notice} 언어 형태학 NLTK(Natural Language Tool Kit) 자연어 처리를 위한 파이썬 패키지 NLTK 설치1234567!pip install nltk # jupyter notebook에서 설치시import nltknltk.download() # nltk의 기능을 제대로 사용하기 위해서는 nltk data를 추가적으로 설치해야 한다 # 해당 코드가 에러가 난다면 깃허브 페이지에 가서 수동 설치 해야함 # https://github.com/nltk/nltk_datanltk.download(\"punkt\") # tokenize를 사용하기 위해서 설치해야 한다 TokenizationNLP 공부할때 참고: wikidocs, &nbsp; lovit blog LemmatizationStemmingNormalizationCleaningStopwordBag of wordsWord CloudTF-IDF한국어 자연어 처리를 위한 파이썬 라이브러리(대표적인 5가지)123451. Twitter2. Komoran3. Hannanum4. Mecab5. Kkma Konlpy를 활용한 영화 리뷰 감정 분석123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170from konlpy.tag import Kkma, Hannanum,Komoran, Twitter, Oktfrom konlpy.utils import pprintkkma = Kkma()han = Hannanum()kom = Komoran()tw = Twitter()okt = Okt()# nlp 라이브러리의 특성을 공부하고 잘 분석해서 상황에 맞는 nlp를 하기 위해 라이브러리를 선별한다.# 보통 Kkma가 성능이 대체적으로 좋다.pprint(kkma.sentences(u\"네 안녕하세요. 반갑습니다.\")): ['네 안녕하세요.', '반갑습니다.']# Kkma는 나는 =&gt; '날'로 제대로 토큰화가 되는걸 확인할 수 있다.pprint(kkma.pos(u\"하늘을 나는 자동차\")) # 품사: [('하늘', 'NNG'), ('을', 'JKO'), ('날', 'VV'), ('는', 'ETD'), ('자동차', 'NNG')]print(han.analyze(u\"아버지가 방에 들어가신다. 안녕하세요. 하늘을 나는 자동차\")): [[[('아버지', 'ncn'), ('가', 'jcc')], [('아버지', 'ncn'), ('가', 'jcs')]], [[('방', 'nbu'), ('에', 'jca')], [('방', 'ncn'), ('에','jca')]], [[('들', 'pvg'), ('어', 'ecx'), ('가', 'px'), ('시', 'ep'), ('ㄴ다', 'ef')], [('듣', 'pvg'), ('어', 'ecx'), ('가', 'px'),('시', 'ep'), ('ㄴ다', 'ef')], [('들어가', 'pvg'), ('시', 'ep'), ('ㄴ다', 'ef')]], [[('.', 'sf')], [('.', 'sy')]], [], [[('안녕','ncps'), ('하세', 'ncpa'), ('요', 'ncn')], [('안녕', 'ncps'), ('하', 'xsms'), ('세요', 'ef')], [('안녕', 'ncps'), ('하', 'xsms'), ('세','ef'), ('요', 'jxf')]], [[('.', 'sf')], [('.', 'sy')]], [], [[('하늘', 'ncn'), ('을', 'jco')]], [[('나', 'ncn'), ('는', 'jxc')], [('나','npp'), ('는', 'jxc')], [('나', 'pvg'), ('는', 'etm')], [('나', 'px'), ('는', 'etm')], [('나', 'pvg'), ('아', 'ecs'), ('는', 'jxc')[('나', 'pvg'), ('아', 'ef'), ('는', 'etm')], [('나', 'px'), ('아', 'ecs'), ('는', 'jxc')], [('나', 'px'), ('아', 'ef'), ('는', 'etm')],[('날', 'pvg'), ('는', 'etm')]], [[('자동차', 'ncn')], [('자동', 'ncn'), ('차', 'ncn')]]]print(han.morphs(u\"아버지가 방에 들어가신다. 안녕하세요. 하늘을 나는 자동차\")) # 형태소 분석: ['아버지', '가', '방', '에', '들', '어', '가', '시ㄴ다', '.', '안녕', '하', '세', '요', '.', '하늘', '을', '나', '는', '자동차']print(kom.pos(u\"아버지가 방에 들어가신다. 안녕하세요. 하늘을 나는 자동차\")): [('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('시', 'EP'), ('ㄴ다', 'EF'), ('.', 'SF'), ('안녕세요', 'NNP'), ('.', 'SF'), ('하늘', 'NNG'), ('을', 'JKO'), ('나', 'NP'), ('는', 'JX'), ('자동차', 'NNG')]# 파일을 읽어와 Corpus를 만드는 함수def read_data(filename, encoding): data = [] with open(filename, encoding=encoding) as f: data = [line.split('\\t') for line in f.read().splitlines()] data = data[1:] return data# train_data와 test_data를 나누어 준다. (train, test data가 서로 분리 되어 저장 되어 있었음) train_data = read_data(\"ratings_train.txt\", 'utf-8')test_data = read_data(\"ratings_test.txt\", 'utf-8') import jsonimport os# 데이터가 너무 많아 만개 데이터만 학습 시키기 위해 데이터 split.train_data = train_data[:10000]test_data = test_data[:1000]# 토큰화 함수 (토큰과 품사 정보 합치기)def tokenize(doc): return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]# json file 형태로 저장 이미 있으면 불러와 train_docs, test_docs 변수에 저장if os.path.isfile(\"train_docs.json\"): with open(\"train_docs.json\", encoding='utf-8') as f: train_docs = json.load(f) with open(\"test_docs.json\", encoding='utf-8') as f: test_docs = json.load(f)else: train_docs = [(tokenize(row[1]), row[2]) for row in train_data] test_docs = [(tokenize(row[1]), row[2]) for row in test_data] with open(\"train_docs.json\", 'w', encoding='utf-8') as make_file: json.dump(train_docs, make_file, ensure_ascii=False, indent='\\t') with open(\"test_docs.json\", 'w', encoding='utf-8') as make_file: json.dump(test_docs, make_file, ensure_ascii=False, indent='\\t')train_docs[0]: [['아/Exclamation', '더빙/Noun', '../Punctuation', '진짜/Noun', '짜증나다/Adjective', '목소리/Noun'], '0']tokens = [t for d in train_docs for t in d[0]]tokens[0]: '아/Exclamation'import nltktext = nltk.Text(tokens, name='NMSC') # 문서를 편리하게 탐색할 수 있는 기능을 제공text.vocab().most_common(10): [('./Punctuation', 4791), ('영화/Noun', 3368), ('하다/Verb', 2829), ('이/Josa', 2624), ('보다/Verb', 2576), ('의/Josa', 2123), ('../Punctuation', 1949), ('가/Josa', 1789), ('에/Josa', 1771), ('을/Josa', 1587)]# bag of words 만들기selected_words = [f[0] for f in text.vocab().most_common(10000)] # 문서마다 bag of words에 포함된 단어가 있는지 카운트 해주는 함수def term_frequency(doc): return [doc.count(word) for word in selected_words]# 학습 시킬 수 있는 형태의 train, test corpus 만들기train_x = [term_frequency(d) for d, _ in train_docs]train_y = [c for _, c in train_docs]test_x = [term_frequency(d) for d, _ in test_docs]train_y = [c for _, c in train_docs]import numpy as npx_train = np.asarray(train_x).astype('float32')x_test = np.asarray(test_x).astype('float32')y_train = np.asarray(train_y).astype('float32')y_test = np.asarray(test_y).astype('float32')# 모델 만들기from tensorflow.keras import models, layers, optimizers, losses, metricsmodel = models.Sequential()model.add(layers.Dense(64, 'relu', 10000))model.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(1, activation='sigmoid'))model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])model.fit(x_train, y_train, epochs=10, batch_size=512)results = model.evaluate(x_test, y_test): 1000/1000 [==============================] - 0s 114us/sample - loss: 0.7367 - binary_accuracy: 0.7940# 리뷰 긍정/부정 추측하는 함수 def predict_pos_neg(review): token=tokenize(review) tf = term_frequency(token) data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0) score = float(model.predict(data)) if(score &gt; 0.5): print(\"[&#123;&#125;]는 &#123;:.2f&#125;% 확률로 긍정 리뷰이지 않을까 추측해봅니다.^^\\n\".format(review,score*100)) else: print(\"[&#123;&#125;]는 &#123;:.2f&#125;% 확률로 부정 리뷰이지 않을까 추측해봅니다.^^\\n\".format(review,(1-score)*100))# 예측 predict_pos_neg(\"올해 최고의 영화! 세번 넘게 봐도 질리지가 않네요.\"): [올해 최고의 영화! 세번 넘게 봐도 질리지가 않네요.]는 99.99% 확률로 긍정 리뷰이지 않을까 추측해봅니다.^^predict_pos_neg('노잼'): [노잼]는 96.37% 확률로 부정 리뷰이지 않을까 추측해봅니다.^^predict_pos_neg(\"대박 재미있음\"): [대박 재미있음]는 98.86% 확률로 긍정 리뷰이지 않을까 추측해봅니다.^^predict_pos_neg(\"대박 재미없음\"): [대박 재미없음]는 73.68% 확률로 부정 리뷰이지 않을까 추측해봅니다.^^# 예측이 잘 되지 않는 문장predict_pos_neg(\"음악이 몰입에 방해가 됩니다\"): [음악이 몰입에 방해가 됩니다]는 54.90% 확률로 긍정 리뷰이지 않을까 추측해봅니다.^^# 다시 학습하고 나서 예측이 바뀜predict_pos_neg(\"음악이 몰입에 방해가 됩니다\"): [음악이 몰입에 방해가 됩니다]는 58.53% 확률로 부정 리뷰이지 않을까 추측해봅니다.^^ 궁금한점1234567891. 다양한 문장을 학습하지 않았거나 신조어로 이루어진 문장으로 예측하려 할때는 처음 본 문장에 대해서는 어떻게 예측을 하는 걸까?# nlp외에 궁금한점 2. iris 데이터로 모델을 만들었을 때 iris에서 나올수 없는 관측치를 대입해도 output 결과로 어떠한 꽃일 것이라 예측을 하는 경우가 있는데 라벨이 유한개인 classification인 경우에 한해 절대 나올 수 없는 아웃라이어 관측치는 예외처리를 해줘야 하는 것인가? 아니면 학습한 모델이 알아서 정해진 라벨중에 그나마 근접한 정답으로 정확도가 낮음에도 output을 주는 것인가..?","categories":[{"name":"AI","slug":"AI","permalink":"http://jungjihyuk.github.io/categories/AI/"},{"name":"Natural Language Processing","slug":"AI/Natural-Language-Processing","permalink":"http://jungjihyuk.github.io/categories/AI/Natural-Language-Processing/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://jungjihyuk.github.io/tags/NLP/"},{"name":"자연어 처리","slug":"자연어-처리","permalink":"http://jungjihyuk.github.io/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/"}]},{"title":"Data Collection","slug":"data-collection","date":"2019-07-14T15:00:00.000Z","updated":"2020-02-24T15:40:32.147Z","comments":true,"path":"2019/07/15/data-collection/","link":"","permalink":"http://jungjihyuk.github.io/2019/07/15/data-collection/","excerpt":"Data mining, crawling, scraping","text":"Data Collection 데이터 수집은 왜 하는 걸까?? 123456789104차 산업혁명 시대를 사는 현대인들 중 Big Data에 관한 존재를 모르는 사람은 없을 것이다Big Data는 방대한 데이터고 그 많은 데이터로 뭐 어떻게 해보려는 시도가 있다는 건 알겠는데도대체 그 Big Data라는 것으로 뭘 하는 걸까?마냥 많은 데이터라는 것에서 그쳤으면 Big Data가 이슈가 되지 않았을 것이다Big Data라는 엄청난 데이터 속에서 사람의 인지 능력으로는 분석하기 힘든 양을한꺼번에 컴퓨터라는 도구로 분석을 해보니 사람보다 연산도 빠르고 분석 성능이 좋았던 것이다따라서 Big Data(Data warehouse)를 수집해서 숨겨진 의미 있는 정보를 추출하고문제를 해결하는 것이 화두가 된 것이다 Data 수집 종류1231. 공공데이터(api, file)2. Portal site ( ex) google, naver, daum..)3. 그 외 Files, Databases 공공 데이터 api나 file 그리고 dataset(file)은 데이터를 수집하는 절차가 복잡하거나 수집해서 처리하는 작업이 번거롭거나 힘들지 않다 그런데 Portal site에서 데이터를 수집하기 위해서는 제법 까다로운 작업이 필요하다 Web Crawling은 불법? 결론적으로 말해서 모든 Crawling, Scraping은 불법이 아니다. 하지만 대부분 불법이므로 주의 해야 한다 어떤 것이 합법인가?Opt-in vs Opt-out1234Opt-in : 정보 수집에 대해 동의를 얻고나서 수집하는 경우 (whitelist)Opt-out : 처음에 정보 제공자에 대해 동의를 얻지 않고 당사자의 거부 의사를 밝혔을 때 정보 수집 중단을 하는 경우 (blacklist) Crawling하는 입장에서는 Opt-out 방법으로 정보를 수집한다따라서 해당 사이트에서 robots.txt에 명시적으로 거부하지 않은 경우, 메인페이지 하단에 crawling 금지 표시가 없는 경우만 정보 수집이 가능하다. Data from Portal site(Web Data) Web으로부터 데이터를 수집하겠다고 마음 먹은 순간 해야할 작업들이 많다 Crawling부터 DB 저장까지 Flow사진 출처: 논문[RCrawler: An R package for parallel web crawling and scraping -Salim Khalil, Mohamed Fakir] 1234Data 수집원 OK? ⇒ Dynamic HTML ⇒ Focused? ⇒ Selenium + Crawling + url check ⇒ Scraping &#x3D;&gt; DB BFS? ⇒ Selenium + Crawling ⇒ Scraping ⇒ DB HTML ⇒ Focused? ⇒ Crawling + url check ⇒ Scraping ⇒ DB BFS? ⇒ Crawling ⇒ Scraping ⇒ DB 데이터를 가져오려면 Web page 구성을 알아야 한다! HTML, CSS, JavaScript등 웹 페이지 구성이 어떻게 되는지 공부해야 한다 사이트 마다 웹 페이지 구성이 다르기 때문에 웹에 대한 이해 없이 무작정 하면 데이터 수집이 안되는 경우를 발견하게 될 것이다 12345678910어떠한 웹 페이지는 요청한 부분만 동적으로 페이지 리로딩 없이 데이터를 가져 와서request url을 확인하기 어려운 경우가 있다.위 그림에 SPA Lifecycle이 그러한 경우 인데,사용자가 직접 클릭을 해야만 데이터를 확인 할 수 페이지라면처음에 요청했던 페이지에는 포함되어 있지 않고 클릭 한 순간dom객체가 추가 되기 때문에 실시간으로 개발자 도구에서 network 부분을 살피지 않는다면절대 숨겨진 데이터를 가져올 수 없을 것이다.따라서 어떠한 웹 페이지 인지에 따라 셀레늄같은 automation framework를 사용할지 말지 결정해야 한다. 잘 모른다면 참고하자 =&gt; Object Model 웹 문서 중 어디서부터 어디까지 찾을 껀데? 수집 범위는 정했니? 지금부터는 Crawling 기법으로 Hyperlink fetch를 반복해서 페이지 사이 link 구조를 알아내야 한다 그 다음 depth를 설정해서 어디까지 crawling 할 것인가를 정하고 focused crawling으로 crawling하는 페이지를 한정 할 것인지 아니면 페이지를 넘나들며 끊임없이 확장할 것인지도 정해야 한다 (목적에 맞게) 이러한 경우를 DFS(Depth First Search)와 BFS(Breadth First Search)라고 한다 Crawling해서 많은 url은 확보 했는데 어떤 url에 유용한 정보가 있는지 아니? url만으로 정보의 유용성을 판단할 수는 없다 따라서 crawling 해서 database에 저장할때 page rank 개념을 활용하여 저장하는 것이 효율적이다 page rank개념은 페이지 참조횟수가 많으면 그만큼 영향력 있고, 가치가 있는 데이터를 포함한 페이지라 간주한다 결국 page rank가 높은 순으로 url을 분류하고 그 url로 부터 data를 수집 하면 된다 단, page rank가 높다고 나한테 필요한 데이터라는 보장은 없다.그래서 데이터 추출후 전처리, 패턴 분석 등 여러가지 처리 후 데이터를 사용해야 한다. Crawling 공부하러가기 유용한 page url을 알아 냈으니 내가 원하는 data를 수집하자 scraping Scraping 공부하러가기 Data miningData mining 출처: incodom Crawling vs Scraping 사진출처: prowebscraping CrawlingBFS Crawling google 박보영 검색 결과 crawling 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657headers = &#123;\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36\"&#125; # 브라우저에서 직접 request보내는 것처럼 흉내내기 위한 header 초기화import time, requestsfrom bs4 import BeautifulSoupdef download(method, url, param=None, data=None, timeout=1, maxretries=3, headers = headers): try: resp = requests.request(method, url, params = param, data = data, headers = headers) # request요청에 대한 response resp.raise_for_status() # 에러 강제하기 except requests.exceptions.HTTPError as e: # 에러 처리 if (500 &lt;= e.response.status_code &lt; 600 and maxretries &gt;0): print(maxretries) time.sleep(timeout) resp=download3(method, url, param, data, timeout, maxretries-1) else: print(e.response.status_code) print(e.response.reason) return respdef parseURL(seed): # download함수와 BeautifulSoup을 이용해 URL parsing 하는 함수 html = download(\"get\", seed) dom = BeautifulSoup(html.text, 'lxml') return [requests.compat.urljoin(seed, _[\"href\"]) for _ in dom.find_all(\"a\") if _.has_attr(\"href\") and len(_[\"href\"]) &gt; 3]url = \"https://www.google.com/search\"html = download(\"get\", url, param = &#123;\"q\":\"박보영\"&#125;)dom = BeautifulSoup(html.text, 'lxml')queue = list()queue.extend([_.find_parent()['href'] for _ in dom.select(\".LC20lb\")]) # 초기 seed값 추가seen = list()while queue: baseURL = queue.pop(0) # queue는 선입 선출 방식이기 때문에 index 가장 앞 0을 꺼낸다 seen.append(baseURL) # 한번 꺼낸 url은 재방문 하지 않도록 seen list에 추가 time.sleep(5) # 빈번한 request로 block 당하는 일 방지하기 위해 시간 끌기 linkList = parseURL(baseURL) # parsing한 url list에 추가 for link in linkList: # 추가된 url을 하나씩 뽑아 queue에 없거나 seen에 없으면 queue에 추가한다 if link not in queue and link not in seen: queue.append(link) print(\"Queue: &#123;0&#125;, Seen: &#123;1&#125;\".format(len(queue), len(seen))):Queue: 862, Seen: 1Queue: 1291, Seen: 2Queue: 2259, Seen: 3Queue: 2381, Seen: 4Queue: 2416, Seen: 5Queue: 2426, Seen: 6.......... DFS Crawling(Focused Crawling) naver에 박보영 검색 후 블로그 url parsing 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import requests, downloaddef checkBlog(url): return requests.compat.urlparse(url)[1] == \"blog.naver.com\"def parseURL(seed): html = download.download(\"get\", seed) dom = download.BeautifulSoup(html.text, 'lxml') if len(dom.select(\"#mainFrame\")) &lt; 1: return [] seed = requests.compat.urljoin(seed, dom.select(\"#mainFrame\")[0][\"src\"]) html = download.download(\"get\", seed) dom = download.BeautifulSoup(html.text, 'lxml')# print(requests.compat.urljoin(seed, dom.select(\"#mainFrame\")[0]['src'])) return [requests.compat.urljoin(seed, _[\"href\"]) for _ in dom.find_all(\"a\") if _.has_attr(\"href\") and len(_[\"href\"]) &gt; 3 and checkBlog(requests.compat.urljoin(seed, _['href']))]url = \"https://search.naver.com/search.naver\"html = download.download(\"get\", url, param = &#123;\"query\":\"박보영\"&#125;)dom = download.BeautifulSoup(html.text, 'lxml')queue = list()queue.extend([_['href'] for _ in dom.select(\"a.sh_blog_title._sp_each_url._sp_each_title\") if checkBlog(_['href'])])seen = list()while queue: baseURL = queue.pop(0) seen.append(baseURL) download.time.sleep(0.5) linkList = parseURL(baseURL) for link in linkList: if link not in queue and link not in seen: queue.append(link) print(\"Queue: &#123;0&#125;, Seen: &#123;1&#125;\".format(len(queue), len(seen))):Queue: 17, Seen: 1Queue: 32, Seen: 2Queue: 48, Seen: 3Queue: 47, Seen: 4Queue: 46, Seen: 5Queue: 45, Seen: 6Queue: 44, Seen: 7Queue: 43, Seen: 8........ crawling 출처: prowebscraping &nbsp; quora &nbsp; tistory 논문: [RCrawler: An R package for parallel web crawling and scraping -Salim Khalil, Mohamed Fakir] Crawling 한 url DB에 저장하기123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import sqlite3, requests, downloadcon = sqlite3.connect(\"bot.db\")cur = con.cursor()cur.executescript(''' DROP TABLE IF EXISTS table1; CREATE TABLE table1( id INTEGER PRIMARY KEY AUTOINCREMENT, table2_id INTEGER NOT NULL, path TEXT NOT NULL, param TEXT, depth INTEGER NOT NULL, inbound INTEGER NOT NULL, seen BOOLEAN DEFAULT FALSE NOT NULL, date TIMESTAMP DEFAUlT CURRENT_TIMESTAMP NOT NULL ); DROP TABLE IF EXISTS table2; CREATE TABLE table2( id INTEGER PRIMARY KEY AUTOINCREMENT, netloc TEXT NOT NULL, date TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL );''')url = \"https://www.google.com/search\"html = download.download(\"get\", url, param = &#123;\"q\": \"박보영\"&#125;)dom = download.BeautifulSoup(html.text, \"lxml\")def parseURL(seed): html = download.download(\"get\", seed) dom = download.BeautifulSoup(html.text, 'lxml') return [requests.compat.urljoin(seed, _[\"href\"]) for _ in dom.find_all(\"a\") if _.has_attr(\"href\") and len(_[\"href\"]) &gt; 3]for href in [_.find_parent()[\"href\"] for _ in dom.select(\".LC20lb\")]: _urlparse = requests.compat.urlparse(href) netloc = \"://\".join(_urlparse[:2]) cur.execute(\"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1\", [netloc]) #netloc을 시퀀스로 만들어서 넘겨줘야함 netlocID = cur.fetchone() if not netlocID: cur.execute(\"INSERT INTO table2(netloc) VALUES(?)\", [netloc]) con.commit() cur.execute(\"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1\", [netloc]) netlocID = cur.fetchone() cur.execute(\"INSERT INTO table1(table2_id, path, param, depth, inbound) VALUES(?, ?, ?, ?, ?)\",[netlocID[0], _urlparse[2], _urlparse[4], 1, 0]) con.commit() print(cur.lastrowid, netlocID)i = 0while True: cur.execute(''' SELECT table1.id, table2.netloc, table1.path, table1.param, table1.depth, table2.id FROM table1 JOIN table2 ON table1.table2_id=table2.id WHERE table1.seen = FALSE and table1.depth &lt; 3 ORDER BY table1.date ASC LIMIT 0, 1; ''') seed = cur.fetchone() if not seed or i &gt; 1000: break i += 1 cur .execute(''' UPDATE table1 SET seen = TRUE WHERE id = ? ''', [seed[0]]) con.commit() baseURL= \"&#123;0&#125;&#123;1&#125;?&#123;2&#125;\".format(seed[1],seed[2],seed[3]) for url in parseURL(baseURL): for href in [_.find_parent()[\"href\"] for _ in dom.select(\".LC20lb\")]: _urlparse = requests.compat.urlparse(href) netloc = \"://\".join(_urlparse[:2]) cur.execute(\"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1\", [netloc]) #netloc을 시퀀스로 만들어서 넘겨줘야함 netlocID = cur.fetchone() if not netlocID: cur.execute(\"INSERT INTO table2(netloc) VALUES(?)\", [netloc]) con.commit() cur.execute(\"SELECT id FROM table2 WHERE netloc=? LIMIT 0,1\", [netloc]) netlocID = cur.fetchone() cur.execute(\"INSERT INTO table1(table2_id, path, param, depth, inbound) VALUES(?, ?, ?, ?, ?)\",[netlocID[0], _urlparse[2], _urlparse[4], seed[4]+1, seed[5]]) con.commit()# break Scraping Crawling한 url로 부터 내가 원하는 데이터를 수집하는 것을 말한다 Naver news 본문 scraping 예제 (Dynamic HTML X)12345678910111213141516171819202122232425262728293031323334353637383940414243from selenium import webdriverfrom bs4 import BeautifulSoupimport downloaddriver = webdriver.Chrome(\"크롬드라이버 경로\")driver.get(\"https://news.naver.com/\")dom = BeautifulSoup(driver.page_source, 'lxml')# crawling으로 url 확보 했다고 가정urls=[x['href'] for x in dom.select(\"#main_content a\") if len(x['href']) &gt; 7 and 'read' in x['href']][7:]def parseContent(url): # crawling한 url을 인자로 전달하면 제목, 본문내용 parsing html = download.download(\"get\", url) dom = download.BeautifulSoup(html.text, 'lxml') return &#123;\"title\": dom.select_one(\"#articleTitle\").text.strip(), \"body\": dom.select_one(\"#articleBodyContents\").text.strip() &#125;contents = list()while urls: # urls안에 있는 url이 없을때 까지 계속 parsing baseURL = urls.pop(0) contents.append(parseContent(baseURL)) import sqlite3con = sqlite3.connect(\"news.db\")cur = con.cursor()cur.execute(\"\"\" CREATE TABLE news( title TEXT NOT NULL, content TEXT NOT NULL );\"\"\")while contents: # parsing한 data DB에 저장하기 content=contents.pop(0) cur.execute(\"\"\" INSERT INTO news (title, content) VALUES(?, ?) \"\"\", [content['title'], content['body']]) con.commit() Selenium Web Browser Automation 단점 page rendering중에는 dom객체에 접근하지 못하고 에러가 날 수 있다. 그래서 time sleep으로 시간을 부여하여 에러 발생 가능성을 줄이고 에러 핸들링이 필요하다. 결국 selenium을 활용하면 오히려 시간이 오래걸릴 수 있다.{: .notice} Dynamic HTML Scraping 예제12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879from selenium import webdriverdriver = webdriver.Chrome(\"chromedriver.exe 경로\") # driver를 생성하면 chrome 브라우저 창 생성def html_parser(url): driver.get(url) time.sleep(1) html = driver.page_source dom = BeautifulSoup(html, 'lxml') resp=dom.select('#main') return respdef search(url, country): driver.get(url) inputTag = driver.find_element_by_css_selector(\"#search_term\") inputTag.send_keys(country) driver.find_element_by_css_selector(\"#search\").click() time.sleep(1) html = driver.page_source dom = BeautifulSoup(html, 'lxml') return [requests.compat.urljoin(url, _['href']) for _ in dom.select(\"#results a\")]nation = search(\"http://example.webscraping.com/places/default/search\", \"korea\")result = []while nation: baseURL = nation.pop(0) dom=html_parser(baseURL) result.append(dom[0].text)for x in result: print(x):National Flag:Area: 120,540 square kilometresPopulation: 22,912,177Iso: KPCountry: North KoreaCapital: PyongyangContinent: ASTld: .kpCurrency Code: KPWCurrency Name: WonPhone: 850Postal Code Format: ###-###Postal Code Regex: ^(\\d&#123;6&#125;)$Languages: ko-KPNeighbours: CN KR RUEditNational Flag:Area: 98,480 square kilometresPopulation: 48,422,644Iso: KRCountry: South KoreaCapital: SeoulContinent: ASTld: .krCurrency Code: KRWCurrency Name: WonPhone: 82Postal Code Format: SEOUL ###-###Postal Code Regex: ^(?:SEOUL)*(\\d&#123;6&#125;)$Languages: ko-KR,enNeighbours: KPEditdriver.close() # 브라우저 창 닫기 Page RankPage Rank 참고: sungmooncho","categories":[{"name":"AI","slug":"AI","permalink":"http://jungjihyuk.github.io/categories/AI/"},{"name":"Data Analysis","slug":"AI/Data-Analysis","permalink":"http://jungjihyuk.github.io/categories/AI/Data-Analysis/"}],"tags":[{"name":"data mining","slug":"data-mining","permalink":"http://jungjihyuk.github.io/tags/data-mining/"},{"name":"crawling","slug":"crawling","permalink":"http://jungjihyuk.github.io/tags/crawling/"},{"name":"scraping","slug":"scraping","permalink":"http://jungjihyuk.github.io/tags/scraping/"},{"name":"page rank","slug":"page-rank","permalink":"http://jungjihyuk.github.io/tags/page-rank/"}]},{"title":"Object Model","slug":"objectModel","date":"2019-07-12T15:00:00.000Z","updated":"2020-02-24T15:43:01.461Z","comments":true,"path":"2019/07/13/objectModel/","link":"","permalink":"http://jungjihyuk.github.io/2019/07/13/objectModel/","excerpt":"object model로 웹 브라우저 이해하기","text":"Object Model 웹 브라우저의 구성요소를 객체화시켜 객체처럼 사용할 수 있도록 하는 것 브라우저에 렌더링되는 HTML문서는 정적인 문서인데, 정적인 요소를 동적으로 제어하기 위한 객체화 방법javscript로 제어할 수 있는 객체 형태로 만들어 준다 Window는 전역 객체이면서, 모든 객체가 소속된 객체(최상위 객체?)Document, navigator, object 등은 window의 Property이면서 각각 객체로서 역할을 한다 object model 출처: tistory1, &nbsp; tistory2, &nbsp; youtube Window전역 객체123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;script&gt; a = 1; # window 객체의 property, 전역변수, 함수에 소속되지 않은 변수 var b = 2; alert('Hello world'); # window 객체의 메소드 window.alert('Hello world');&lt;/script&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; Document Document 객체는 웹 페이지 그 자체를 의미 웹 페이지에 존재하는 HTML요소에 접근하고자 할 때는 DOM으로 만들어야 한다 Document 메소드12341. HTML 요소 선택2. HTML 요소 생성3. HTML 이벤트 핸들러 추가4. HTML 객체 선택 HTML 요소 선택 HTML 요소 생성 HTML 이벤트 핸들러 추가 HTML 객체 선택 사진 출처: tcpschool Property vs Attribute vs Variable자바스크립트에서 Property와 Variable123Property : 인스턴스로부터 만들어진 변수, 인스턴스에 종속된 변수Variable : 인스턴스와 상관없이 만들어진 변수 예제로 알아보자1234567891011121314151617181920212223&lt;script type=\"text/javascript\"&gt; var setMyName = function(value)&#123; this.name = value; &#125; var setMyName2 = function(value)&#123; var name = value; &#125; var setName = new setMyName(\"jihyuk\"); # setName 인스턴스 var setName2 = new setMyName2(\"jihyuk2\"); # setName2 인스턴스 console.log(setName); # Property를 포함함한 객체 console.log(typeof(setName)); # setName 인스턴스는 object를 반환한다 console.log(setName.name); # Property 값 출력 console.log(typeof(setName.name)); console.log(setName2); # Property를 포함하지 않은 객체 console.log(typeof(setName2)); console.log(setName2.name); # Property가 없다 console.log(typeof(setName2.name));&lt;/script&gt; Html과 Dom에서 Attribute와 Property123Attribute: HTML관점에서 선택자Property: DOM관점에서 선택자 예제로 알아보자1234567891011121314# HTML 관점&lt;div class=\"name\"&gt;ji hyuk&lt;/div&gt;# 태그 div는 Element# class는 attribute# name은 값# ji hyuk은 data# DOM 관점# 태그 div는 Element# class는 property# name은 값# ji hyuk은 data Attribute vs Property: MediumVariable vs Property: blog DOM Document Object Model의 약자로 객체 지향 모델로써 구조화된 문서를 표현하는 형식이다. Html, xml 같은 문서를 객체형태로 바꾸어 객체로써 이용하기 위한 형태이다. DOM은 플랫폼/언어 중립적으로 구조화된 문서를 표현하는 W3C의 공식 표준이기 때문에 문서를 객체로써 쓴다면 DOM 형식을 사용해야한다. DOM은 HTML문서의 모든 요소에 접근하는 방법을 정의한 API이기도 하다.DOM은 넓은 의미로 웹 브라우저가 HTML 페이지를 인식하는 방식으로 볼 수 있고좁은 의미로는 document 객체와 관련된 객체의 집합으로 볼 수 있다. 등장 배경123DOM은 HTML 문서의 요소를 제어하기 위해 웹 브라우저에서 처음 지원되었다. 브라우저가 다양해지면서 브라우저 사이에 DOM 구현이 호환되지 않음에 따라,W3C에서 DOM 표준 규격을 작성하게 되었다. DOM 출처: tistory, &nbsp; wiki CCSOM","categories":[{"name":"Web","slug":"Web","permalink":"http://jungjihyuk.github.io/categories/Web/"},{"name":"Object Model","slug":"Web/Object-Model","permalink":"http://jungjihyuk.github.io/categories/Web/Object-Model/"}],"tags":[{"name":"object model","slug":"object-model","permalink":"http://jungjihyuk.github.io/tags/object-model/"},{"name":"dom","slug":"dom","permalink":"http://jungjihyuk.github.io/tags/dom/"},{"name":"bom","slug":"bom","permalink":"http://jungjihyuk.github.io/tags/bom/"},{"name":"javascript","slug":"javascript","permalink":"http://jungjihyuk.github.io/tags/javascript/"}]},{"title":"XML & JSON","slug":"xmlandjson","date":"2019-07-09T15:00:00.000Z","updated":"2020-02-24T15:43:43.171Z","comments":true,"path":"2019/07/10/xmlandjson/","link":"","permalink":"http://jungjihyuk.github.io/2019/07/10/xmlandjson/","excerpt":"XML과 JSON에 대한 이해 그리고 오픈 api 불러오기","text":"Markup Language 태그 등을 이용하여 문서나 데이터의 구조를 명기하는 언어의 한가지 이다. 123마크업 언어를 사용하여 데이터를 기술하면컴퓨터도 이해하고 사람도 이해할 수 있는 방식으로 문서를 정의하고 데이터를 구조화 할 수 있다.데이터를 문서화, 구조화 할 뿐만아니라 그 문서를 컴퓨터 화면에 보여줄 수도 있다. XMLXML 이란? Extensible Markup Language의 약자로 W3C에서 개발된 다목적 마크업 언어이다. XML은 데이터를 전달하고 저장하는 목적으로 만들어졌다. XML 등장 배경123정부나 항공우주 기업의 대규모 계획 사업에서 기계 판독형 문서를 공유할 목적으로SGML(Standard Generalized Markup Language)라는 마크업 언어가 있었는데,사용하기에 너무 복잡하고 HTML의 한계를 극복하기 위해 XML이 탄생했다. XML의 특징1234567891011121314151617181. 데이터의 표현이 자유롭다- XML은 데이터에 의미를 부여하는 메타데이터를 기술 할 수 있다2. 데이터의 확장성이 뛰어나다3. 유효성 체크를 한다는 점이 엄청난 장점이다.- Valid XML과 Well formed XML는 서로 다르다- ex) &lt;?xml ~&gt;으로 시작하면 XML문서로서 가능하지만 가능하다고 해서- 모두 well formed xml은 아닐 수 있다 (well formed 조건에 부합하지 않는 것이 하나라도 있을때)4. 텍스트(Unicode) 기반으로 작성되어 읽기 쉽다5. Well-formed Documents- root element를 가져야한다- closing tag가 있어야 한다- tag는 대소문자에 민감하다- ex) &lt;body&gt;body&lt;&#x2F;Body&gt; (X) &lt;body&gt;body&lt;&#x2F;body&gt; (O)- tag는 적절하게 감싸야 한다- ex) html에서는 tag의 시작점과 끝점이 명확하지 않아도 상관없지만- xml은 정확하게 명시해야 한다. &lt;b&gt;&lt;i&gt;Hello&lt;&#x2F;b&gt;&lt;&#x2F;i&gt; &#x3D;&gt; HTML에서는 가능 , XML에서는 불가능- attribute 값은 쌍 따옴표로 감싸야 한다- ex) &lt;note date&#x3D; 19&#x2F;7&#x2F;10&gt;&lt;&#x2F;note&gt; (X) &lt;note date&#x3D; &quot;19&#x2F;7&#x2F;10&quot;&gt;&lt;&#x2F;note&gt; (O) HTML vs XMLHTML은 데이터를 표현하는 것에 초점을 두고 XML은 데이터를 구조화 하고 전달하는 것에 초점이 맞춰저 있다. XML 구성 요소123456789101112131. XML declaration2. DTD(Document type declaration)- DTD를 사용하면 어떤 문서의 종류인지 확인이 가능하고- 해당 문서의 규칙을 따를 수 있도록 유효성 검사를 작동하게 된다.3. Root Element start tag, end tag4. Comment5. Elements6. Characters7. Attributes8. Entity9. XML Schema- namespaces, data types 지원- XML 문법 준수 XML Schema1234567891011121314&lt;?xml version=\"1.0\"?&gt;&lt;xs:schema xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"&gt;&lt;xs:element name=\"note\"&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=\"to\" type=\"xs:string\"/&gt; &lt;xs:element name=\"to\" type=\"xs:string\"/&gt; &lt;xs:element name=\"to\" type=\"xs:string\"/&gt; &lt;/xs:sequence&gt; &lt;xs:complexType&gt;&lt;/xs:element&gt;&lt;/xs:schema&gt; &lt;!-- xs는 namespace --&gt; XML Tree XML vs LXMLLXML XML보다 속도가 빠르고 자주 쓰는 방법 예제12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152from lxml import etreebookStore = etree.Element(\"bookstore\")book1 = etree.SubElement(bookStore, \"book\")book2 = etree.SubElement(bookStore, \"book\", attrib=&#123;\"category\":\"children\"&#125;)book1.attrib[\"category\"] = \"cooking\"title1 = etree.Element(\"title\", lang=\"en\")title1.text = \"Everyday Italian\"book1.append(title1)etree.SubElement(book1, \"author\").text = \"Giada De Lausadlf\"etree.SubElement(book1, \"year\").text = \"2003\"etree.SubElement(book1, \"price\").text = \"40.3\"title2 = etree.Element(\"title\")title2.set(\"lang\", title1.get(\"lang\"))title2.text = \"Harry Potter\"book2.append(title2)etree.SubElement(book2, \"author\").text = \"Giada De Lausadlf\"etree.SubElement(book2, \"year\").text = \"2003\"etree.SubElement(book2, \"price\").text = \"40.3\"xmlBytes = etree.tostring(bookStore, encoding=\"UTF-8\", pretty_print=True, xml_declaration=True)xmlstr = etree.tounicode(bookStore, pretty_print=True)etree.dump(bookStore):&lt;bookstore&gt; &lt;book category=\"cooking\"&gt; &lt;title lang=\"en\"&gt;Everyday Italian&lt;/title&gt; &lt;author&gt;Giada De Lausadlf&lt;/author&gt; &lt;year&gt;2003&lt;/year&gt; &lt;price&gt;40.3&lt;/price&gt; &lt;/book&gt; &lt;book category=\"children\"&gt; &lt;title lang=\"en\"&gt;Harry Potter&lt;/title&gt; &lt;author&gt;Giada De Lausadlf&lt;/author&gt; &lt;year&gt;2003&lt;/year&gt; &lt;price&gt;40.3&lt;/price&gt; &lt;/book&gt;&lt;/bookstore&gt;xmlRoot = xmlTree.getroot()for childNode in xmlRoot: print(childNode.tag, childNode.attrib):book &#123;'category': 'cooking'&#125;book &#123;'category': 'children'&#125; 예제 (Write, Parse)12345678910111213141516171819202122232425262728# bookStore는 위 예제와 동일xml = etree.XML(etree.tostring(bookStore))xmlTree = etree.ElementTree(xml)xmlRoot = xmlTree.getroot()# xmlTree book_tree, book_root 이름의 xml 파일을 생성한다xmlTree.write(\"book_tree.xml\")etree.ElementTree(xmlRoot).write(\"book_root.xml\")getxmlTree = etree.parse(\"book_tree.xml\")xmlRoot = getxmlTree.getroot()etree.dump(xmlRoot):&lt;bookstore&gt; &lt;book category=\"cooking\"&gt; &lt;title lang=\"en\"&gt;Everyday Italian&lt;/title&gt; &lt;author&gt;Giada De Lausadlf&lt;/author&gt; &lt;year&gt;2003&lt;/year&gt; &lt;price&gt;40.3&lt;/price&gt; &lt;/book&gt; &lt;book category=\"children\"&gt; &lt;title lang=\"en\"&gt;Harry Potter&lt;/title&gt; &lt;author&gt;Giada De Lausadlf&lt;/author&gt; &lt;year&gt;2003&lt;/year&gt; &lt;price&gt;40.3&lt;/price&gt; &lt;/book&gt;&lt;/bookstore&gt; JSONJSON 이란? JavaScript Object Notation의 약자 JSON 등장 XML의 대안으로서 좀 더 쉽게 데이터를 교환하고 저장하기 위해 고안되었다. XML보다 가볍고 사용하기 편하다. 왜 json을 쓰는가? JSON의 특징장점12345671. javascript 객체 표기법을 따른다2. 사람과 기계 모두 읽기 편하다- XML보다 가독성이 뛰어나다3. 프로그래밍 언어와 운영체제에 독립적이다- 언어에 관계없이 통일된 데이터를 주고받을 수 있다4. 가볍다- XML보다 메모리가 효율적이다 단점12341. 문법 오류에 민감하다- 콤마가 누락되거나 중괄호가 잘못 닫히는 등 구두점에서 오타가 나면 전체 JSON 파일이 망가진다2. 주석을 지원하지 않는다3. 데이터 타입을 강제할 수 없다 (JSON Schema로 보완은 가능하지만 데이터 스스로 타입을 기술할 수 없다) XML vs JSON123456781. JSON은 종료 태그를 사용하지 않는다2. JSON의 구문은 XML 구문보다 짧다3. XML은 배열을 사용할 수 없지만, JSON은 배열을 사용할 수 있다4. XML은 XML 파서로 파싱되며, JSON은 자바스크립트 표준 함수인 eval() 함수로 파싱된다5. XML 문서는 XML DOM을 이용하여 문서에 접근하지만 JSON은 문자열을 전송 받은 후에 해당 문자열을 바로 파싱하므로, XML보다 더 빠른 처리 속도를 보여준다6. JSON은 전송받은 데이터의 무결성을 사용자가 직접 검증해야 하지만 XML은 스키마를 사용하여 무결성을 검증할 수 있다(JSON Schema로 보완 가능하긴 함) 출처: tcpschool JSON 구성 요소1231. 데이터는 이름과 값의 쌍으로 이루어진다2. Array (대괄호 [])3. Object (중괄호 &#123;&#125;) 데이터 타입1234561. Number2. String3. Boolean4. Object5. Array6. Null Stringify &amp; Parse Stringify는 JSON파일을 Serialize하고 Parse는 Deserialize한다 Stringify는 json객체를 string객체로 변환하고 parse는 string객체를 json 객체로 변환한다 예시12345678910111213141516&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt; var obj = &#123;name: \"jh\", \"age\": 25, \"car\": true&#125;; objstr = JSON.stringify(obj, function(k,v)&#123;if(v===23)return;else return v;&#125;); console.log(\"obj: \",obj); console.log(\"objstr1\", objstr); objstr = JSON.stringify(obj, null, 10/* ' ', '\\t' */); console.log(\"objstr2\", objstr); objbyte = JSON.parse(objstr); console.log(\"objbyte\",objbyte);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; Open API JSON형태로 불러오기12345678910111213141516171819202122232425262728293031323334353637383940import json, urlliburl = 'http://openapi.airkorea.or.kr/openapi/services/rest/ArpltnInforInqireSvc/getCtprvnRltmMesureDnsty'params = &#123; \"serviceKey\": \"rHPpLuWO16wWq7c2Z87Q8gwiZ7z6agbTuwvSDBpCEC7dqDXusPHYkC%2FVMq029DVkRJegegKOoUETTvYa82Dc2Q%3D%3D\", \"numOfRows\": 10, \"pageNo\": 1, \"startPage\": 1, \"sidoName\": \"인천\", \"dataTerm\": \"DAILY\", \"ver\":\"1.3\", \"_returnType\": \"JSON\"&#125;params[\"serviceKey\"] = urllib.parse.unquote(params[\"serviceKey\"])params = urllib.parse.urlencode(params)params = params.encode(\"UTF-8\")req = urllib.request.Request(url, data=params)res = urllib.request.urlopen(req)resStr = res.read()resStr = resStr.decode(\"UTF-8\")resObj = json.loads(resStr)resJSON = json.dumps(resObj, indent=\" \")x = resObj['list']for i in x: print(i['stationName'], i['pm25Value']):신흥 9송림 9구월동 2숭의 10석바위 31부평역 20부평 5연희 -검단 7계산 8 JSON Schema","categories":[{"name":"Language","slug":"Language","permalink":"http://jungjihyuk.github.io/categories/Language/"},{"name":"Markup Language","slug":"Language/Markup-Language","permalink":"http://jungjihyuk.github.io/categories/Language/Markup-Language/"}],"tags":[{"name":"xml","slug":"xml","permalink":"http://jungjihyuk.github.io/tags/xml/"},{"name":"json","slug":"json","permalink":"http://jungjihyuk.github.io/tags/json/"},{"name":"api","slug":"api","permalink":"http://jungjihyuk.github.io/tags/api/"}]},{"title":"객체지향의 사실과 오해 책으로 객체지향 이해하기","slug":"object","date":"2019-06-23T15:00:00.000Z","updated":"2020-02-24T15:42:54.235Z","comments":true,"path":"2019/06/24/object/","link":"","permalink":"http://jungjihyuk.github.io/2019/06/24/object/","excerpt":"객체지향 제대로 알자","text":"목차123456789101112131415161718191. 협력하는 객체들의 공동체- 역할, 책임, 협력- 객체지향의 본질2. 이상한 나라의 객체3. 타입과 추상화4. 역할, 책임, 협력- 협력- 책임- 역할- 객체지향 설계 기법5. 책임과 메시지- 메시지와 메서드- 객체 인터페이스- 인터페이스와 구현의 분리6. 객체 지도- 기능 설계 대 구조 설계7. 함께 모으기- 설계하고 구현하기- 추상화 기법 협력하는 객체들의 공동체","categories":[{"name":"Web","slug":"Web","permalink":"http://jungjihyuk.github.io/categories/Web/"},{"name":"Objectoriented","slug":"Web/Objectoriented","permalink":"http://jungjihyuk.github.io/categories/Web/Objectoriented/"}],"tags":[{"name":"object","slug":"object","permalink":"http://jungjihyuk.github.io/tags/object/"},{"name":"설계","slug":"설계","permalink":"http://jungjihyuk.github.io/tags/%EC%84%A4%EA%B3%84/"}]},{"title":"Flask","slug":"flask","date":"2019-05-17T15:00:00.000Z","updated":"2020-02-24T15:41:30.854Z","comments":true,"path":"2019/05/18/flask/","link":"","permalink":"http://jungjihyuk.github.io/2019/05/18/flask/","excerpt":"Flask로 파이썬 웹 프로그래밍하기 & 선박사님 멘토링 공부내용 정리","text":"2019-05-18 1st웹 World Wide Web의 줄임말로 인터넷 상에서 이루어지는 서비스 중 하나로써, 공유 목적으로 개발되었다 Web: naver blog HTTP 웹 상에서 정보를 주고받을 수 있는 프로토콜, 이때 정보는 보통 HTML문서나, 이미지, 영상 등을 포함합니다 HTTP: MDNHTTP란? : zerocho HTTP protocol 특징 Statusless Connectless HTTP 프로토콜은 상태가 없다 HTTP 프로토콜은 상태에 대한 지속적인 연결이 없다 이전에 했던 작업, 지금한 작업에 대한 정보를 갖고 있지 않다 웹 브라우저의 요청에 대한 응답을 하면 클라이언트와의 접속이 끊긴다 연결이 계속되어 있으면 좋을텐데 왜 귀찮게 비연결방식으로 하고 쿠키라는 방식으로 저장을하는거야? 123HTTP는 인터넷 상에서 불특정 다수의 통신환경을 기반으로 설계되었다는 점이 포인트입니다만약 불특정 다수의 클라이언트와 Google이라는 하나의 서버가 지속적으로 연결을 유지한다면많은 리소스가 발생하게 됩니다. 따라서 리소스 낭비를 줄여 더 많은 연결을 위해 비연결 지향으로 설계하게 된 것입니다 많은 클라이언트와의 연결이 원활해지는 장점이 있다면 비연결 지향으로 생기는 단점도 있지 않을까? 123456789첫번째로 위에서 언급했듯이 쿠키라는 것을 따로 두고 클라이언트 정보를 임시로 저장하는 방법을 채용해야한다그리고 두번째로 동일한 클라이언트의 모든 요청에 대해, 매번 새로운 연결시도&#x2F;해제의 과정을 거쳐야 하므로연결&#x2F;해제에 대한 오버헤드가 발생한다는 단점이 있습니다이에 대한 해결책으로 HTTP연결을 새로 생성할 때마다 발생되는 오버헤드를 줄이기 위해HTTP 1.1 부터 지원하는 기능인 KeepAlive 속성을 사용할 수 있습니다그러나 KeepAlive 속성을 on상태로 바꾼다 해도, 서버가 나쁜 환경에서는 프로세스수가 기하급수적으로 늘어나기 때문에메모리를 많이 사용하게 되므로 주의해야 합니다 HTTP Protocol : tistory1, &nbsp; tistory2 Cookie HTTP의 특성인 Connectless, Stateless의 문제점을 보완한 것이 바로 Cookie! Connectionless로 인해 서버는 클라이언트의 요청에 대한 응답을 한 후 연결을 끊기 때문에 다른 페이지로 이동하고 싶을 경우 서버에 재요청을 해야합니다. 재요청시 서버는 클라이언트를 식별할 수가 없는 Stateless특징이 있기 때문에 같은 브라우저에서 요청을해도 서버는 같은 브라우저인지 알 수가 없고, 로그인과 같이 서버가 클라이언트를 기억해야 할 경우에 클라이언트 정보를 저장하지 못한다면 페이지 이동시을 하거나 리로딩같은 재요청을 하는 경우에 계속해서 로그인을 해야 하는 불편함이 있습니다. 이러한 불편함을 해결하기 위해 쿠키라는 것을 저장해서 서버가 클라이언트를 식별할 수 잇도록 합니다 쿠키는 서버에서 생성하여, 클라이언트에서 보낸 특정 정보를 저장합니다. 그리고 쿠키의 속성값은 서버에 요청할 때마다 참조 또는 변경하여 데이터 상태를 관리합니다. cookie : github blog Session Cookie의 단점을 보완하기 위해 생긴 Session! Session은 서버단에서 사용자 정보를 기록할 수 있는 방법입니다 Session?HTTP session id를 식별자로 구별하여 데이터를 사용자의 브라우저에 쿠키형태가 아닌 접속한 DB에 정보를 저장합니다 클라이언트는 HTTP session id를 쿠키로 메모리 저장된 형태로 가지고 있습니다메모리에 저장하기 때문에 브라우저가 종료되면 사라지게 됩니다 Session 절차12345671. 클라이언트가 서버에 Resource를 요청합니다2. 서버에서는 HTTP Request를 통해 쿠키에서 Session id를 확인 후 없으면 set-cookie를 통해 새로 발행한 session-id를 보냅니다3. 새로 부여 받은 session-id를 클라이언트 쪽에서 HTTP request에 포함하여 원하는 Resource를 요청합니다4. 서버는 session id를 통해 해당 세션을 찾아 클라이언트 상태 정보를 유지하며 적절한 응답을 합니다 뭐야 쿠키만 있음되지 세션은 또 뭐야? 1234쿠키에 대한 정보를 HTTP Header에 추가하여 보내기 때문에 상당한 트래픽을 발생시키는 문제가 있습니다또한 결제정보, 개인정보등을 쿠키에 저장했을때 쿠키가 유출되면 보안에 문제가 발생할 수도 있습니다따라서 클라이언트측에 저장하는것이 아니라 서버 DB에 저장하는 방법을 사용해서 문제를 해결! Token 세션은 서버의 메모리를 차지하고 있기 때문에 동시 접속자 수가 많은 웹 사이트일 경우 서버 과부화의 원인이 되고, 세션 정보가 중간에 탈취 당할 수도 있기 때문에 완벽하다고 볼수는 없습니다. 그래서 쿠키와 세션의 문제점을 보완하기 위해 Token(토큰) 인증 방식 도입! Token 인증방식은 보호할 데이터를 토큰으로 치환하여 원본 데이터 대신 토큰을 사용하는 기술 1234토큰 방식 이외에 어떤 새로운 기술이 또 생길지 모릅니다그렇지만 현존하는 기술중 Token 방식이 가장 안전하다고해서 무조건 Token 방식을 써야 하는 가?꼭 그렇지만은 않아 보인다. 어떤 웹 서버를 운영할 것인가에 따라 해당 서버를 이용할 이용자의 숫자에 따라어떤 서비스를 제공할 것이냐에 따라 적절하게 사용해야 한다고 봅니다 HTTPs HTTPS: tistory HTTP message서버와 클라이언트가 HTTP 통신을 할때 주고 받는 메시지 12클라이언트 --&gt; 서버 : Request Message서버 --&gt; 클라이언트 : Response Message Request Message 1234567891011요청라인: url HTTP Method protocol version요청헤더: User-Agent(브라우저) Accept(수신되는 데이터중 브라우저가 처리가능한 데이터 타입) Cookie(유저 정보 임시 기억) Host(요청 도메인 정보) Referer(현재 페이지 접속 전 어느 사이트 경유했는지에 대한 정보) Connection # ex) keep-alive공백라인메시지 본문 Response Message 1234567891011상태라인: HTTP version Status code Reason-phrase응답헤더: Date Server # ex) Apache Last-Modified Content-Encoding Content-Length Content-Type # ex) text&#x2F;html; charset&#x3D;utf-8공백라인메시지 본문 HTTP Request method Request Method Explanation Get 요청라인을 통해 자원 요청(url에 데이터 표시) Post 메시지 본문을 통해서 자원 요청(url에서 데이터 숨김) Put URL에서 자원을 생성 Delete URL에서 자원을 삭제 Options 응답 가능한 HTTP Method 요청 Head HTTP Header 정보만 수신 Trace Request의 loop back 테스트 Connect 터널링의 목적으로 연결 요청 Client, Server 클라이언트(Request) —&gt; 서버(Response) 브라우저에서 문서확인 &lt;— 문서(요청에 대한 응답) ex) html, json, jpg… HTTP Status12345678910111213200 (OK): 성공적인 응답, 오류 없이 전송 성공201 (Created): 요청이 성공적으로 처리되어 리소스가 만들어졌음을 의미202 (Accepted): 요청이 받아들여졌지만 처리되지 않았음을 의미301 (Moved Permanently): 요청한 정보가 새로운 주소로 영구적으로 옮겨 갔음을 의미302 (Found) : 요청한 정보가 새로운 주소로 일시적으로 옮겨 갔음을 의미304 (Not Modified): 브라우저에 캐시되어 있는 버전을 쓴다400 (Bad Request): 요청 자체가 잘못 되었을때 사용하는 코드401 (Unauthorized): 인증이 필요한 리소스에 인증 없이 접근할 경우 발생403 (Forbidden): 서버가 요청을 거부할때 발생. 관리자에 의해 사용자를 차단했거나 서버에 index.html이 없는 경우 발생404 (Not Found): 에러는 파일의 확장자가 제대로 입력이 되지 않았거나 주소를 잘못 쳤을 경우(존재하지 않는 url 요청을 했을 경우) 발생하는 에러이다408 (Request Timeout): 요청 중 시간이 초과되었을때 사용하는 코드500 (Internal Server Error): 요청한 주소의 서버에 관리상 문제가 있을 경우 발생하는 에러, 서버측 파일에 소스코드 자체에 오류가 있을 경우 즉, 컴파일이 불가능한 경우에 발생할 수 있다503 (Service Temporarily Unavailable): 서버를 현재 일시적으로 사용할 수 없을 때 발생, 유지보수중이거나 서버가 터졌을 때 발생 HTTP 심화 학습 : ston 301 redirect vs 302 redirectResource 일반적으로 리소스란, 사용될 수 있는 어떤 항목을 말한다프린터나 디스크 드라이브와 같은 장치들이 리소스가 될 수 있으며, 메모리도 마찬가지 이다 쉽게 말해 프로그램을 실행시키기 위해 사용되야 할 자원들, 항목들을 총칭해서 리소스라고 한다{: .notice} Resource : naver blog1, naver blog2 Resource 확인하는 법: naver post ORMVirtual EnvironmentTemplate language익혀야할 부분 자주쓰는 단축키 손에 익히기 Declaration Implementation Type Declaration Jinja2 2019-05-23 2ndSQLalchemy SQLarlchemy는 Python 언어를 위한 ORM이다. SQL문법을 사용하지 않고 Python class로 스키마를 작성하면 Create table을 한것 처럼 DB table을 생성해준다. TypeSQLarlchemy 일반 데이터 타입 정수형 BigInteger SmallInteger Integer 실수형 Float 논리형 Boolean 문자형 String Text Unicode : 유니코드 UnicodeText : 기간형(시간, 날짜) Date : yyyy.mm.dd DateTime : Date + Time Time : hh:mm:ss Interval : 기간 열거형 Enum 이진데이터형 LargeBinary MatchType Numeric 타사의 데이터 타입 정수형 Integer Int BigInt SmallInt 실수형 Float Real 문자형 Char : 고정 문자열 Varchar : 가변 문자열(메모리를 효율적으로 사용할 수 있다) ex) varchar(10)일 때 test를 저장하면 4byte 영역만 차지한다 nChar : 고정 문자열 + 유니코드 문자열 (char의 2배공간 사용) nVarchar : 가변 문자열 + 유니코드 문자열 이진데이터형 Binary VarBinary 기간형(시간,날짜) Date DateTime TimeStamp 파일형 BLOB CLOB JSON 리스트형(배열) Array WTForms 클라이언트로부터 입력받을 Form을 제공하는 API. 필드의 정의, 유효성 검사, 입력 가져오기, 오류 집계를 포함하는 기능을 제공한다. Field 일반적으로 데이터베이스 테이블에서 타입을 지정해주는 열을 말한다. 입력 받는 값의 타입. 기본 필드 숫자 필드 FloatField : 실수를 받는 필드 IntegerField : 정수를 받는 필드 문자 필드 StringField : 문자열을 받는 필드 논리형 필드 BooleanField : True, False를 받는 필드 파일 필드 FileField : 파일을 받는 필드 MutipleFileField : 여러 파일을 받을 수 있는 필드 날짜 필드 DateField : 날짜를 받는 필드 DatetimeField : 날짜, 시간을 같이 받는 필드 선택형 필드 RadioField : SelectField와 비슷하지만, 라디오 버튼을의 목록을 보여준다. SelectField : 값과 레이블로 이루어진 선택들을 쌍으로 가진다. 값은 어떤것이 와도 된다. SelectMultipleField : SelectField와 같지만 여러 선택을 가질 수 있다. 버튼형 필드 SubmitField : Submit 버튼이 눌리는 것을 체크하는 필드 DecimalField 편리한 필드HiddenField : 입력 폼이 보이지 않는 필드 PasswordField : 비밀번호를 입력할때 값이 보이지 않도록 하는 필드 TextAreaField : 텍스트를 자유롭고 길게 받을 수 있는 필드 Field EnclosuresFormField : Form을 받는 필드 FieldList : 필드의 인스턴스를 list형태로 받는 필드 커스텀 필드필요시 직접 필드를 수정해서 사용한다 2019-06-08 3rdflask_security admin 페이지에 login 화면 추가 과제 admin + flask_security + login.html 방법 찾아보기 로그인 controller 로직 상세 구현하기 출석부 만들기 2019-06-09 4thapp.py 분석하기1# -*- coding: utf-8 -*- 해당 파일은 utf-8 인코딩 방식을 사용할 것임을 명시해준다. 1from flask import Flask Flask Project 생성시 만든 가상환경 ‘Flask_venv’에 포함된 flask 모듈안에 있는 app.py 내 선언된 Flask 클래스 를 사용하겠다. 1app = Flask(__name__) 모듈 하나만 사용한다면 __ name__ 이름으로 parameter를 주면 현재 작업하는 파일을 flask 인스턴스로 활용하겠다는 의미. flask 프레임워크를 사용하여 서버 페이지를 작성하겠다, flask로 나만의 app을 만들겠다. 등등 의미로 생각하면 됨. 123@app.route('/')def app_start(): return 'You can run your web app' 위에서 app이라는 이름으로 flask를 인스턴스화 했기 때문에 이제 app을 이용하여 flask에 있는 기능을 사용할 수 있게 됐음. 그 중에 route함수는 호출 요청을 분석한 후에 원하는 uri를 처리하는 기능을 담당한다. 따라서 특정 uri로 요청이 들어오면 요청에 알맞은 처리를 담당하는 뷰함수를 실행할 수 있게 route가 매핑을 해준다. 로컬에서 실행하는 경우 ‘localhost:port/‘ 로 요청했을 때 route 데코레이터가 app_start라는 뷰함수에 연결해주어 app_start 함수실행 결과를 return 해주게 된다. 12if __name__ = '__main__': app.run() 현재 파일이 메인모듈 파일에서 실행하는 건지 import 모듈에 의해 실행되는건지 확인하는 조건문이다. 만약 메인모듈에서 실행하는 거라면 로컬 서버를 실행해라 라는 뜻. URL &amp; URI URL은 Uniform Resource Locator(파일 식별자), URI는 Uniform Resource Identifier(통합 자원 식별자)이다. url은 특정 서버의 원하는 리소스의 위치 주소이고, uri는 실제 리소스의 위치가 아닌 rewrite 기술이 적용되어 리소스의 위치 이름을 식별자로서 역할을 할 수 있게 변경된 주소 이름이라고 생각하면 된다.{: .notice} In Flask class Default configuration parameters1234567891011121314151617181920212223242526272829303132#: Default configuration parameters. default_config = ImmutableDict(&#123; 'ENV': None, 'DEBUG': None, 'TESTING': False, 'PROPAGATE_EXCEPTIONS': None, 'PRESERVE_CONTEXT_ON_EXCEPTION': None, 'SECRET_KEY': None, 'PERMANENT_SESSION_LIFETIME': timedelta(days=31), 'USE_X_SENDFILE': False, 'SERVER_NAME': None, 'APPLICATION_ROOT': '/', 'SESSION_COOKIE_NAME': 'session', 'SESSION_COOKIE_DOMAIN': None, 'SESSION_COOKIE_PATH': None, 'SESSION_COOKIE_HTTPONLY': True, 'SESSION_COOKIE_SECURE': False, 'SESSION_COOKIE_SAMESITE': None, 'SESSION_REFRESH_EACH_REQUEST': True, 'MAX_CONTENT_LENGTH': None, 'SEND_FILE_MAX_AGE_DEFAULT': timedelta(hours=12), 'TRAP_BAD_REQUEST_ERRORS': None, 'TRAP_HTTP_EXCEPTIONS': False, 'EXPLAIN_TEMPLATE_LOADING': False, 'PREFERRED_URL_SCHEME': 'http', 'JSON_AS_ASCII': True, 'JSON_SORT_KEYS': True, 'JSONIFY_PRETTYPRINT_REGULAR': False, 'JSONIFY_MIMETYPE': 'application/json', 'TEMPLATES_AUTO_RELOAD': None, 'MAX_COOKIE_SIZE': 4093, &#125;) Fatal error in launcher: Unable to create process using … pip list 명령어를 쳤을때 떳던 에러 해결1python.exe -m pip install --upgrade pip 2019-06-30 5thflask - mysql 연동하기‘mysql.h’ No such file or directory 오류 위 오류가 난 상황 : pip install flask-mysqldb 설치할때 오류 명 그대로 mysql.h 파일이 없다는 뜻이다. 해결12345671. https:&#x2F;&#x2F;www.lfd.uci.edu&#x2F;~gohlke&#x2F;pythonlibs&#x2F;#mysqlclient.Then 사이트 들어가서 내가 사용중인 python 버전에 맞는 파일을 다운로드 한다2. flask site-packages폴더에 저장하고 pip 명령어를 입력한다 pip install mysqlclient-1.4.2-cp37-cp37m-win32.whl (파일명)3. 오류가 날 경우 python 버전과 whl파일과 호환이 되는 파일인지 체크한다 참고로 cp37이라고 써있으면 python 3.7버전이라는 뜻이다4. pip install flask-mysqldb 명령어를 입력한다 출처: tistory, &nbsp; stackoverflow 2019년 8월 21일 6th기존 DB를 Flask-SQLAlchemy ORM Model로 사용하기출처: github blog","categories":[{"name":"Web","slug":"Web","permalink":"http://jungjihyuk.github.io/categories/Web/"},{"name":"Flask","slug":"Web/Flask","permalink":"http://jungjihyuk.github.io/categories/Web/Flask/"}],"tags":[{"name":"Flask","slug":"Flask","permalink":"http://jungjihyuk.github.io/tags/Flask/"},{"name":"Python","slug":"Python","permalink":"http://jungjihyuk.github.io/tags/Python/"},{"name":"Web","slug":"Web","permalink":"http://jungjihyuk.github.io/tags/Web/"},{"name":"Programming","slug":"Programming","permalink":"http://jungjihyuk.github.io/tags/Programming/"}]},{"title":"AI 이노베이션 스퀘어 수업(기본반)","slug":"AILecture","date":"2019-04-28T15:00:00.000Z","updated":"2020-02-24T15:39:37.274Z","comments":true,"path":"2019/04/29/AILecture/","link":"","permalink":"http://jungjihyuk.github.io/2019/04/29/AILecture/","excerpt":"AI 이노베이선 스퀘어에서 배운 AI 공부 정리","text":"수업 목차Python 1일차 &nbsp; Type(2일차) &nbsp; 3일차 &nbsp; 4일차 &nbsp; Function(5일차) 6일차 &nbsp; Decorator(7일차) &nbsp; Class(8일차) &nbsp; 9일차 &nbsp; Meta_Class(10일차) 11일차 &nbsp; 디버깅 Numpy 12일차 &nbsp; 13일차 &nbsp; newaxis(14일차) Pandas 15일차 &nbsp; 16일차 &nbsp; 17일차 &nbsp; 18일차 &nbsp; 19일차 Machine Learning 20일차 &nbsp; Process(21일차) &nbsp; 22일차 &nbsp; 23일차 &nbsp; 24일차 &nbsp; 25일차26일차 &nbsp; 추천 시스템(27일차) &nbsp; 28일차 &nbsp; 29일차 Deep Learning 30일차 &nbsp; 31일차 &nbsp; 32일차 &nbsp; 33일차 &nbsp; 34일차 2019년 4월 29일 월요일 1st이 수업은 기본반이라고 되어 있지만 사실상 fundamental 즉, 핵심적이고, 근본적인, 필수적인 것들을 다루기 때문에 어려운 내용도 포함 하고 있다. 왜 프로그래밍 언어가 많은 걸까?? : 언어마다 각각의 장단점이 있기 때문이다 그리고 더 구체적으로는 언어마다 특화되있는 분야가 있기 때문이다 ## 왜 AI에는 파이썬인가? 123456789101112131415161718Life is short, you need!파이썬의 슬로건에서 보여주듯이파이썬은 개발 속도가 빠르기 때문에 생산성이 좋다!1. 생산성- Efficient --&gt; 빠르고 체계적인 일처리가 가능하다 - Effective --&gt; 원하는 결과를 가져다 준다2. 멀티 패러다임- 절차 지향, 객체지향, 함수지향 프로그래밍이 모두 가능하다3. 연구자 친화적 언어, 개발자 친화적 언어 - 언어중에서 속도가 느린 언어에 속하지만 개발속도는 빠르고 함수적 프로그래밍이 가능하다그리고 이 파이썬은 크게 3가지 분야에서 유리하다.첫번째 시스템 자동화 분야두번째 웹세번째 데이터 사이언스 * ※ 이 수업은 Data Science분야를 집중해서 다뤄볼 것이다. Python의 특징 다양한 패러다임을 지원한다. 글루 언어다. 언어이면서 명세서이다. CPython / De facto -&gt; 많이 쓰여서 표준이된것. (사실상 표준) Library &amp; Tool (많다) Python: General Purpose(범용적) &lt;-&gt; R: domain specific(도메인용, 통계전문) 인터프리터 언어이다. 모바일 지원에 대해 약하다. (이는 절대 개선될 수 없다. 왜냐하면 apple과 google에서 swift, 및 자사 언어를 사용하기 때문에) 그러나 DS분야에서는 그나마 낫다. 속도가 엄청 느리다. (Dynamic language) ※이번 수업은 c로 만든 python으로 사용한다 ※python3.3 부터 유니코드로 인한 속도가 개선되었다. Interpreter vs Compiler REPL vs IDE vs Text EditorREPL: &nbsp; Read-Eval-Print loop의 약자로 컴파일 과정없이 즉석으로 코드를 입력하고 실행결과를 바로 보는 대화형 환경을 말한다.IDE: &nbsp; Integrated Development Environment의 약자로 개발통합환경 즉, 코딩을 위한 편집기, 컴파일, 링크, 디버그 등… 실행 모듈 개발에 필요한 기능을 한곳에 모아둔 프로그램을 말한다. Text Editor: &nbsp; 문서 편집기, 메모장이나 노트패드, atom 등을 text editor라고 하고 보통 코딩을 위한 text editor는 코딩을 더 편리하게 도와주는 기능이 탑재되어있다. atom같은 경우에는 원하는 경우 설치하여 터미널창을 추가할 수도 있고 각 언어별 자동완성기능 등 여러가지 편리한 기능들을 사용할 수있도록 도와주는 프로그램이다. ## Jupyter notebook Python + Markdown 지원 REPL? Python의 REPL에서 여러줄의 코드를 실행하기 편하고 편집하기 유용한 버전으로 업그레이드 한 것이 IPython Notebook. IPython의 강점은 한 파일 내에서 쉽게 코드 cell 단위로 실행할 수 있다는 것이다. 다만 IPython는 파이썬 전용이다. 그리고 한 번 실행하고 Python 버전을 바꾸려면 로컬 서버를 내렸다가 다시 올려야 하는 불편함이 있다. 이러한 불편함을 극복하고 만들어진 것이 바로 Jupyter Notebook이다. Jupyter 이름에는 뜻이 숨어 있다. Ju는 Julia Py는 Python 그리고 R은 R 세 단어를 합친 단어이다. Jupyter notebook은 특이한 점이 웹에서 사용한다는 것이다. 앞으로 이 수업은 파이썬 공식 문서를 이용할 것이다. 왜냐하면 정확한 정보를 제공하고 공식 문서를 보는 연습을 미리 해두면나중에 공부할때 필히 도움이 될 것이다. &nbsp; 공식 문서 자료형 숫자, 문자1234567891011121314151617181920212223242526272829303132333435자료형 중 숫자는 크게 4가지가 있다.1. Integer2. Float3. Boolean4. ComplexInteger는 정수형으로 숫자의 범위가 없다. 따라서 오버플로우가 없다.그리고 python에서 정수의 종류는 한 가지Float는 부동소수로 숫자의 범위가 있다. 따라서 오버플로우가 있다.※ 0.1 + 0.1 + 0.1 의 결과값은 0.3000000000000004로 나온다.Why? --&gt; 컴퓨터는 근사값을 계산하기 때문에 정확한 값을 출력하지 못한다.※ a &#x3D; 2e3 --&gt; 2000.0 b &#x3D; 2e-3 --&gt; 0.002그리고 컴퓨터가 정수와 부동소수의 저장 방식의 차이 때문에 .의 유무로 정수인지 부동소수인지 판단한다.Boolean은 True &#x2F; FalseTrue는 숫자 1에 대응되고 False는 숫자 0에 대응된다.※ True 처럼 bold채로 쓰인 것은 키워드이다.Complex는 복소수로 j로 표시한다.ex) i &#x3D; 1 + 3j : (1+3j)문자는 크게 3가지가 있다.1. String2. Bytes3. BytearrayString은 python3 버전에서 unicode문자에 해당한다.Byte는 문자 앞에 b를 붙이면 byte문자로 인식하고 ASCII코드에 해당한다.ex) a &#x3D; b&#39;안녕&#39; SyntaxError: bytes can only contain ASCII literal characters Python Tip1 Python에서는 변수를 식별자라고 명칭한다. 이때 식별자는 생성 규칙이 정해져 있다.{: .notice} 1231. 영문으로 써야한다.2. 첫번째문자는 특수문자를 사용할 수 없다.3. 미리 정의되어있는 문자는 사용할 수 없다. Python Tip2 파이썬은 동적타입, 즉 타입을 지정해주지 않아도 자동으로 지정해주기 때문에 정수형인지부동소수점인지 문자인지 등을 명시하지 않아도 타입이 지정된다.{: .notice} Python keword 종류1234567891011121314151617181920212223242526272829303132333435363738import keywordkeyword.kwlist['False', 'None', 'True', 'and', 'as', 'assert', 'async', 'await', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield'] Namespace 보기12345678910111213%whos # 여태까지 사용한 식별자를 보여줌Variable Type Data/Info-------------------------------a int 1abc bytes b'abc'b int 2c int 3f bool Falsei complex (1+3j)keyword module &lt;module 'keyword' from 'C&lt;...&gt;conda3\\\\lib\\\\keyword.py'&gt;t bool Truew str ㅇㅇ 문자열 연산 및 예외 연산1234567891011'정지혁' * 3: 정지혁정지혁정지혁'정' + '정': '정정''정' + 1: TypeError: can only concatenate str (not \"int\") to str# 데이터 타입에 따라서 지원되는 연산이 다르다. Markdown 문법아주 기본적인 마크다운 문법을 배웠고 jupyter에서 작동하는 커멘드를 배웠다.ESC : &nbsp; 명령 커멘드H: &nbsp; Help (도움말)ESC + Y: &nbsp; Code modeESC + M: &nbsp; Markdown modeESC + A &nbsp; 현재 라인 위에 새로 추가하기ESC + B &nbsp; 현재 라인 밑에 새로 추가하기ESC + L : &nbsp; 해당 줄에 숫자 Ctrl + Shift + P : &nbsp; Help (도움말) 복습 시간 18시 15분 ~ 19시 30분 / 총 1시간 15분{: .notice} 2019년 4월 30일 화요일 2nd자료형은 총 20가지가 있지만 13가지를 배울 것이다.자료형123456781. 숫자형 [Integer, Float, Boolean, Complex]2. 문자형 [String, Bytes, Bytearray]3. List4. Tuple5. Set6. Frozenset7. Dictionary8. Range 정수형을 표현하는 4가지 방법 2진수 0b를 숫자 앞에 붙인다. 8진수 0o를 숫자 앞에 붙인다. 16진수 0x를 숫자 앞에 붙인다. 10진수 아무것도 안쓰면 그냥 10진수이다. 정수형 숫자 범위123456789101112import syssys.maxsize결과: 9223372036854775807정수형에서 오버플로우가 없다고 했는데..?실제로 메모리에 할당 가능한 최대 숫자 크기가 저 값이고초과되었을 때 동적으로 추가 할당이 된다.(?)sys.int_infosys.int_info(bits_per_digit=30, sizeof_digit=4)32비트 python인 경우, 정수는 최대 30비트까지 허용된다? 진법 변환 builtinbin() =&gt; 2진법으로 변환 oct() =&gt; 8진법으로 변환 hex() =&gt; 16진법으로 변환 2, 8, 16진법의 숫자를 입력하면 자동으로 10진수로 변환 bold채가 아닌데 색이 변하는 것은 builtin함수 float부동소수는 소수점이 존재하는 수예외적으로 무한대와 숫자가 아닌 경우도 포함한다컴퓨터의 부동소수 연산은 정확하지 않은 근사값을 보여준다 1234567891011121314151617float('inf')=&gt; inf (infinity)float('nan')=&gt; nan (not a number)# 무한대 개념은 딥러닝에서 미분의 개념을 꼭 알아야 하는데 이때 중요하게 작용한다. 파이썬은 이처럼 숫자 체계가 범위가 넓기 때문에 인공지능에 이용되는 장점이 있다.# 부동소수 연산 a = 1.7976931348623157e+308aa + 1a = a + 1:1.7976931348623157e+3081.7976931348623157e+308True .(점)은 부동소수점을 결정하는 리터럴 리터럴은 데이터 타입을 결정하는 문자를 일컫는 말이다. 1234import syssys.float_infosys.float_info(max&#x3D;1.7976931348623157e+308, max_exp&#x3D;1024, max_10_exp&#x3D;308, min&#x3D;2.2250738585072014e-308, min_exp&#x3D;-1021, min_10_exp&#x3D;-307, dig&#x3D;15, mant_dig&#x3D;53, epsilon&#x3D;2.220446049250313e-16, radix&#x3D;2, rounds&#x3D;1) float형 숫자의 연산+ , - , * , /, //, %, **가 있다. 12345단, 음수 나눗셈은 주의 해야 한다.ex)10 &#x2F;&#x2F; -3&#x3D;&gt; -4why? --&gt; -4 + 0.66667 이런식으로 간주하기 때문에 자료형을 구별하는 기준12345678910111213┌─ Mutable # 추가, 삭제가 가능한 경우 &#x2F; 특징 : 메모리 번지 안바뀜, 재할당할 필요없음└─ Immutable # 추가, 삭제가 불가능한 경우 &#x2F; 특징 : 재할당으로 메모리 번지 바뀜Container ┌─ Homogeneous # 요소들이 서로 같은 타입인 경우 └─ Heterogeneous # 요소들이 서로 다른 타입이 가능한 경우(요소가 1개 이상인 데이터 구조)Sequence ┌─ Indexing # 요소를 하나씩 출력 └─ Slicing # 요소를 한번에 여러개 출력(순서가 있음) Lookup ┌─ Mapping hash # key값과 value를 갖는 Dictinary가 갖는 특징 └─ set # 순서가 없는 고유한 원소들의 집합(key값으로 이루어진 데이터 구조) Indexing123a = '정지혁'a[0]: 정 Slicing1234567891011121314151617181920a = '정지혁'a[0:3] or a[:3]:'정지혁'a[-3:] or a[0:]:'정지혁'a[0:3:2] # 양수일때 (맨 뒤에 오는 숫자 - 1) 을 하면 건너 뛰는 문자의 개수를 나타낸다:'정혁'a[::-1] # 음수일때 |맨 뒤에 오는 숫자 + 1|을 하면 건너 뛰는 문자의 개수를 나타내고 거꾸로 출력한다.:'혁지정'a[:-3:-1]:'혁지'a[:70] # 슬라이싱은 범위가 벗어나도 에러가 나지 않는다:'정지혁'b = '정지혁 천재'b[slice(0,3)]: '정지혁'b[slice(0,-1,2)]: '정혁천' List vs Tuple차이점 List는 수정, 삭제, 추가가 가능하고 인덱싱, 슬라이싱이 가능하지만, Tuple은 수정, 삭제, 추가가 불가능하고 인덱싱, 카운팅만 가능하다.{: .notice} 123456789x = [1]type(x): listy = (1)type(y): int#하나의 요소를 갖는 튜플을 생성하려면 콤마를 적어줘야한다.y = (1,) Tuple Tip 콤마가 뒤에 있다는 것은 튜플이라는 것을 알려주기 때문에 가독성도 높일 수 있고, 콤마를 써야만 tuple로 인식이 되는 경우가 있기 때문에 마지막에 콤마를 꼭 써주는 습관을 갖도록 하자. ex) (1,2,){: .notice} Set vs Dictionary공통점 둘다 집합의 성질을 띄어 중복허용이 불가능하고, 순서가 없다.{: .notice} 차이점 set은 key값만 있는 반면 dictionary는 key, value쌍을 이뤄 mapping hash 타입을 이룬다.{: .notice} 1234567891011121314151617181920212223242526272829s = &#123;&#125;type(s):dict# python이 처음 만들었을 때는 set이 없었기 때문에 공집합을 만들면 Dictionary로 간주한다.# 그렇다면 set은 공집합을 어떻게 만드나?s = set()type(s): set# 집합은 고유의 연산자가 있다.a = &#123;1,2,3&#125;a - &#123;2&#125;: &#123;1,3&#125;a ^ &#123;3&#125;: &#123;1,2&#125;# set의 활용# set은 공통된 메소드를 확인할때도 사용한다set(dir(list())) &amp; set(dir(tuple())):&#123;'__add__', '__class__', '__contains__', .... 'count', 'index'&#125; __ missing__ &amp; defaultdict__ missing__ 보통 dictionary에 존재하지 않는 key값에 접근할 경우 KeyError가 발생한다 그런데 missing 메소드를 재정의 해서 내가 원하는 return 값을 주면 에러가 발생하지 않는다 즉, missing 메소드를 구현하면 KeyError가 나는 상황에서 missing 메소드를 호출하게 된다 1234567891011121314151617181920212223242526272829303132333435363738class MyDict(dict): def __missing__(self, key): self[key] = rv = [] return rvm = MyDict()type(m): __main__.MyDictm.update(&#123;'x':1&#125;) # 해당 키가 있으면 value를 수정하고 없으면 추가한다m: &#123;'x': 1&#125;m['y']: []m: &#123;'x': 1, 'y': []&#125;m['y'].append(2): &#123;'x': 1, 'y': [2]&#125;class MyDict2(dict): def __missing__(self, key): self[key] = rv = &#123;&#125; return rvm2 = MyDict2(&#123;'a':1&#125;)m2['b']: &#123;&#125;m2.update(&#123;\"c\":[1,2,3]&#125;)m['b'].update(&#123;'x':1,\"y\":2&#125;)m: &#123;'a': 1, 'b': &#123;'x': 1, 'y': 2&#125;, 'c': [1, 2, 3]&#125; defaultdict 없는 key값에 접근했을 때 에러가 나지 않고 default로 원하는 타입의 값 자동으로 할당해주는 dict type 123456789101112131415161718192021from collections import defaultdictm = defaultdict(list)type(m): collections.defaultdictm: defaultdict(list, &#123;&#125;)m['x'].append(1)m: defaultdict(list, &#123;'x': [1]&#125;)m['y']: defaultdict(list, &#123;'x': [1], 'y': []&#125;)[m['y'].append(x) for x in range(1,11)]: [None, None, None, None, None, None, None, None, None, None]m: defaultdict(list, &#123;'x': [1], 'y': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&#125;) 출처: tistory Internals Python은 -5부터 256까지 숫자는 재할당을 해도 메모리 번지가 바뀌지 않도록 인터널 기법을 사용한다. 많이 쓰이는 작은 정수들을 미리 할당해 놓음으로써 메모리 공간과 연산비용을 많이 아낄 수 있게된다.{: .notice} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from sys import interndir(intern):['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']※ 주의# interning된 값을 재할당할때는 메모리 번지가 바뀌지 않는다a = 100id(a):140706464961408a = 100id(a):140706464961408 파이썬 내부 동작 원리 : mingrammer Garbage Collection은 메모리 관리 기법 중 하나로, 프로그램이 동적으로 할당했던 메모리 영역 중에서 필요 없게 된 영역을 해제하는 기능이다.{: .notice} xxx = xxx식별자 or 변수 = 식(Expression), statement Expression: 연산결과가 하나의 값으로 만들 수 있는 것 ex) 3 + 1 , float(‘inf’) 등 … Expression vs StatementExpression은 값 또는 값들과 연산자를 함께 사용해서 표현해 하나의 값으로 수렴하는 것 이때 함수, 식별자, 할당 연산자 [], 등을 포함한다. 그리고 Expression은 평가가 가능하기 때문에 하나의 값으로 수렴한다. 여기서 평가라는 의미를 정확하게 알고 있어야 한다. 평가란 컴퓨터가 이해할 수 있는 기계 이진 코드로 값을 변환하면 리터럴의 형태가 달라도 그 평가값은 같게 되는 것을 말한다. (표현식의 값을 알아낸다.) ex) 12345a, b = 4, 5eval('1+2+3')eval('a+b'):6:9 참고 Statement는 예약어와 표현식을 결합한 패턴이다. 그리고 실행가능한 최소의 독립적인 코드 조각을 일컫는다. Statement는 총 5가지 경우가 있다. 1. 할당 (Assignment) 2. 선언 (Declaration) 3. 조건 (if) 4. 반복문 (for, while) 5. 예외처리 for문으로 변수 할당하기 12345# statementfor i in range(1, 20+1): exec('r' + str(i) + '=' +str(i))# r1, r2 ...r20 까지 1,2,...20 할당 결론적으로 모든 Expression은 Statement지만 어떤 Statement는 expression이지 않다. retrun 3 이런 구문은 평가를 통해 3의 값이 나오는 것이 아니기 때문이다. ex) exec(‘1+2’)는 문제 없지만 eval(‘a=3’)는 오류가 난다{: .notice} ### 기타 내장 함수 1234dir(obejct) : 어떠한 객체를 인자로 넣어주면 해당 객체가 어떤 변수와 메소드를 가지고 있는지 출력을 합니다.type(object) : 어떠한 객체를 인자로 넣어주면 해당 객체의 타입을 반환한다.len(object) : 어떠한 객체를 인자로 넣어주면 해당 객체의 요소 갯수를 반환한다.id(object) : 해당 객체가 저장되어 있는 메모리 위치를 반환한다. id함수로 보는 메모리 할당1234567891011121314151617181920x = 10y = 10hex(id(x)):'0x7ffb006b9460'hex(id(y)):'0x7ffb006b9460'# -5 ~ 256사이 숫자이기 때문에 재할당을 해도 메모리 주소가 변하지 않는다.x = 1000y = 1000hex(id(x)): '0x1bc813b7650'hex(id(y)): '0x1bc813b73d0'x = 2000hex(id(x)): '0x1bc813b7db0'# 새로운 식별자로 같은 값에 binding을 하거나 reassignment를 하게되면 메모리 주소값이 변경된다. ※ 메모리 잘 쓰는 방법: &nbsp; wikidocs 비교 연산자12345678910111213141516171819202122232425262728293031323334353637381 == 3: False1 != 3: True'정지혁' &lt; '천재': True[1,2] &lt; [3]: True# 첫번째 요소 끼리 비교후 같으면 그 다음 요소 비교[1,2] &lt; 'a': TypeError# 비교할 때는 같은 타입끼리 해야 한다.a = 1000b = 1000a is b: False# 같은 메모리 번지인지까지 따진다.'ㅈ' not in '정지혁': True1 in [1,2,3]:True1 in '정지혁': TypeError# 정수형과 리스트를 in 연산을 했을 때는 타입이 달라도 가능하지만# 정수형과 문자형은 불가능하다# 기본적으로 멤버쉽 연산자(in)는 container에서만 쓸 수 있고 문자열 일때는 문자열 끼리만 가능하다. Error NameError 값을 할당하지 않은 식별자를 사용했을 때 발생하는 에러 IndexError 인덱스 값에서 벗어난 인덱스를 사용했을 때 발생하는 에러 TypeError 서로 다른 타입간의 연산을 했을 경우 발생하는 에러 KeyError dictionary에서 없는 key값으로 접근할때 발생하는 에러 AttributeError 존재하지 않는 Attribute에 접근하려고 할 때 발생하는 에러 UnboundLocalError 할당하기 전에 지역변수를 참조했을 때 발생하는 에러 복습 시간 18시 35분 ~ 20시 5분/ 총 1시간 30분{: .notice} 2019년 5월 2일 목요일 3rd할당문의 종류 6가지1234567891011121. 기본 할당문- a &#x3D; 12. Chain assignment- a &#x3D; b &#x3D; 13. Augmentation- a +&#x3D; 14. Pakcing5. Unpacking- Container 쪼개기6. Global , nonlocal- global 이용하여 전역번수 접근, 변경하기 # 추천하지 않는 기능- nonlocal은 함수 중첩시 함수와 함수 사이 변수 Unpacking 방법은 빅데이터 처리시 많이 쓰인다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# Chain assignment #a = b = 2a: 2b: 2b = 3a: 2# 변수 어느 하나 재할당 한다고 같이 바뀌지 않는다-- 주의 --x = y = [1000,2000]y.append(3000)x: [1000,2000,3000]y: [1000,2000,3000]# 그러나 mutable일때는 같이 변하므로 주의해야 한다!# Augmentation #a = 0a += 1 # (재할당)# 다른 언어처럼 선증가, 후증가가 지원되지 않는다++a (X)a++ (X)그러나 # ++a는 에러가 나지 않는다Why?# 앞에 있는 +를 부호연산자라고 간주하기 때문이다# Packing #x = 1,2,3y = 1,# Unpacking #x,y = 1,2 (O)x,y,*z = 1,2,3,4 (O)*x, = 1,2,3 (O)*a, = '정지혁' (O)*u, = &#123;'a':1,'b':2,'c':3,'d':4,'e':1&#125; (O) # 단, 키 값만 리스트 형태로 반환*x, y = range(10) (O)x, = 1,2 (X) # 왼쪽 식별자와 오른쪽 식의 갯수를 맞춰줘야 함*x, y, *z = 1,2,3,4,5 (X)*x = 1,2,3 (X) # 오른쪽에 오는 식은 Container면 모두 가능# * (별표)는 나머지를 리스트로 반환, 그리고 * 두 개이상 못씀#Global nonlocal#a = 1def name(): global a a += 1 return aname(): 2def name(): a = 1 a += 1 return a# 위 함수와는 같지 않음 / Why? 밑 함수에서는 a를 그냥 재할당한 것임def name(t): a = t print(a) def name2(): nonlocal a a += 1 print(a) return name2()name(3): 3 4 Packing &amp; Unpacking: &nbsp; blog 조건의 형태 3가지1231. if, else &amp; and, or2. if, elif, else3. 중첩 if if문 예시12345a = 6if 0 &lt; a &lt; 10: print(True)else: print(False) AND &amp; OR A and B A가 참(Truely)이면 B 체크 =&gt; B 반환 A가 거짓(Fasly)이면 B 체크 X =&gt; A 반환 A or B A가 참이면 B 체크 X =&gt; A 반환 A가 거짓이면 B 체크 =&gt; B 반환 반복문 2가지121. for2. while 여기서 개념 하나 추가 Iterable! Iterable은 순회, 반복 가능한 것을 말한다.그래서 for문에 쓸 수 있다.보통 container이면 Iterable ※ 아닌것도 있지만 아주 나중에 배운다. container이지만 Iterable이 아닌것이 set인가?? iterable의 조건중 __ iter__랑 __ getitem__ 두가지가 있어야 되는데 set은 __ iter__ 한가지 밖에 없다 왜지? 12345678910111213141516171819202122# for #for i in &#123;'a':1,'b':2&#125;.values(): print(i)for i, j in &#123;'a':1,'b':2&#125;.items(): print(i,j)# in 뒤에 오는 것은 Container, 여러개의 요소를 갖고 있는것은 반복문이 가능하다# while #i = 0while i &lt; 10: i+=1 print(i) if i == 5: break # 탈출문 else: print(\"완료\")# continue는 continue 밑은 실행하지 않고 넘어간다 for문은 반복횟수를 알때 주로 사용하고, while문은 반복횟수가 정해지지 않았을 때, 모를때 주로 사용한다. 모든 for문은 while문으로 바꿀수 있지만, 모든 while문은 for문으로 바꾸기 어렵다. Enumeration for문에 index가 필요할때 iterable 객체를 enumerate로 감싸면 index값이 같이 출력된다 123456789a = ['a','b','c','d','e']for index, value in enumerate(a): print(index, value):0 a1 b2 c3 d4 e else문 3가지 쓰임 조건문에서 =&gt; 조건에 맞지 않는 경우 반복문에서 =&gt; 반복문이 정상 완료 되고나서 실행 0번도 수행이라고 간주하기 때문에 else문이 실행될 수 있다 예외처리할 때 Dictionary view key values items 구문 실행시 실행시간 알아보기12345678%%timeitfor i in range(3,10,2): for j in range(1,10): print(i,\"*\",j,\"=\", i*j) print()# 391 µs ± 31.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) Python에서 중요한 두 가지 (Two A) Abstraction Automation python 내부 구조 확인 가능 사이트: pythontutor 복습 시간 17시 45분~ 18시 43분/ 총 58분{: .notice} 2019년 5월 3일 금요일 4th선언문 2가지121. 함수 선언2. 클래스 선언 12345def name(arg1, arg2 = 2): pass # 에러가 나지 않게 형태만 갖추기name(3) # 함수 호출(콜): (3,2) Argument 인자로 어떤 데이터 타입도 올 수 있다. 단 튜플을 넣을 때 괄호를 꼭 써줘야 한다{: .notice} Python의 또다른 장점 ‘return’문은 생략 가능하다 ## Parameter vs Argument Parameter Argument 선언문에서 괄호 안 호출문에서 괄호안 키워드 방식이 온다 식이 들어갈 수 있다 ### Parameter 사용법 1234561. Positional + keyword2. Only Positional3. Only Keyword4. Variable Positional5. Variable keyword6. Variable Positional + Variable keyword 12345678910111213141516171819202122232425262728293031323334353637383940# Positional + Keyword #def name(a,b): ''' 함수 설명 ''' # Docs String =&gt; Shift + Tab 하면 설명이 그대로 나온다 return a, b # 참고로 함수 설명에 ( / )가 있을 경우 Positional 방식이라는 뜻name(1,2):(1,2)name(3, b = 4):(3,4)name(a=1,b=2):(1,2)# Only Keyword #def name(*,a,b): return a + b# Variable Positional#def name(*a): return a[0],a[1:3],a[3:]name():()name([1,2,3],(4,5,6),&#123;'a':1,'b':2&#125;):([1, 2, 3], ((4, 5, 6), &#123;'a': 1, 'b': 2&#125;), ())# !주의! 할당할때 *는 list를 반환하고 함수에서 *는 tuple로 반환한다# Variable Keyword #def name(**a): return aname(a = ['a',2], b = &#123;'a':'a','b':2&#125;, c = range(3),d = 5):&#123;'a': ['a', 2], 'b': &#123;'a': 'a', 'b': 2&#125;, 'c': range(0, 3), 'd': 5&#125;# Variable Positional + Variable Keyword #def name(*b, **a): return b, aname(2,3,4,5, a = 9, b = 3, c = [1,2]) # !주의! keyword를 쓰기 시작하면 끝까지 keyword를 써야한다:((2, 3, 4, 6), &#123;'a': 9, 'b': 3, 'c': [1, 2]&#125;) Positional Only 사용자가 직접 만드는 함수의 파라미터에는 Positional only 방식을 사용할 수 없다. 하지만 기본 내장 함수 중에 파라미터 부분에 / 표시가 되어 있는 경우는 Positional Only 방식을 사용하라는 의미 이다. (shift + tab으로 설명 볼때), (앞으로 python 3.8부터는 positional only 방식을 지원한다고 한다.){: .notice} positional only : python Python에서는 Parameter로 받아 올때 Type을 지정해주지 않는다.Why? Python 철학중 EAFP라는 것이 있는데 이는 ‘허락보다는 용서를 구하기 쉽다’로부부관계를 예시로 설명하면 이해하기 쉽다.결혼하고 나면 보통 남자든 여자든 비싼 사치품을 사는 것이 쉽지 않다.이때 사치품을 사려고 하는 입장의 사람은 결정해야한다.사고 혼날 것인가.허락을 받을 것인가.전자가 더 실행하기 쉽고 빠르다는 것이 Python의 철학인 것이다. Python Tip1 파이썬은 오버로딩이 안된다.(@연산자로 오버로딩 가능해졌다?) 즉, 같은 함수 이름을 여러개 정의하여 매개변수를 달리하여 사용하는 기법이 허용이 되지 않는다.파이썬의 단점 중에 속도가 느리다는 점이 있었는데, 오버로딩을 지원하지 않음으로써 속도를 개선했다. (단, 오버라이딩은 사용 가능하다. (매소드 재정의)){: .notice} multipledispatch 파이썬으로 오버로딩 지원해주는 패키지 123456789101112131415from multipledispatch import dispatch@dispatch(int, int)def add(x,y): return x + y@dispatch(object, object)def add(x,y) return \"%s + %s\"%(x,y)add(1,2): 3add(1,'hello'): '1 + hello' 오늘의 명언자동이 많으면 제약이 많다. ## 함수의 특징 3가지 12345671. return이 반드시 있어야 한다- python에서는 return을 생략하면 None을 반환하도록 되어 있다2. 함수 안에 또 다른 함수를 선언할 수 있다3. Global, Local- 함수 안에 없는 값을 return 하게 될 경우 가까운 Global 식별자를 return- Global 식별자이름 하게 되면 접근, 수정이 가능하다- 함수 밖에서 함수 안의 식별자에 접근, 수정이 불가능하다 함수안의 함수12345678910111213141516171819def a(): def b(): return 3 return ba():&lt;function __main__.a.&lt;locals&gt;.b()&gt;a()():3def a(): def b(): return 3 return b()a():3# 둘의 차이가 있다 위에것은 함수를 리턴하는 것이고 밑에꺼는 함수 안에서 함수를 호출하여 값을 리턴 Python Tip2 return 값이 있는지 없는지 확인하는 방법 1. type() 2. 값을 저장해서 확인하기{: .notice} Python Tip3 함수를 리스트에 넣어서 계산을 편리하게 할 수도 있다.{: .notice} Python Tip4 jupyter에서는 두 가지로 호출할 수 있는 함수인지 판단 가능 1. callable 2. 출력{: .notice} Python Tip5 Python keyword는 총 35개다.{: .notice} 1234567import keywordcnt = 0for x in keyword.kwlist: cnt += 1print(cnt):35 신기한 함수12345import matplotlib.pyplot as pltplt.plot([1,2,3,4,5],[9,3,7,3,9])# 설명에서 plot[x] =&gt; 여기서 [] 대괄호는 리스트가 아니고 옵션이라는 뜻 추가 공부 동적 프로그래밍에 대해서 찾아보기 피보나치 다른 방법 공부해보기 과제란에 올려주시는거 문제 풀어보기 여태까지 공부했던건 tree형태로 가지치기 map 그려보기 Python 철학 처음부터 끝까지 정독해보기 복습 시간 17시 28분 ~ 19시/ 총 1시간 32분{: .notice} 2019년 5월 7일 화요일 5th&lt;First class function/Higher order function 관계 그림 수정&gt; 일급 객체: git blog, tistory First class function 함수를 값처럼 사용할 수 있다. ## Higher-Order-Function 함수를 리턴값으로 쓰고, 함수를 인자로 쓰는 함수 ## 함수의 인자로 함수가 들어가는 경우 1231. map2. filter3. reduce &#x3D;&gt; 여러개 값을 하나의 값으로 축약 예제1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# mapdef a(x): return x + 1list(map(a,[1,2,3])):[2,3,4]temp = []for i in [1,2,3]: temp.append(i+1)else: print(temp):[2,3,4]# filterdef b(x): return x &gt; 3list(filter(b,[1,2,3,4,5,6])):[4,5,6]# reducefrom functools import reducereduce(lambda x,y:x+y,[1,2,3,4,5]): 15add5 = lambda n: n+5reduce(lambda l, x: l+add5(x), range(10),0): 95# 0 + (0 + 5) =&gt; 5 / 5 + (1 + 5) =&gt; 11 / ..... reduce(lambda l, x: l+add5(x), range(10)): 90# 0 + (1 + 5) =&gt; 6 / 6 + (2 + 5) =&gt; 13 / .....# 초기값 list (O)reduce(lambda l, x: l+[add5(x)], range(10),[]): [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]# 초기값 tuple (O)reduce(lambda x,y : x+(y,), [1,2,3,4], ()): (1, 2, 3, 4)# 초기값 set (X)reduce(lambda x,y : x+&#123;y&#125;, [1,2,3,4], set()): TypeError# 초기값을 주는지 안 주는지에 따라 결과값이 달라진다 filter는 predicate function =&gt; True or False를 되돌려 주는 함수 Python Tip1 shift + tab 했을 때 나오는 *iterables와 iterable는 차이가 있다. 별표가 있는 것은 iterable 여러개가 오고 별표가 없는 것은 한개만 온다{: .notice} ### 별표(*)의 총 7가지 방법 12345671. Unpacking 방법에서 나머지2. Only keyword3. Variable Positional4. Variable Keyword5. Unpacking (벗겨내기, list 쪼개기)6. Unpacking (dictionary)7. import에서 모두 ### Annotation 12345678910def xx(x:int) -&gt; int: return xxx.__annotations__&#123;'x': int, 'return': int&#125;# 타입을 표시해줌xx(3.0)xx('hi')# 둘다 가능 인자에 default값 넣는 꼼수12345n = 0def a(n): return na(n or 3)# 인자에 디폴트를 사용할 수는 없지만 이렇게 흉내는 낼 수 있다 ## 식의 종류 조건식 3 if a &gt; 0 else 6 함수식 (lambda: 익명함수) (lambda x: x + 1)(2) (lambda x, y=1: x + y)(3) (lambda *x: x)(4,1,2) list(map(lambda a:a+8, [1,2,3,4,5])) lambda 파라미터 : return 값 반복식 (x for x in range(10)) Haskell에서 가져옴 1234567891011121314151617181920# 조건식 + 반복식integer = [1,-1,4,0,44,-34,-42,14]['양수' if i &gt; 0 else ('음수' if i &lt; 0 else 0) for i in integer]list(map(lambda i: '양수' if i &gt; 0 else ('음수' if i &lt; 0 else 0), integer)): ['양수', '음수', '양수', 0, '양수', '음수', '음수', '양수']# 조건식 + 반복식 vs 반복식 + 조건식li1 = [x if x%2==0 else None for x in range(10)]li1: [0, None, 2, None, 4, None, 6, None, 8, None]li2 = [x for x in range(10) if x%2==0]li2: [0, 2, 4, 6, 8]# 조건식이 왼쪽에 있을때 오른쪽에 있을때 사용법에 있어서 차이가 있으니 조심하자# 기본적으로 파이썬은 왼쪽에서 오른쪽으로 실행! Python Tip2 Local, Argumentation은 stack에 저장되고 Parameter는 heap영역에 들어간다{: .notice} Python Tip3 default값에 mutable값을 넣으면 값을 공유한다?, 값이 고정된다?{: .notice} 12345678import timetime.time()1557232234.682229 # 수행할 때마다 값이 변한다def a(t=time.time()): return ta()1557232228.6397958 # 값이 고정된다 Python Tip4 bytearray와 frozenset은 리터럴이 없다{: .notice} Return의 3가지 형태1234561. 자기는 변하지만 return이 None- ex) append, extend2. 자기 자신이 변하지 않고 return 값이 있다- ex) count, index3. 자기 자신도 변하고 return 값도 있다- ex) pop mutable에 사용하는 함수중에서 return 값이 None인 경우가 종종 있다. ex) append, extend{: .notice} 123456789101112131415161718192021222324252627# 1def xx(y, x=[]): return x.append(y)# 사실 엉터리 코딩 x.append(y)는 None을 리턴하고,# 함수 밖에서 x 리스트에 접근도 할 수 없기 때문에 but 인자에 기본값 x list 말고# 외부에 선언된 list 넣으면 list 확인 가능# default값을 mutable로 사용하면 heap영역에 들어간다# 1-1def xx(list): return list.append(3)x = [1,2]xx(x)x: [1,2,3]# 2def xx(y, x=[]): x.append(y) return x# xx함수를 호출 할때마다 x 리스트가 계속 변한다def xx(y): x = [] x.append(y) return x# xx함수를 호출하면 원소가 하나인 리스트 반환 파이썬 변수의 유효 범위(Scope) 유효 범위 규칙(Scope Rule)은 변수에 접근 가능한 범위, 변수가 유효한 문맥범위를 정하는 규칙 LEGB123456781. Local : 함수 내 정의된 지역변수2. Enclosing Function Local : 함수를 내포하는 또다른 함수 영역- 함수 안의 함수가 있는 경우 함수와 함수 사이3. Global : 함수 영역에4. Built-in : 내장 영역- 함수 안의 함수가 있는 경우 함수안의 함수에서 함수 밖의 변수를 사용?우선순위 &#x3D;&gt; L &gt; E &gt; G &gt; B LEGB 우선순위 확인 예제123456789101112131415x = 'global'def outer(): #x = \"local\" def inner(): #nonlocal x #x = \"nonlocal\" #print(\"inner:\", x) return x inner() #print(\"outer:\", x) return xouter() Python Tip5 함수 중첩은 3번 이상 하지 않는 것이 좋다.{: .notice} 신기한 기능123456import seaborn as snstips = sns.load_dataset('tips')tips.head(10) # 앞에 10개만 보여줘tips.tail(10) # 뒤에 10개만 보여줘tips.sample(10, replace = True) # 랜덤으로 10개 보여줘 랜덤 10개 추가공부 변수, 인자와 힙, 스택간의 관계 복습 시간 19시 10분 ~ 21시 40분 / 총 2시간 30분{: .notice} 2019년 5월 9일 목요일 6th함수형 패러다임멀티 프로세싱 기법에 최적화된 패러다임 빅데이터 처리시 효율적이다 함수형 프로그래밍의 특징1234567891. 코드가 간결해진다- 내부 구조를 몰라도 input, output만 알면 사용 가능2. 수학적으로 증명이 가능하다3. for, while문을 자제하고 iter를 사용한다4. 수학적 증명이 필요하기 때문에 구현이 어렵다- 단, python에서는 multi paradiam이기 때문에 적절히 혼용 가능5. 디버깅, 테스트가 용이하다6. 모듈성, 결합성이 있다.7. mutable은 처리하지 않는다 반복을 줄이는 5가지 방법(for문을 최대한 쓰지 않고) 1234567891. Iterator- 메모리 효율적, 속도 빠름- 실행시에 메모리 할당2. Generator3. Comprehension- for를 쓰지만 for를 쓰지 않는 기법4. Recursive function- 메모리 효율, 속도면에서 성능이 좋지않아 사용안함5. map, filter, reduce iterable 1. iterator로 바꿀 수 있는 2. 순회, 반복가능 (요소 하나씩 뽑아냄) 3. for 뒤에 사용할 수 있는 container{: .notice} 왜 함수형 패러다임에서 반복을 줄여야 하는가?for문 처럼 대입하는 것은 함수형 패러다임에 맞지 않고 수학적 증명과는 거리가 있기 때문이다. Iterator데이터 스트림을 표현하는 객체, next()메소드를 사용하여 다음 요소를 가져온다 12345678910111213141516a = [1,2,3]b = iter(a)next(b):1# 실행할 때마다 index 0번지 부터 하나씩 뽑아낸다# iterator를 객체화하면 iterator의 성질도 잃고 객체화 하기 전 iterator의 요소 전부를 뽑아냄으로 주의!a = [1,2,3]b = iter(a)next(b): 1list(b) # tuple(b), set(b) 다 똑같음: [2,3]next(b): StopIteration Iterator vs Iterable1234from collections.abc import Iterable, Iteratorset(dir(Iterator))-set(dir(Iterable)): &#123;'__next__'&#125; GeneratorIterator를 생성해주는 Function, 그리고 일반 함수와 비슷해 보이지만 Generator는 yield를 포함한다는 점에서 차이가 있다 두 가지 방법으로 만들 수 있다 generator 표현식(tuple) yield 1234567891011121314# tuple로 만들기a = (x for x in range(10))a: &lt;generator object &lt;genexpr&gt; at 0x000001EBD55D0DE0&gt;# yield로 만들기def x(): yield 1 yield 2y = x()next(y):1 주의 iterator와 generator는 scope를 초과하면 StopIteration 에러가 뜬다.{: .notice} file을 불러오면 generator 처럼 행동한다.{: .notice} 12345x = open('file.txt')next(x): '안녕\\n'next(x): '반가워\\n' reversed 원본 데이터를 뒤집고 iterator로 만드는 함수 123456789rev = reversed([1,2,3,4])type(rev): list_reverseiteratornext(rev): 4list(rev): [3,2,1] Iterator vs Generator &amp; Generator vs FunctionIterator vs Generator Iterator는 반복가능한 객체 그리고 데이터 스트림을 표현하는 객체라고 한다. 예를 들어 list는 반복가능한 자료형 즉 iterable이지만 iterator는 아니다. 12for x in [1,2,3]: print(x) 이처럼 in 다음에 iterable이 오면 반복해서 요소 하나씩 꺼낼 수 있긴 하다하지만 list는 iterator는 아니라고 했다그렇다면 어떻게 list가 iterator처럼 처리되는가? 그 이유는 in 다음에 iterable이 오면 iter없이 iterator로 변환 해주기 때문이다Generator는 iterator를 생성해주는 Function 따라서 Generator와 iterator는 비슷하다 하지만 역할이 다르기 때문에 명칭도 다른것!생성 방식에서 차이가 있고 Iterator는 객체 Generator는 함수Generator는 tuple, yield로 만들고 Iterator는 liter() 함수로 만든다 Generator vs Function Generator Iterator를 만들어주는 것 반복 가능한 객체를 만들어주는 함수 12345678def generator(): while True: yield from [1,2,3,4] # Cycling 기법e = generator()next(e):1 # 실행할 때마다 1부터 4까지 계속 반복해서 return# yield는 return과 비슷하다고 생각하면 된다 일반적으로 함수는 사용이 종료되면 결과값을 호출한 곳에 반환해주고 함수 자체를 종료 시킨 후 메모리상에서 사라진다 하지만 yield를 사용할 경우 그 상태로 정지 되며 반환 값을 next()를 호출한 쪽으로 전달한다함수 호출이 종료되면 메모리상의 내용이 사리지지 않고 다음 함수 호출까지 대기한다다음 함수 호출이 발생할 경우 yield이후 구문부터 실행된다 여기서 generator를 사용하는 이유를 알 수 있다 generator를 사용하면 호출한 값만 메모리에 할당되므로 메모리를 효율적으로 사용할 수 있게된다이러한 기법을 Lazy Evaluation이라고 한다 Lazy Evaluation은 계산 결과 값이 필요할 때까지 계산을 늦추는 방식이다 Lazy Evaluation은 속도가 느리다는 단점이 있지만 파이썬에서는 내부적으로 최적화 되어 있어 속도가 빠르다 참고: tistory ComprehensionIterable한 객체를 생성하기 위한 방법 1231. List2. Set3. Dictionary 123456789101112131415161718# list# for 앞에는 식이 오면된다a = [(x,y) for x in range(10) for y in range(20)]: [(0,0),(0,1),(0,2),......(9,19)]# setb = &#123;x+1 for x in range(10) if &gt; 5&#125;: &#123;7, 8, 9, 10&#125;# dictionaryc = &#123;x:1 for x in range(10) if x&gt;5&#125;: &#123;6: 1, 7: 1, 8: 1, 9: 1&#125;# generator 표현식 (tuple)d = (x for x in range(10))d: &lt;generator object &lt;genexpr&gt; at 0x000001EBD5645DE0&gt; Recursive function재귀함수 123456def fib(num): if num &lt; 3: return 1 return fibB(num-1) + fibB(num-2)fib(10) # 10번째 항 (1 1 2 3 5 8 13 21 34 55): 55 itertools12341. cycle2. count3. islice4. chain cycle12345678910from itertools import cyclefor x in cycle(iter([1,2,3])): print(x) if(x==3): break:123 countislicechainall, any all은 전부다 True일때 True를 반환하고 False가 하나라도 있으면 False를 반환한다. any는 하나라도 True이면 True를 반환하고 전부다 False이면 False를 반환한다. 1234567891011121314# allall_pred = lambda item, *tests: all(p(item) for p in tests): all_pred([1,2,3], sum, max): Trueall_pred([0,1,2,3], sum, min): False# anyany_pred = lambda item, *tests: any(p(item) for p in tests)any_pred([0,1], sum, min): Trueany_pred([0,1], min): False 복습 시간 18시 ~ 19시 50분/ 총 1시간 50분{: .notice} 2019년 5월 10일 금요일 7th함수의 중첩으로 가능한 것들 121. Closure2. Decorator Closure 함수를 중첩시키고 함수를 리턴하는 함수. 클로저는 보통 함수를 쉽게 변형할 수 있는 기법이다. 123456789101112def add(x): def addd(y): return x + y return addd# 3더해주는 함수add(3)(10): 13# 4더해주는 함수add(4)(10): 14 Closure: github blog Decorator 함수나 클래스를 추가, 수정해서 재사용 가능하게 해주는 것 데코레이터를 사용하려면 함수 중첩이 있어야 하고, 함수를 파라미터로 받아야 하고, 중첩된 inner 함수를 return 해야 한다. 예제를 통한 decorator 이해하기중첩 X, 함수 리턴 X 일때12345678910111213141516171819202122232425262728def login_check(fn): id=input('id: ') if(id=='jh'): print(\"jh님 안녕하세요\") fn() else: print('존재하지 않는 회원입니다')@login_checkdef home(): print('jh님의 home page 입니다')id: [jh ] # home 함수 선언시 input창이 뜬다: id: jh jh님 안녕하세요 jh님의 home page 입니다# 다른 아이디를 입력했을 때id: [hj ]: id: hj 존재하지 않는 회원입니다.callable(home): Falsecallable(login_check): True 결론 데코레이터 아님. 함수 return X, 문자열 return일 때12345678910111213141516171819202122def login_check(fn): def inner(): id = input('id: ') if(id=='jh'): print(\"jh님 안녕하세요\") fn() else: print(\"존재하지 않는 회원입니다\") print('ㅋㅋㅋㅋ') return 'a'@login_checkdef home(): print('jh님의 home page 입니다'): ㅋㅋㅋㅋcallable(home): Falsecallable(login_check): True 결론 당연한 결과지만 login_check함수 안에서 inner 함수를 return 하지 않으면 inner함수를 사용할 방법이 없다. 그리고 함수위에 ‘@login_check’을 사용하면 @밑으로 함수선언을 하게되면 @밑 함수는 ‘@login_check’의 인자로 들어가게 된다.결국 ‘@함수이름’의 return값이 함수이름이 아니게되면 @밑에 선언된 함수는 not callable이게 된다.따라서 데코레이터 아님. 함수 return X, 함수 호출 return 일때123456789101112131415161718192021222324def login_check(fn): def inner(): id = input('id: ') if(id=='jh'): print(\"jh님 안녕하세요\") fn() else: print(\"존재하지 않는 회원입니다\") return inner()@login_checkdef home(): print(\"jh님의 home page 입니다\") : id: [jh ] id: jh jh님 안녕하세요 jh님의 home page 입니다: id: [hj ] id: hj 존재하지 않는 회원입니다callable(home): False 함수 return X, 문자열 return일 때와 결과가 같다. 이로써 ‘@login_check’을 사용하면 밑에 선언된 함수는 login_check함수의 인자로 들어가 login_check함수의 return 값을 반환한다는 사실이 확실해졌다.login_check함수의 return 값은 inner함수 호출이고 inner함수의 호출값의 return은 None 이기 때문에 home함수의 return 값은 None 따라서 데코레이터 아님. 어노테이션 X1234567891011121314151617181920212223242526def login_check(fn): def inner(): id = input('id: ') if(id=='jh'): print(\"jh님 안녕하세요\") fn() else: print(\"존재하지 않는 회원입니다\") return innerdef home(): print(\"jh님의 home page 입니다\")home(): jh님의 home page 입니다login_check(home)():id: jhjh님 안녕하세요jh님의 home page 입니다login_check(home)():id: hj존재하지 않는 회원입니다 결론 home함수는 따로 작동하기 때문에 기능확장이라 할 수 없어서 데코레이터가 아님. 함수 파라미터 O, 함수 중첩, 함수 이름 return O1234567891011121314151617181920212223def login_check(fn): def inner(): id = input('id: ') if(id=='jh'): print(\"jh님 안녕하세요\") fn() else: print(\"존재하지 않는 회원입니다\") return inner@login_checkdef home(): print(\"jh님의 home page 입니다\")home(): id [jh ] id: jh jh님 안녕하세요 jh님의 home page 입니다home(): id [hj ] id: hj 존재하지 않는 회원입니다 결론 데코레이터 맞음! (home함수에 login_check함수 기능 추가) 데코레이터 기능 수정하기1234567891011121314151617def trans_odd(fn): def inner(x): print('홀수 입니다') result = fn(x+1) return result return inner@trans_odddef odd(x): if (x%2==0): return \"홀수 입니다\" else : return \"홀수가 아닙니다\"odd(4): '홀수가 아닙니다'odd(3): '홀수 입니다' Closure vs Decoratorpartial 부분을 대체하여 클로저 처럼 사용하는 함수 12345from functools import partialadd3 = partial(add,3) # add의 두개 인자중 하나를 3으로 대체add3(7): 10 Python Tip1 locals(), globals() 함수는 함수내에서 사용하면 메모리상에 올라간 local, global 변수를 각각 확인 할 수 있다{: .notice} 123456789101112x = 10def a(): y = 20 def b(): a = 1 print(locals()) b = 2 return b()a():&#123;'a':1&#125;# b = 2는 print문 출력 이후에 있기 때문에 locals에 포함되있지 않다 선언할 때는 모든 것이 메모리에 할당 되지만 실행할때는 순서대로 할당되기 때문이다 name, namespace, module 그리고 namename은 말 그대로 이름을 붙여주는 즉, 변수명 혹은 식별자라고 생각하면 된다module은 파이썬 코드를 담고 있는 파일이다, 좀 더 자세하게 말하면 클래스, 함수, 변수명의 리스트가 들어 있다고 보면 된다 namespace는 names(변수명들)을 담을 수 있는 공간이다, 모듈은 자신의 유일한 namespace를 갖고 있으며 모듈의 namespace이름은 보통 모듈이름과 같다. 그래서 동일한 모듈내에서 동일한 이름을 가지는 클래스나 함수를 정의할 수 없다. 또한 모듈은 각각 독립적이기 때문에 동일한 이름을 갖는 모듈을 갖을 수 없다. > import를 통해 namespace와 __name__에 대해서 자세히 알아보자 import 방법은 3가지가 있다12341. import &lt;module_name&gt;- 모듈의 name을 prefix로 사용함으로써 모듈의 namespace에 접근할 수 있다2. from &lt;module_name&gt; import &lt;name,&gt;3. from &lt;module_name&gt; import * 12345678910111213141516171819202122231. import &lt;module_name&gt;import syssys.path# sys는 모듈, path는 sys모듈의 namespace에 담겨 있는 name# 모듈 prefix sys를 통해 namespace path에 접근2. from &lt;module_name&gt; import &lt;name,&gt;from sys import pathpathsys.path# 모듈 prefix를 사용하거나 사용하지 않고 둘다 접근 가능하다# 단, del path를 하거나 name을 재정의 하게되면 모듈의 name을 사용할 수 없게된다# 몇개의 name만 필요하고 name를 명확하게 구분할 수 있는 상황에서는 써도 무관하다3. from &lt;module_name&gt; import *from sys import*sys.pathpath# 2번방법과 동일, 그러나 모듈에 있는 모든 name을 직접 현재 namespace로 가져오게된다# 말할 것도 없이 전체를 import하면 name을 쓰는데 제약이 많이 생긴다 Namespace Binding: slideshare name import를 하면 해당 모듈의 names를 namespace에 dict타입으로 할당하는 것을 보았다이때 import한 모듈의 name은 파일명이 된다 12345from sys import *sys.__dict__ # namespace 불러오기'__name__': 'sys', '__doc__': \"This module.......... 이번엔 import를 하지 않고 main script(최상위 스크립트 환경)에서 직접 shell에서 실행하는 경우에 python interpreter가 최초로 파일을 읽어 실행하는 경우를 생각해보자 이때는 모듈이름 해당 파일 이름이 아닌 __main__가 된다 123__name__'__main__' 따라서 만약에 ‘이 파일이 interpreter에 의해 실행되는 경우라면’ 이라는 의미를 갖는다 1234567if __name__ == '__main__': main()if __name__ == '__main__': print 'This program is being run by itself'else: print 'I am being imported from another module' name의 의미 : tistory Python의 모든 것은 Object(객체)이다Object는 python이 data를 추상화 한 것이다쉽게말해 프로그래밍으로 구현될 대상, 현실에 존재하거나 상상가능한 대상을 특징지어 구현될 대상이라고 할 수 있다그리고 python 프로그램의 모든 data는 객체나 객체간의 관계로 표현된다 John von neumann’s stored program computer model을 따르고 또 그 관점에서 코드 역시 객체로 표현된다 객체를 구현하려면?객체를 구현하기 위한 설계도 및 틀을 Class(클래스)라고한다Class를 실제로 프로그래밍할때 사용하려면 클래스 선언, 메모리 할당, mapping 3가지 단계가 필요하다이해를 돕기 위해 java의 경우를 예로 들겠다 1234567891011121314package test;import test.Add; // 1. 선언된 클래스 import (클래스 선언)public class Test&#123; public static void main(String[] args)&#123; Add add = null; // 참조변수 선언 add = new Add(); // 참조변수에 인스턴스에 대한 참조(참조값) 할당 //Add add = new Add(); 위와 동일 // 메모리에 생성되어 저장된 객체 처리 가능 // add는 레퍼런스 변수, 인스턴스를 가리키는값 // 참조변수를 사용하여 멤버변수, 메소드 접근가능 System.out.print(add.sum(3,4)); &#125;&#125; 12345671. 클래스 사용을 위해 클래스 선언2. 클래스 사용시 메모리에 생성3. Index table에 참조변수와 메모리 연결을 위한 주소를 매핑하는 참조값이 만들어진다4. 참조값은 JVM이 자동적으로 생성5. 참조값을 사용하게되면 참조값에 연결된 메모리 즉, 인스턴스를 사용한다는 것참조 ≒ 참조값(Hash code) 그렇다면 Python에서 객체의 의미를 살펴보자 1234567891011121314a = 1print(type(a))a = 3.2print(type(a))print(a)a.__class__: &lt;type 'int'&gt; &lt;type 'float'&gt; 3.2 int# Python에서는 선언과 할당을 동시에 하면서# 할당값에 의해 변수의 타입(객체의 타입)이 결정되고 naming된 변수 이름이 인스턴스가 되는 것이다 참조와 참조변수 : tistory None &amp; 객체 객체가 있는지 없는지 구분할때 None을 활용해 확인할 수 있다{: .notice} 주의12345None == False: False# False는 0이라는 값과 매칭되어 있기 때문에 즉, 0이라는 객체이기 때문에# 존재론적 관점에서 None이 아니다. 복습 시간 18시 22분 ~ 20시 / 총 1시간 38분{: .notice} 2019년 5월 13일 월요일 8thClass (클래스) 값 메소드 두 가지로 이루어져있다 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class A: x = 1 def a(self, y): self.y = y return yA.x # 클래스로 클래스 변수 접근a = A() # 인스턴스 생성a.x # 인스턴스 a로 x(클래스 변수)접근vars(a) # 인스턴스 변수 확인a.a(3) # 인스턴스 a로 a() (메소드) 접근vars(a)A.a(a,5) # 클래스로 인스턴스 a와, 5을 인자로 넘겨주고 a함수 접근vars(a) # 인스턴스 변수는 인스턴스마다 고유로 갖을 수 있는 변수 이다: 1 1 &#123;&#125; 3 &#123;'y':3&#125; 5 &#123;'y':5&#125;dir(A)dir(a): ['__class__','__dict__',.......,'a','x'] ['__class__','__dict__',.......,'a','x','y']class B: x = 2 def b(): print('Access class')B.b()b = B()b.b(): Access class TypeErrorclass B: x = 2 def b(self): print('Access instacne')B.b()b = B()b.b()B.b(b): TypeError Access instance Access instance Instance (인스턴스)클래스를 사용하려면 인스턴스화 해야한다 인스턴스는 클래스의 값과 메소드에 접근이 가능하다 123456789101112class A(object): # 기본적으로 class는 object라는 클래스를 상속받는다 # 명시하지 않아도 default로 상속한다 def __init__(self): print('init') # object는 공통적인 속성들을 모아둔 class(추상화, 상속)# init은 내부적으로 인스턴스화 할때 호출함 / 생성자라고도 한다# init의 추상화 내용이 마음에 들지 않는 경우 변경 가능함(다형성) A() # 클래스를 호출하면 인스턴스 객체를 반환한다: init &lt;__main__.A at 0x23b6c143a90&gt;a = A() # 클래스를 호출함으로써 인스턴스 할당 # 인스턴스화를 하면 클래스에 정의되어 있는 기능 사용할 수 있다 클래스 변수 vs 인스턴스 변수 클래스 변수는 모든 인스턴스들이 어트리뷰트와 메서드를 공유한다. 반면 인스턴스 변수는 각 인스턴스 별로 개별적인 값을 갖는다. 인스턴스는 클래스내에 정의된 모든 것을 사용할 수 있지만, 클래스는 여러 인스턴스를 생성하기 때문에 인스턴스 변수에 접근 할 수 없다. 예제로 살펴보기123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116class A: a = 1 # class variable, attribute def __init__(self, y): self.y = y # instance variable, attribute# 접근 예제class A: x = 1 y = 2 def add(self, x, y): sum = x + y self.sum = 20 return suma = A()aa = A()a.add(3,4)aa.add(5,6)A.add(a, 10, 20)vars(a)a.sumaa.sum = 0vars(aa)A.sum : 7 11 30 &#123;'sum':20&#125; 20 &#123;'sum': 0&#125; AttributeError # 클래스로 인스턴스 변수에 접근했기 때문class B: x = 1 y = 2 def sum(self,x, y): sum = x+y self.sum = 20 return sumb = B()b.sum(1,2)B.sum(b, 3, 4)b.sumB.sumvars(b)vars(B)dir(b): 3 7 20 &lt;function __main__.B.sum(self,x,y)&gt; &#123;'sum': 20&#125; mappingproxy(&#123;'__module__': '__main__', 'x': 1, 'y': 2, 'sum': &lt;function __main__.B.sum(self, x, y)&gt;, .....&#125;) ['__class__', ......, 'sum','x','y']# 클래스변수가 mutable 일때 주의class C: tricks = [] def __init__(self, name): self.name = name def add_trick(self, trick): self.tricks.append(trick)a = C('jh')b = C('other')a.add_trick('first')a.tricksb.tricks: ['first'] ['first']# 인스턴스 별로 개별 리스트 변수를 만들고 싶다면 인스턴스 변수에 리스트 할당해야함class D: def __init__(self, name): self.tricks = [] self.name = name def add_trick(self, trick): self.tricks.append(trick)a = D('jh')b = D('other')a.add_trick(1)a.add_trick(2)b.add_trick('first')b.add_trick('second')a.tricksb.tricks: [1, 2] ['first', 'second'] 실행 순서 메소드와 변수가 이름이 같을때 변수를 먼저 접근하기 때문에 주의 해야 한다{: .notice} self 는 인스턴스라고 생각하면 된다. 메소드의 인자로 self가 있는건 self 자리에 인스턴스를 인자로 넘겨받아 해당 함수를 접근해서 사용 가능하게 된다는 의미로 받아들이면 된다{: .notice} Type casting a = list({1,2,3}) 리스트 클래스의 괄호 안에 dict타입을 넣게 되면 리스트 타입으로 변경된다. 파이썬에서는 타입 변경이 없기 때문에 타입 변경시에는 클래스 안에 인자로 넣어 인스턴스화 하여 바꿔준다. 단, 모든것이 되는것은 아니다{: .notice} 123456789101112a = int('0')a: 0# 원래는 문자를 정수형으로 타입 변환이 되지 않지만# 문자형으로 된 숫자를 정수형 타입으로 변환되는 경우가 몇가지 있다# 이는 init으로 바꿀 수 있게 해둔 것이다 (특수한 경우이다)b = int('b'): ValueError# invalid literal for int() with base 10: 'b'# 기본적으로 문자를 정수형으로 바꿀 수 없다. 클래스 밖에 있는 함수를 클래스의 지역 변수에 할당 할 수 있다1234567891011121314151617181920212223242526272829303132333435363738def out(self, x): self.array.pop(x) return self.arrayclass Array: def __init__(self): self.array = [] def add(self, x): self.array.append(x) def add5(self, x): # 클래스 내에 다른 함수를 호출 가능 self.add(x+5) return self.array pop_method = outarray = Array()array.add(1)array.add(2)array.add(3)vars(array): &#123;'array': [1, 2, 3]&#125;array.pop_method(0): [2, 3]vars(array): &#123;'array': [2, 3]&#125;array.array: [2, 3]array.add5(1): [2, 3, 6] classmethod, staticmethod1234567891011121314class A: a = 1 def __init__(self,y): self.y = y def getx(self): return self.y @classmethod def getxx(cls): # class method print('a') @staticmethod # 똑같이 함수 처럼 사용 def y(cls): print('b') 객체 지향의 특징1234567891011121. 캡슐화- 재활용 가능- 파이썬에서는 기본적으로 외부에서 클래스 접근 가능- descriptor로 클래스 접근을 막을 수도 있다2. 추상화- 구체적인것과 추상적인 것을 분리시킨다- 특징을 뽑아 객체로 구현3. 상속- 추상화의 반대- 추상화한 클래스를 물려받아 구체적으로 원하는 대로 바꾸어 사용 가능4. 다형성- 다양한 결과를 낼 수 있다 Python Tip1 유지보수를 해야 한다고 느끼면 객체지향 프로그래밍을, 멀티프로세스나 다양한 문제를 다양한 방식으로 풀고 디버깅을 편하게 해야 한다고 느끼면 함수형 프로그래밍을 하면 된다{: .notice} Python Tip2 동적으로 인스턴스 변수, 메소드 추가 가능 but 좋지 않은 방식{: .notice} 123456789101112131415161718# ex)class Dyn(): name = 'jh' def name(self): print('nothing')dy = Dyn()dyn.d()vars(dy)dy.namedy.name = 'jane'dy.namevars(dy): 'nothing' &#123;&#125; 'jh' 'jane' &#123;'name': 'jane'&#125; Object, TypeObject는 최상위 객체Type는 meta class Naming1. camelCase(카멜 표기법)첫 문자는 소문자로 표기하고, 그 다음 단어의 첫 시작은 대문자로 표기한다 원래는 첫 문자는 대,소문자 구분없었지만 요즘은 소문자로 쓰는 방법이 카멜 표기법 이다ex) helloWorld함수명은 이 표기법을 권장한다. 단 ,소문자 + underscore를 쓰기도 한다 2. PascalCase(파스칼 표기법)첫 문자를 대문자로 표기하고, 그 다음 단어의 첫 시작도 대문자로 표기한다 ex) HelloWorld클래스명은 이 표기법을 권장한다. 단, 이미 만들어져 있는 클래스는 소문자로 시작한다 3. snake_case(스네이크 표기법)한 단어마다 _ (underscore)를 붙여 이어나가는 표기법이다 ex) hello_world모듈은 이 표기법을 권장한다. 내장 함수도 보통 스네이크 표기법을 따른다 4. 전부 대문자전부 대문자를 쓸 경우 상수처럼 쓴다 (관례)ex) NUMBER = 10 c.f 패키지는 소문자로 구성한다 복습 시간 18시 30분 ~ 20시 20분 / 총 1시간 50분{: .notice} 2019년 5월 14일 화요일 9thDesign pattern20 ~ 30가지가 있다 주로 사용하는 coding 방식, 웹에서 주로 이용 (MVC 패턴 같은 것들) Class inheritance12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Door: colour = 'brown' def __init__(self, number, status): self.number = number self.status = status @classmethod def knock(cls): print(\"Knock!\") @classmethod def paint(cls, colour): # 클래스, 인스턴스 모두 사용 가능하고 cls.colour = colour # 클래스 변수 바꾼다 # 클래스로 접근한다 / 클래스만 값에 접근 가능 @classmethod def paint2(cls, number): # number는 인스턴스 변수 cls.number = number # classmethod는 클래스 변수만 바꿀 수 있다 def open(self): self.status = 'open' def close(self): self.status = 'closed'class SecurityDoor(Door): passDoor.knock()door = Door(1, 'open')vars(door)door.knock()door.paint('red') # 인스턴스로 클래스 변수 바꿀 수 있음 (@classmethod)door.colourDoor.colourdoor.paint2(2)door.numberDoor.paint2(3) # 클래스만 인스턴스 변수 바꿀 수 있음 (@classmethod)door.numberDoor.number: Knock! &#123;'number': 1, 'status': 'open'&#125; Knock! 'red' 'red' 1 1 3 mappingproxy클래스를 상속 받으면 원래 클래스 변수를 공유한다※ 메모리 번지를 공유 1234567sdoor = SecurityDoor(1, 'closed')print(SecurityDoor.colour is Door.colour) print(sdoor.colour is Door.colour):True True Composition (합성) 상속을 하지 않고 클래스내에 객체를 불러와 다른 클래스의 일부 기능을 사용하는 방법. 123456789101112131415161718192021class SecurityDoor: locked = True def __init__(self, number, status): self.door = Door(number, status) # Door의 객체를 갖게 한다 def open(self): if self.locked: return self.door.open() def __getattr__(self, attr): # try except와 비슷 return getattr(self.door, attr) # Door의 attr를 가져와라 (상속을 비슷하게 사용)class ComposedDoor: def __init__(self, number, status): self.door = Door(number, status) def __getattr__(self, attr): # 없으면 가져와라 return getattr(self.door, attr) # 바꾸지 않고 불러와서 사용할 때 123456789class A: x = 1a = A()hasattr(a,'x')getattr(a,'x'):True 1 ※ Design pattern에서는 상속대신 합성을 주로 사용한다 Composition : blog 예외처리문 Python의 철학중 양해를 구하기보다 용서를 구하기가 더 쉽다라는 것이 있다. 이처럼 Python에서 예외처리는 빠질 수 없는 부분이다. 123하지만 DataScience 분야에서는 많이 사용하지는 않는다.웹이나 자동화 등 사용자로부터 입력을 받거나 외부 조건에 의해 오류가 많이 날 수밖에 없는 환경에서는 굉장히 중요하다따라서 오류가 나더라도 중단하지 않고 실행을 시켜야 하는 경우에 대비해서 예외처리문을 삽입하는 것이다 예외처리 구조1234567891011a = &#123;'a':1&#125;try: t = a['b']except: # 에러가 나면 실행 / 에러종류에 따라 여러개 만들 수 있음 print('except')else: # 에러가 나지 않으면 실행 print('else')finally: # 에러 상관없이 실행 print('finally')# try, except가 예외처리의 필수 응용123456789101112131415161718192021222324252627a = &#123;'a':1&#125;try: t = a['n']except : print('all')except KeyError: print('except')# SyntaxError =&gt; except 혼자 오는 것은 마지막에 와야 한다a = &#123;'a':1&#125;try: t = a['n']except KeyError as f: # 에러에 대한 상세 표시 print(f)except: print('except'):'n'a = &#123;'a':1&#125;try: t = a['n']except Exception as f: # Exception 상속(상위 에러) print(f)except: print('except') syntax error, runtime error syntax error는 구문오류로 실행자체가 안된다, runtime error는 실행은 되지만 값이 나오지 않는다{: .notice} 에러를 강제로 발생시키는 방법1234567891011121314151617def x(a): if a &gt; 0 : raise else: raise SyntaxErrorx(3)x(-3): RuntimeError SyntaxErrora = 3assert a &gt; 4AssertionError# 해당 조건이 만족하지 않으면 에러 발생 다른 사람 것을 고쳐 쓰는 방법123451. 상속후 오버라이딩2. 데코레이터# 오버로딩은 같은 이름의 메소드를 가지면서 매개변수 유형은 다를때 서로 다른 메소드로 간주하는 것# 파이썬에서는 오버로딩이 지원되지 않아 같은 이름의 메소드를 정의할경우 재할당이 된다 Mangling 맹글링은 소스 코드에서 선언된 함수 또는 변수의 이름을 컴파일 단계에서 컴파일러가 일정한 규칙을 가지고 변형하는 것을 말한다. 이는 보통 객체 지향에서 오버로딩시 함수의 이름이 같고 파라미터만 다를때 알아서 구별할 수 있도록 하는데 사용된다.{: .notice} 복습 시간 17시 30분 ~ 19시, 20시 ~ 20시 30분 / 총 2시간{: .notice} 2019년 5월 16일 목요일 10thDuck typing미운오리새끼 이야기에서 유래가 되어 오리가 아닌데 오리처럼 행동을 하면 오리라고 간주한다는 개념이다 타입을 미리 정하지 않고 실행되었을 때 해당 Method들을 확인하여 타입을 정한다 장점 타입에 대해 자유롭다 상속을 하지 않아도 상속을 한것처럼 클래스의 메소드 사용이 가능하다 단점 원치 않는 타입이 들어 갈 경우 오류가 발생할 수 있다 오류 발생시 원인을 찾기 어려울수 있다 1234567891011121314151617181920212223242526class Airplane: def fly(self): print(\"Airplane flying\")class Whale: def swim(self): print(\"Whale swimming\")def lift_off(entity): entity.fly()def lift_off2(entity): if entity.swim(): entity.fly() airplane = Airplane()whale = Whale()lift_off(airplane)lift_off2(airplane)lift_off(whale)lift_off2(whale): Airplane flying AttributeError Whale swimming AttributeError Duck typing vs InheritancePolymorphism(다형성)12 Monkey patch런타임상에서 함수, 메소드, 속성을 바꾸는 패치. 런타임 실행중 메모리상의 오브젝트에 적용된다. 123456789101112131415161718192021222324252627282930313233343536import matplotliblen(dir(matplotlib)): 109mat1 = set(dir(matplotlib))import matplotlib.pyplot as pltlen(dir(matplotlib)): 172mat2 = set(dir(matplotlib))mat3 = mat2 - mat1len(mat3): 63mat3: &#123;'_cm', '_cm_listed', '_constrained_layout', '_contour', '_image', '_layoutbox', '_mathtext_data', '_path', ...... 'texmanager', 'text', 'textpath', 'ticker', 'tight_bbox', 'tight_layout', 'transforms', 'tri', 'units', 'widgets'&#125; Runtime어떤 프로그램이 실행되는 동안의 시간 그래서 런타임 에러는 ‘어떤 프로그램이 실행되는 동안 발생하는 에러를 말한다 Meta classType=&gt; Class 행동을 지정할 수 있다 ex) 인스턴스를 한개만 만들 수 있게 지정 (싱글톤) Type의 3가지 활용1231. 메타클래스 자체로 사용할 때2. 객체의 클래스 이름을 알아낼 때(함수 type())3. 메타클래스, 클래스를 만들어줄 때 예제로 알아보기12345678910111213141516171819202122232425262728293031323334353637383940class MyType(type): # type을 상속받아 메타클래스를 만듦 passclass MySpecialClass(metaclass=MyType): # 안적어주면 type 상속 passmsp = MySpecialClass()print(type(msp))print(type(MySpecialClass))print(type(MyType)): &lt;class '__main__.MySpecialClass'&gt; # 인스턴스 msp의 클래스명은 MySpecialClass &lt;class '__main__.MyType'&gt; # 클래스 MySpecialClass의 메타클래스는 MyType &lt;class 'type'&gt; # 메타클래스 MyType의 메타클래스는 type# 따라서 메타클래스를 만들기 위해서 type을 상속받아야 한다# lambda 함수식 처럼 클래스도 선언없이 사용할 수 있다A = type('Integer', (int,), &#123;&#125;) # int클래스를 상속받아 A라는 클래스를 생성a = A(3)atype(a): 3 __main__.IntegerB = type('List', (list,), &#123;&#125;)b = B([1,2,3])btype(b): [1,2,3] __main__.ListC = type('multi', (A, B), &#123;&#125;): TypeError# multiple bases have instance lay-out conflict# =&gt; 상속받으려는 두 클래스의 속성이 비슷하여 충돌이 일어나는 경우 다중 상속이 불가하다.# =&gt; 물론 해결하는 방법은 있는 듯 하다 Singleton 인스턴스를 하나만 만들 수 있는 클래스 설정파일을 만드는 객체, 임시저장소 활용할때 쓴다?? 121. Type을 상속받는다2. __call__ (클래스 호출할때 사용함) 1234567891011121314151617class Singleton(type): instance = None def __call__(cls, *args, **kw): if not cls.instance: cls.instance = super(Singleton, cls).__call__(*args, **kw) # super().__call__(*args, **kw) 동일 return cls.instanceclass ASingleton(metaclass=Singleton): passa = ASingleton()b = ASingleton()a is b: True# 싱글톤 인스턴스 a를 만들고 다시 b를 만들었더니 isinstance &amp; issubclass isinstance는 어떤 객체가 특정 클래스인치 판별하는 predicate issubclass는 어떤 클래스가 특정 클래스의 상속을 받았는지 판별하는 predicate{: .notice} 12345isinstance(1,(str,int)) # 두번째 인자는 tuple도 가능issubclass(bool,int): True True getattribute vs getattr vs getattrinstance.attribute(method) getattribute 실행 (getattr) attribute가 없으면 attribute error getattr가 정의 되어 있으면 실행 instance.attribute(variable) 참고 : tistory as import할때 명명법 바꾸기 예외처리문에서 에러에 대한 상세표시(설명할 수 있는 다른 객체로 변화 시켜줌) with 구문 사용할때 파일 내용 할당하기 12345678with open('test.txt', 'w',encoding='utf-8') as f: f.write('ㅎㅎㅎㅎㅎ')with open('test.txt', 'r', encoding='utf-8') as f: print(f.read()): ㅎㅎㅎㅎㅎ# __enter__, __exit__가 정의 되어 있으면 with 사용가능하다 all import할때 포함시키고 싶은 범위를 지정해주는 special method{: .notice} special method : slideshare, &nbsp; git blog _ 7가지 활용12345678910111213141516171819202122232425262728293031323334351. _*- from module import *에 의해 포함되지 않는 변수명명법2. __*__- magic or special method 명명법3. __*- mangling- 클래스내에 __를 사용하여 변수명을 바꿔주는 방법- 이때 외부에서 해당 변수에 접근을 하지 못하는 private 기능을 하는 것처럼 눈속임을 한다4. _- 숫자에 쓰는 언더바- ex) a &#x3D; 100_0005. _ (이름이 중요하지 않지만 관례상 쓸때)for i,_,k in zip([1,2,3],[4,5,6],[7,8,9]): print(i,_,k)for i,_,_ in zip([1,2,3],[4,5,6],[7,8,9]): print(i,_,_) # 주의, 맨 마지막에 쓴 값 출력 (할당하지 않으면)6. _method- private7. _ 맨 마지막에 쓴 값 출력 (할당하지 않으면)a &#x3D; 3a-: 3 3(8). _() # 다른 언어지원할 때- 라이브러리 사용해야 해서 기본 7가지로 생각 추가 복습 다형성 추상클래스 getattribute 복습 시간 20시 ~ 22시 30분/ 총 2시간 30분{: .notice} 2019년 5월 17일 금요일 11thMultiple inheritance(다중 상속)말 그대로 상속을 2개 이상을 하는 것 function 기법 실행 순서를 직접 정할 수 있다 그러나 같은 값을 중복해서 출력하는 경우가 생긴다 123456789101112131415161718192021222324class x: def __init__(self): print('x')class A(x): def __init__(self): x.__init__(self) print('A')class B(x): def __init__(self): x.__init__(self) print('B')class C(A,B): def __init__(self): B.__init__(self) A.__init__(self) print('C')c = C(): X B X A C super super는 상속을 전부 실행하지 않는다 따라서 중복의 문제를 해결할 수 있다. 하지만 super와 function을 함께 사용하면 상속을 전부 실행하지 않는다 1234567891011121314151617181920class x: def __init__(self): print('x')class A(x): def __init__(self): x.__init__(self) print('A')class B(x): def __init__(self): x.__init__(self) print('B')class C(B,A): def __init__(self): super().__init__() # super는 부모 인스턴스를 반환 / 클래스 명,self 생략 가능 print('C')c = C(): X B C only super super는 상속 실행 순서를 자동적으로 지정해준다 super를 사용할때 전부 super를 사용하면 중복 해결, 원하는 값 출력 가능하다 다이아 문제 해결 1234567891011121314151617181920class x: def __init__(self): print('x')class B(x): def __init__(self): super().__init__() print('B')class A(x): def __init__(self): super().__init__() print('A')class C(A,B): def __init__(self): super().__init__() print('C')c = C(): x B A C 왜 실행 순서에 따라 출력되지 않을까? MRO (Method Resolution Order) 메소드 실행 순서를 확인하는 클래스 메소드(인스턴스로 사용 불가) 123456C.__mro__C.mro(): (__main__.C, __main__.A, __main__.B, __main__.x, object) [__main__.C, __main__.A, __main__.B, __main__.x, object] # 반환 타입이 서로 다름 실행 순서는 C -&gt; A -&gt; B -&gt; x 인데 출력 결과는 왜 반대일까? 그 이유는 바로 super사용시 stack에 들어가기 때문이다 ## 다중 상속시 절대 에러가 나지 않게 하는 방법 Mixins특수한 class를 만들어 충돌이 일어나지 않게 다중 상속을 한다 123456789101112131415161718class FirstMixin(object): def test1(self): print(\"first mixin!!!\")class SecondMixin(object): def test2(self): print(\"second mixin!!!\")class TestClass(FirstMixin, SecondMixin): passt = TestClass()t.test1t.test2: first mixin!!! second mixin!!! 다이아 문제 다중 상속시 어느 클래스의 메소드를 상속 받아야 할 지 모호한 경우{: .notice} ## ABC class (Abstract base class) 추상적인 부분은 구현하지 않고 구체적인 부분에서 구현하도록 강제하는 기법 추상 클래스 특징 1231. ABC class를 사용하면 duck typing 문제점을 보완할 수 있다2. 상속받는 클래스는 추상메소드를 구현하지 않아도 클래스 기능은 동작한다3. abc 모듈을 import 해야한다 추상클래스: wikidocs 12345678910# sequence 타입의 조건 (sequence type은 iterable을 상속받아 만들어졌다)class A: x = 1 def __getitem__(self,x): print('A') def __len__(self): print('B')a = A()a[0]: A ABCMeta123456789101112from abc import ABCMeta, abstractmethodclass Y(metaclass = ABCMeta): @abstractmethod def a(self): return 1class A(Y): passa = A(): TypeError 오버라이딩을 하지 않는 경우 에러가 발생하기 때문에 오버라이딩을 강제시킨다 1234567class A(Y): def a(self): return 1a = A()a.a():1 12345678910111213from abc import ABCMeta, abstractclassmethodclass Y(metaclass = ABCMeta): @abstractclassmethod def a(self): return 1class B(Y): def a(self): return 1b = B()b.a(): 1 abstractmethod vs abstractclassmethodduck typing+meta class+abc =&gt; 강려크하다 register123456789from abc import ABCMetaclass MyABC(metaclass=ABCMeta): passMyABC.register(tuple) # tuple처럼 사용assert issubclass(tuple, MyABC)assert isinstance((), MyABC) 좋지 않은 방법이기 때문에 내가 만든 클래스에서만 사용하도록 권장 Descriptor 점(.)으로 객체의 멤버를 접근할 때, 먼저 인스턴스 변수(dict)에서 멤버를 찾는다. 없을 경우 클래스 변수에서 찾는다. 클래스에서 멤버를 찾고 객체가 descriptor 프로토콜을 구현했다면 바로 멤버를 리턴하지 않고 descriptor 메소드(get, set, delete)를 호출한다 Descriptor 구현 방법 3가지 123451. get, set + composition2. Properties3. Decorator 1. get, set + composition123456789101112131415161718192021222324class RevealAccess: def __init__(self, initval = None, name='var'): self.val = initval self.name = name def __get__(self, obj, objtype): print('get') return self.val def __set__(self, obj, val): print('Updating',self.name) self.val = val + 10 def __delete__(self, obj, val): print('안지워짐')class Myclass: x = RevealAccess() y = 5m = Myclass()m.x: getm.x = 20: Updating varm.x: get 30 2. Properties1234567891011121314class C(object): #getx, setx, delx 이름 상관없음 def getx(self): print('AAA') return self.__x def setx(self, value): self.__x = value def delx(self): del self.__x x = property(getx, setx, delx, \"I'm the 'x' property.\")d = C()d.x: AAA AttributeError 3. Decorator1234567891011121314151617181920class D: __X = 3 # 실제값은 __X에 저장 @property def x(self): return self.__Xd = D()d.x():TypeErrorclass D: def __init__(self): self._x = 0 @property def x(self): return self.__x @x.setter #이름은 똑같지만 다른 메모리번지에 할당해주는 역할 def x(self, x): self.__x = x Descriptor 부분은 다시 공부하고 정리하기 Descriptr : slideshare 싱글 디스패치, 멀티 디스패치epiphany 우연한 순간에 귀중한 것들과의 만남, 혹은 깨달음을 뜻하는 통찰이나 직관, 영감을 뜻하는 단어이다. python 공부도 그렇듯 계속해서 하다보면 저절로 내것이 될꺼라 믿는다. epiphany : brunch 복습 시간 22시 30분 ~ 1시 10분 / 총 2시간 40분{: .notice} 디버깅debug package, builtin_functionpdb package12345678x = 1def y(): import pdb; pdb.set_trace() x = x + 1 print(x) y() breakpoint123456x = 1def y(): breakpoint() x = x+1 print(x) 2019년 5월 20일 월요일 열두번째 수업정보의 진화 단계 DIKW : blog 인공지능의 시작과 배경Physical Labor과 Cognitive Labor의 한계를 극복하기 위해 인공지능으로 자동화 시키는 분야가 발달하게 됨 그러나 요즘은 보통 물리적 노동보다는 인지적 관점에서 관심이 쏠리고 있다 아직 인공지능은 이해하는 능력은 부족하지만 인식하는 능력은 사람의 영역 그 이상까지 왔다 지능지식을 이해 인식 추론 학습 생성 해결 결정 할 수 있는 능력 인공지능12345678910&#39;인간을 대체할 수 있는 기계 또는 지능을 갖춘 존재로부터 의사소통, 상황의 상관관계 이해 및 결론 도출 등 인간의 행동을 모방할 수 있는 기술&#39;좁은 의미에서 기계학습이라 볼 수 있다기계학습은 데이터를 넣어주면 프로그래밍된 논리나 규칙을 바탕으로스스로 학습하여 문제해결을 하는 알고리즘을 생성한다deep learning은 인간 신경망을 모델화하여 스스로 데이터 세트를 예측하는 기술이다deep learning은 인식분야에서 정확도가 높지만 인식이외에 기능은 좋지 않다deep learning은 정형화 데이터에서 성능이 좋지 않고 비정형 데이터에서 성능이 좋다 AI, Machine learning, deep learning 인공지능 영역의 분류 인공지능의 문제해결 전략12345678910인간의 인지적 작업을어떻게 Computing Model로 만들어내고그것을 Machine에서 구현하여그 작업을 자동으로 효율적으로 할 수 있게 할 것인가?Computing Model- Theory of computation 컴퓨터 과학의 한 갈래로, 어떤 문제를 컴퓨터로 풀 수 있는지, 또 얼마나 효율적으로 풀 수 있는지- Programmable 파이썬은 연산속도가 느린데 도대체 왜 파이썬으로 AI를 하는가?Numpy가 있기 때문에!Numpy는 속도가 빠르고 사용하기가 쉽다! Numpy는 벡터 연산, 행렬 연산을 효율적으로 쉽게 만들 수 있다Numpy는 속도 개선의 최적화를 하지 않아도 되기 때문에 AI에서 Numpy를 쓰는 것이다 Numpy Numarray와 Numeric이라는 오래된 Python 패키지를 계승해서 나온 수학 및 과학 연산을 위한 파이썬 패키지이다. Numpy 속도가 빠른 이유1234561. C나 Fortran으로 만들어져 속도가 빠르다2. Array기반으로 처리하기 때문에 속도가 빠르다3. 데이터를 1열로 저장해, 효율적인 자료구조 형태를 갖기 때문에 빠르다4. Homogeneous한 Type만을 저장하기 때문에 타입 체크 비용이 들지 않아 빠르다5. 데이터를 메모리에 한번에 올려 처리하기 때문에 속도가 빠르다6. 데이터 구조가 Structured array방식이기 때문에 데이터 접근이 빠르다 Numpy는 벡터 기반이다 1차 Vector (Numpy에서 vector는 방향이 없다고 간주) 2차 Matrics 3차 Tensor python 속도 개선을 위한 방법1234567891011121. Computing Power- GPU- Parallel Computing2. Compiler- Cython- PyPy ....3. Library- Numpy4. Algorithm&#x2F; Data Structure Vectorization123loop없이 벡터연산으로 속도 향상을 하는 방법요즘은 cpu자체에서 vector processor를 지원함수형 패러다임 + 선형대수 기법 Numpy Tip1 python list와 numpy list는 차이가 있다. python은 linked list , type check로 인해 속도가 느리고, numpy 에서는 type이 통일되어 있어 속도가 빠르다{: .notice} Python 문법으로 벡터화 하기 vs Numpy12345678910def x(a,b): return [i+j for i,j in zip(a,b)]x([1,2,3],[4,5,6]): [5, 7, 9]@np.vectorizedef z(a,b): return a + bz([1,2,3],[4,5,6]): array([5, 7, 9]) Numpy 사용하기123456789101112131415161718192021222324252627282930313233343536import numpy as npa = np.array(0)b = np.array([1,2,3])c = np.array([[1,2],[3,4]])d = np.array([[[1,2],[3,4],[5,6]]])abcdtype(a): array(0) array([1,2,3]) array([[1, 2], [3, 4]]) array([[[1, 2], [3, 4], [5, 6]]]) numpy.ndarraya = np.arange(5,25).reshape(4,5)np.max(a)np.min(a): 24 5np.argmax(a)np.argmin(a) # Function 방식: 19 0a.argmax() # Method 방식: 19 Factory Method 객체를 만들어내는 부분을 서브 클래스로 위임해 캡슐화 하는 패턴 타입에 따라 다르게 동작하고 싶을때 사용하는 패턴이다 1234567891011121314import numpy as npnp.array([1,2,3]): array([1, 2, 3])np.array((1,2,3)) # 메소드 방식(Factory Method): np.array(['a', 1])np.ndarray(['a',1]) # 인스턴스 방식(Homogeneous한 타입의 mutable이기 때문에 타입이 다르면 에러가 난다): TypeErrornp.ndarray(shape=(2,2), dtype=float, order='F') # 인스턴스 방식은 랜덤으로 값이 채워진다: array([[1.49769904e-311, 0.00000000e+000], [0.00000000e+000, 5.02034658e+175]]) Endianness 컴퓨터의 메모리와 같은 1차원 공간에 여러 개의 연속된 대상을 배열하는 방법 여기서 바이트를 배열하는 방법을 Byte order라고 한다 1234567891011121314151617181920212223242526272829303132333435363738import numpy as npnp.array(['a', 1]) # little-endian: array(['a', '1'], dtype='&lt;U1')dt = np.dtype(\"&gt;i4\") # big-endiandt.byteorder: '&gt;'a = np.array(['a', 1])a.flags: C_CONTIGUOUS : True # C 저장 방식 F_CONTIGUOUS : True # Fortran 저장 방식 OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : Falseb = np.array([[1,2],[3,4]], order = \"C\")b.flags: C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : Falsec = np.array([[1,2],[3,4]], order = \"C\")c.flags: C_CONTIGUOUS : False F_CONTIGUOUS : True OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False Big-endian 큰 단위가 앞에 오는 경우 최상위 바이트 (MSB - Most Significant Byte)부터 차례로 저장하는 방식 Little-endian 작은 단위가 앞에 오는 경우 최하위 바이트 (LSB - Least Significant Byte)부터 차례로 저장하는 방식 Big-endian VS Little-endian123456789101112131415161718192021빅 엔디언은 사람이 숫자를 읽고 쓰는 방법과 같기 때문에 디버깅 과정에서 메모리의 값을 보기 편하다는 장점이 있다.ex) 0x12345678 &#x3D;&gt; 12 34 56 78로 표현리틀 엔디언은 메모리에 저장된 값의 하위 바이트들만 사용할 때 별도의 계산이 필요 없다는 장점이 있다.ex) 32비트 숫자인 0x2A(16진수)를 표현하면 2A 00 00 00 가 되는데, 하위 바이트를 사용하려고 한다면 앞의 한 바이트만 떼어 내면 된다. (빅 엔디언에서는 하위 바이트를 얻기 위해서는 3바이트를 더해야 한다는 단점이 있다) 보통 변수의 첫 바이트를 그 변수의 주소로 삼기 때문에 이런 리틀 엔디언의 성질은 종종 프로그래밍을 편하게 해준다.또한 가산기가 덧셈을 하는 과정은 LSB로부터 시작하여 자리 올림을 계산해야 하므로 리틀 엔디언에서 가산기 설계가 조금 더 단순해진다.(오늘날의 프로세서는 여러개의 바이트를 동시에 읽어들여 동시에 덧셈을 수행하는 구조를 갖고 있어 사실상 차이가 없다)※ 엔디안 방식은 데이터를 전송하는 네트워크 층에서 중요하게 여겨진다. 서로 다른 방식의 데이터 저장방식을 갖고 통신을 하게되면 엉뚱한 값을 주고 받기 때문이다.빅 엔디언 &#x3D;&gt; Unix의 Risc계열의 프로세서가 사용하는 바이트 오더링 네트워크에서 사용하는 바이트 오더링 앞에서부터 스택에 PUSH 비교연산에서 리틀 엔디언보다 속도가 빠르다리틀 엔디언 &#x3D;&gt; Intel 계열의 프로세서가 사용하는 바이트 오더링 뒤에서부터 스택에 PUSH 계산연산에서 빅 엔디언 보다 속도가 빠르다 출처: tistory, &nbsp; 위키백과 특수 행렬 만들기123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import numpy as np# 영행렬 만들기z = np.zeros([3,3])z: array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])# 단위행렬(항등행렬) 만들기y = np.eye(3)y: array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])# 전치행렬 만들기t = np.array([[1,2,3],[4,5,6],[7,8,9]])t.T: array([[1, 4, 7], [2, 5, 8], [3, 6, 9]])# 일행렬 만들기o = np.ones((5,4))o: array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]])# 원하는 숫자로 행렬 채우기f = np.full((3,3),3)f: array([[3, 3, 3], [3, 3, 3], [3, 3, 3]])# 원하는 행렬 shape 복사해서 일행렬 만들기l = np.ones_like(f)l: array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])# 대각행렬 만들기np.diagonal([[1,2],[3,4]]): array([1, 4])# 상부 삼각행렬np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]]): array([[1, 2, 3], [0, 5, 6], [0, 0, 9], [0, 0, 0]])# 하부 삼각행렬np.tri(4): array([[1., 0., 0., 0.], [1., 1., 0., 0.], [1., 1., 1., 0.], [1., 1., 1., 1.]])np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1): array([[ 0, 0, 0], [ 4, 0, 0], [ 7, 8, 0], [10, 11, 12]])np.linspace(0,30): array([ 0. , 0.6122449 , 1.2244898 , 1.83673469, 2.44897959, 3.06122449, 3.67346939, 4.28571429, 4.89795918, 5.51020408, 6.12244898, 6.73469388, 7.34693878, 7.95918367, 8.57142857, 9.18367347, 9.79591837, 10.40816327, 11.02040816, 11.63265306, 12.24489796, 12.85714286, 13.46938776, 14.08163265, 14.69387755, 15.30612245, 15.91836735, 16.53061224, 17.14285714, 17.75510204, 18.36734694, 18.97959184, 19.59183673, 20.20408163, 20.81632653, 21.42857143, 22.04081633, 22.65306122, 23.26530612, 23.87755102, 24.48979592, 25.10204082, 25.71428571, 26.32653061, 26.93877551, 27.55102041, 28.16326531, 28.7755102 , 29.3877551 , 30. ])np.logspace(1,100): array([1.00000000e+001, 1.04811313e+003, 1.09854114e+005, 1.15139540e+007, 1.20679264e+009, 1.26485522e+011, 1.32571137e+013, 1.38949549e+015, 1.45634848e+017, 1.52641797e+019, 1.59985872e+021, 1.67683294e+023, 1.75751062e+025, 1.84206997e+027, 1.93069773e+029, 2.02358965e+031, 2.12095089e+033, 2.22299648e+035, 2.32995181e+037, 2.44205309e+039, 2.55954792e+041, 2.68269580e+043, 2.81176870e+045, 2.94705170e+047, 3.08884360e+049, 3.23745754e+051, 3.39322177e+053, 3.55648031e+055, 3.72759372e+057, 3.90693994e+059, 4.09491506e+061, 4.29193426e+063, 4.49843267e+065, 4.71486636e+067, 4.94171336e+069, 5.17947468e+071, 5.42867544e+073, 5.68986603e+075, 5.96362332e+077, 6.25055193e+079, 6.55128557e+081, 6.86648845e+083, 7.19685673e+085, 7.54312006e+087, 7.90604321e+089, 8.28642773e+091, 8.68511374e+093, 9.10298178e+095, 9.54095476e+097, 1.00000000e+100])# Randomnp.empty((3,3)): array([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000], [0.00000000e+000, 0.00000000e+000, 4.36754031e-321], [8.70018274e-313, 6.79038653e-313, 1.24610994e-306]]) array 는 몇차원 데이터인지 통칭하는 단어이다. 그리고 return 값에 array가 나오면 Numpy형태라는 뜻. 파이썬에서 사용하는 형태를 Numpy로 바꿔준다. 벡터를 만드는 방식이기도 하다{: .notice} 행렬 연산12345678910111213141516171819202122232425import numpy as npa = np.array([1,2,3,4,5]) # broadcastinga + 3: array([4, 5, 6, 7, 8])a.dot(a) # 내적: 55np.sum(a): 15t = np.array([[1,2,3],[4,5,6],[7,8,9]])np.sum(t, axis = 1) # 행연산: array([ 6, 15, 24])np.sum(t,axis=0) # 열연산:array([12, 15, 18])A = np.array([[1,2],[3,4]])B = np.array([[1,2],[3,4]])A @ B # At sign 연산자 (행렬곱): array([[ 7, 10], [15, 22]]) Python, Numpy 속도 비교12345%timeit np.sum(np.arange(10000000)): 24.6 ms ± 2.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)%timeit sum(range(10000000)): 352 ms ± 6.34 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) 데이터 정보 확인하는 방법12341. dtype2. size3. shape4. ndim 123456789101112import numpy as npa = np.arange(10)a.dtypea.sizea.shapea.ndim: dtype('int32') 10 (10,) 1 Stride 12345678910111213import numpy as npa = np.array([[1,2,3],[4,5,6],[7,8,9]])a.dtype: dtype('int32')a.strides: (12, 4)# 8bit = 1byte# dtype에서 int 32bit라고 나왔기 때문에 byte로 바꾸면 4byte가 되는데# 데이터 하나당 4byte를 차지한다고 보면된다# 따라서 strides에서 맨 앞을 4byte로 나누어주면 그 갯수만큼 하나의 묶음으로 생각한다# 즉, 한 행이 3개 데이터로 구성 되어 있다는 뜻 stride만 바꾸어 shape 자유자재로 바꾸기 123456789101112import numpy as npa = np.arange(10).reshape(2,5)a: array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]])a = np.arange(10).reshape(-1,5)a: array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]])# -1은 자동으로 알아서 하라는 뜻 / 행렬의 크기를 모를때 유용 reshape vs resize12345678910111213141516171819202122232425a=np.array([[0,1],[2,3]])# reshapea. reshape(4,1): array([[0], [1], [2], [3]])a. reshape(1,4): array([[0, 1, 2, 3]])# resizenp.resize(a,(2,3)): array([[0, 1, 2], [3, 0, 1]])np.resize(a,(1,4)): array([[0, 1, 2, 3]])np.resize(a,(2,4)): array([[0, 1, 2, 3], [0, 1, 2, 3]]) 데이터 형태 변환하기12345678910111213141516import numpy as npa.astype('float32'): array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]], dtype=float32)a.astype('int64') : array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=int64) a.astype('bool'): array([[ True, True, True], [ True, True, True], [ True, True, True]]) array는 sequence type sequence type은 indexing, slicing이 가능하다! 123456789101112131415161718192021import numpy as npn = np.arange(10).reshape(5,2)n: array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])n[:,1]: array([1, 3, 5, 7, 9])n[:][1]: array([2, 3])n[1,:]: array([2, 3])n[n&gt;3]: array([4, 5, 6, 7, 8, 9]) Numpy Indexing123451. 일반 indexing2. 콤마3. Fancy indexing4. Masking5. 조건문 (where) 예제1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import numpy as npa = np.arange(25).reshape(5,5)a: array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]]) # 일반 indexingfor x in range(3,5): for y in range(3,5): print(a[x][y], end=\" \") print(): 18 19 23 24# 콤마a[3:,3:]: array([[18, 19], [23, 24]])# Fancy indexinga[[3,4],3:]: array([[18, 19], [23, 24]])# Maskinga[(a &gt; 17) &amp; (a &lt; 20) + (a &gt; 22)].reshape(2,2): array([[18, 19], [23, 24]])b = np.array([[False,False,False,False,False], [False,False,False,False,False], [False,False,False,False,False], [False,False,False,True,True], [False,False,False,True,True]])a[b].reshape(2,2): array([[18, 19], [23, 24]])# 조건문a[np.where((a &gt; 17) &amp; (a &lt; 20) + (a &gt; 22))].reshape(2,2): array([[18, 19], [23, 24]]) nditer1234567891011121314import numpy as npa = np.nditer([1,2,3])next(a): (array(1), array(2), array(3))b = np.nditer([[1,2],[3,4]])next(b): (array(1), array(3))c = np.array([[1,2],[3,4]])d = np.nditer(c)next(d): array(1) 복습 시간 17시 40분 ~ 19시 / 총 1시간 20분{: .notice} 2019년 5월 21일 화요일 13thMasking True, False를 활용해 인덱싱하는 방법 123456789101112131415import numpy as npa = np.arange(10)a &gt; 3: array([False, False, False, False, True, True, True, True, True, True])a[a&gt;3]: array([4, 5, 6, 7, 8, 9])a[(a &gt; 3) &amp; (a &lt; 8)]: array([4, 5, 6, 7])a[[True, True, True, True, True, True, False, False, False, False]]: array([0, 1, 2, 3, 4, 5]) ix_Cartesian product 연산 12345678910111213import numpy as nph = np.arange(25).reshape(5,5)h: array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])h[np.ix_([1,3],[0,1,2,3,4])]:array([[ 5, 6, 7, 8, 9], [15, 16, 17, 18, 19]]) Namedtuple 이름 있는 튜플 만들기sequence tuple 처럼 사용 가능클래스처럼 이름으로 접근가능 123456789101112131415from collections import namedtuplet = namedtuped('AttendanceSheet',['name','attendance'])x=t('jh','yes')x[0]x[1]x.namex.attendancetype(x): jh yes jh yes __main__.AttendanceSheet broadcasting 벡터연산에서 자동으로 크기 맞춰주는 기법 123456import numpy as npa = np.arange(10)a + 1: array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) ufunc(universal function) 범용적인 함수 즉, python, numpy 둘다 있는 함수 but 차이가 있다 1개의 배열에 대한 ufunc 함수123456789101112131415abs,fabs &#x3D;&gt; 절대값ceil &#x3D;&gt; 올림floor &#x3D;&gt; 내림modf &#x3D;&gt; 정수부분과 소수점 부분 분리rint &#x3D;&gt; 올림하거나 내림하거나 5를 기준으로log, log10, log2, log1p &#x3D;&gt; 로그 값 취하기exp &#x3D;&gt; exponential 지수함수 (정확히 어떻게 계산되는지는 모르겠음)sqrt &#x3D;&gt; 루트square &#x3D;&gt; 제곱isnan &#x3D;&gt; nan인지 체크isinfinite &#x3D;&gt; 유한한 수안자 체크logical_not &#x3D;&gt; 모르겠음sign &#x3D; &gt; 0을 제외하고 다 1로 반환 (사실 정확하지 않음)sin, cos, tan &#x3D;&gt; sin, cos, tan값 계산arcsin, arccos, arctan &#x3D;&gt; 역삼각함수 계산 2개의 배열에 대한 ufunc 함수12345678910111213141516add &#x3D;&gt; 각 요소 더하기subtract &#x3D;&gt; 각 요소 빼기multiply &#x3D;&gt; 각 요소 곱하기divide &#x3D;&gt; 각 요소 나눈 값floor_divide &#x3D;&gt; 각 요소 나눈 몫mod &#x3D;&gt; 각 요소 나눈 나머지power &#x3D;&gt; 승 계산 ex) 2,3 &#x3D;&gt; 2의 3 승 : 8maximum, fmax &#x3D;&gt; 더 큰 값minimum, fmin &#x3D;&gt; 더 작은 값greater &#x3D;&gt; 앞 값이 더 크면 True 작으면 Falsegreater_equal &#x3D;&gt; 앞 값이 크거나 같으면 True 작으면 Falseless &#x3D;&gt; greater 반대less_equal &#x3D;&gt; greater_equal 반대equal &#x3D;&gt; 같으면 Truenot_equal &#x3D;&gt; 다르면 Truecopysign &#x3D;&gt; 모르겠음 Python, Numpy ufunc python에서는 동시에 사용 못하지만 numpy에서는 한꺼번에 연산 가능 123456import mathmath.sqrt(4): 2.0np.sqrt((4,9)): array([2., 3.]) 1234np.sqrt([4,9])np.sqrt((4,9))둘다 가능 Numpy Tip1 mutable 성질이 중요하지 않으면 list, tuple 혼용 가능{: .notice} 배열 분할하기, 붙이기123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# split (분할하기)a = np.arange(16).reshape(4,4)a: array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]])np.hsplit(a,2) # 수평축으로 분할(세로, 사실상 수직) (np.split(a,2,axis=1)): [array([[ 0, 1], [ 4, 5], [ 8, 9], [12, 13]]), array([[ 2, 3], [ 6, 7], [10, 11], [14, 15]])]np.hsplit(a,(1,2)): [array([[ 0], [ 4], [ 8], [12]]), array([[ 1], [ 5], [ 9], [13]]), array([[ 2, 3], [ 6, 7], [10, 11], [14, 15]])]np.vsplit(a, 2): [array([[0, 1, 2, 3], [4, 5, 6, 7]]), array([[ 8, 9, 10, 11], [12, 13, 14, 15]])]np.s_[a,b]: (array([0, 1, 2, 3, 4]), array([5, 6, 7, 8, 9]))[1,2,3,4,5][2:5]: [3, 4, 5][1,2,3,4,5][slice(1,5)]: [2, 3, 4, 5]np.arange(10)[np.s_[2:5]]: array([2, 3, 4])# stack (붙이기)a = np.arange(5)b = np.arange(5, 10)np.stack((a,b), axis=1): array([[0, 5], [1, 6], [2, 7], [3, 8], [4, 9]])np.stack((a,b), axis=0): array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]])np.vstack((a,b)): array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]])np.hstack((a,b)): array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])np.column_stack((a,b)) # np.c_[a,b]: array([[0, 5], [1, 6], [2, 7], [3, 8], [4, 9]])np.row_stack((a,b)) # np.r_[a,b]랑 같음: array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) view &amp; copy python은 기본적으로 shallow copy, numpy는 기본적으로 deep copy 123456789101112131415161718192021222324# python에서 deep copy하기import copya = [[1,2,3]]b = copy.deepcopy(a)a[0][1] = 4ba: [[1, 2, 3]] [[1, 4, 3]]# numpy는 기본적으로 deep copya = np.array([[1,2,3],[4,5,6]])b = a.copy()a[0][0] = 4ba: array([[1, 2, 3], [4, 5, 6]]) array([[4, 2, 3], [4, 5, 6]]) ravel &amp; flatten Ravel - Bolero (클래식/디지몬 어드벤처 극장판에서 나오는 노래)ravel은 몇 차원이건 간에 모두 1차원으로 만들어 준다그리고 view 방식이기 때문에 원래 값을 바꾸기 때문에 주의 해야한다flatten은 copy 방식 123456a = np.arange(10).reshape(2,5)a.ravel()a.flatten(): array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) newaxis return이 None이고 차원을 추가한다곱하기 할때에도 활용하는 방법이다.(차원을 맞추어 계산해야 하기 때문) 12345678910111213141516171819202122232425262728293031323334353637a = np.array([[1,2,3],[4,5,6]])aa.shape: array([[1, 2, 3], [4, 5, 6]]) (2,3)# z축에 추가b=a[:,:,np.newaxis]bb.shape: array([[[1], [2], [3]], [[4], [5], [6]]]) (2, 3, 1) ## 평면 두개 # y축에 추가c=a[:,np.newaxis]cc.shape: array([[[1, 2, 3]], [[4, 5, 6]]]) (2, 1, 3) ## 평면 두개# x축에 추가d=a[np.newaxis,:]dd.shape: array([[[1, 2, 3], [4, 5, 6]]]) (1, 2, 3) ## 평면 한개 elementwise product123456a = np.array([[1,1],[0,1]])b = np.array([[2,0],[3,4]])a*b: array([[2, 0], [0, 4]]) 복습 시간 18시 30분 ~ 21시 / 총 2시간 30분{: .notice} 2019년 5월 23일 목요일 14thnewaxis 정리1차원: 방향이 없는 벡터(스칼라)형태의 데이터만 존재, [] 1개 123456import numpy as npa = np.array([1,2,3])a.shape: (3,) # 3개의 데이터가 하나로 묶여 있다고 생각 2차원 : 행렬, 평면, [] 2개 12345678910111213141516import numpy as npa = np.array([1,2,3])a[np.newaxis] # x축 추가 행기준으로 묶기a[np.newaxis].shape: array([[1,2,3]]) # 가장 바깥 [] 소거하고 행갯수 세면 x축 데이터 갯수 # 그 다음 안 [] 소거하고 행갯수 세면 y축 데이터 갯수 (1,3)a[:,np.newaxis] # y축 추가 열기준으로 묶기 (np.expand_dims(a, 1))a[:,np.newaxis].shape: array([[1], # 가장 바깥 [] 소거하고 열갯수 세면 x축 데이터 갯수 [2], # 그 다음 안 [] 소거하고 열갯수 세면 y축 데이터 갯수 [3]]) (3,1) 이 경우는 뭐지? 1234567891011121314151617181920212223242526272829303132import numpy as npa = np.array([[1,2],[4,5,6]])a: array([list([1, 2]), list([4, 5, 6])], dtype=object)a = np.arange(27).reshape(3,3,3)np.swapaxes(a, 0, 2): array([[[ 0, 9, 18], [ 3, 12, 21], [ 6, 15, 24]], [[ 1, 10, 19], [ 4, 13, 22], [ 7, 16, 25]], [[ 2, 11, 20], [ 5, 14, 23], [ 8, 17, 26]]])np.moveaxis(a, 0, 2): array([[[ 0, 9, 18], [ 1, 10, 19], [ 2, 11, 20]], [[ 3, 12, 21], [ 4, 13, 22], [ 5, 14, 23]], [[ 6, 15, 24], [ 7, 16, 25], [ 8, 17, 26]]]) 3차원 : 행렬 중첩, 평면 겹쳐서 직육면체처럼 [] 3개 123456789101112131415161718192021222324252627import numpy as npa = np.array([[1,2,3],[4,5,6]])a[np.newaxis]a[np.newaxis].shape: array([[[1, 2, 3], [4, 5, 6]]]) # 가장 바깥 []소거하고 []x2인 행갯수 세면 x축 데이터 갯수 # [[1,2,3]] 이라는 평면 1개 (1,2,3) # 그 다음 안 [] 소거하고 []x1인 행갯수 세면 y축 데이터 갯수 # 마지막 [] 소거하고 행갯수 세면 z축 데이터 갯수a[:,np.newaxis]a[np.newaxis].shape # 위와 동일: array([[[1, 2, 3]], [[4, 5, 6]]]) (2,1,3) a[:,:,np.newaxis]a[:,:,np.newaxis].shape #: array([[[1], [2], [3]]])(2, 3, 1) tile1234567891011121314import numpy as npa = np.array([1,2,3])np.tile(a,3): array([1, 2, 3, 1, 2, 3, 1, 2, 3])np,tile(a,(2,3)): array([[1, 2, 3, 1, 2, 3, 1, 2, 3], [1, 2, 3, 1, 2, 3, 1, 2, 3]])np.tile(a,[2,3]) # duck typing: array([[1, 2, 3, 1, 2, 3, 1, 2, 3], [1, 2, 3, 1, 2, 3, 1, 2, 3]]) 파일 불러오기loadtxt, genfromtxt12345678910111213141516%%writefile a.csv1,2,34,5,6: Writing a.csvx = np.loadtxt('a.csv', delimiter = ',')x: array([[1., 2., 3.], [4., 5., 6.]])x = np.genfromtxt('a.csv'): array([nan, nan])# loadtxt는 delimiter를 이용해 문자열 구분을 하지 않으면 에러가 나지만# getfromtxt는 nan이라는 출력값을 주고 에러를 발생시키지 않는다 fromfile1234x = np.fromfile('a.csv', sep=',') # \\n을 만나면 종료x: array([1., 2., 3.]) FileFlat 구조가 있는 파일 123451. text file &#x3D;&gt; 확장자 상관없이 열 수 있다.&#x3D;&gt; 데이터 교환시 유용함2. binary file&#x3D;&gt; 연결프로그램에 의존적 123np.savez()np.save() Raw 구조가 없는 파일 12345678910111213141516171819&#96;&#96;&#96;## linear algebra#### WhyPythonIsSlow + open_with 내용 복습https:&#x2F;&#x2F;docs.scipy.org&#x2F;doc&#x2F;numpy&#x2F;user&#x2F;quickstart.html 복습### 설명 보기&#96;&#96;&#96;pythonimport numpy as npnp.lookfor(&#39;shape&#39;): 설명 ~np.info(&#39;shape&#39;): 설명 ~ 복습 시간{: .notice} 2019년 5월 24일 금요일 15thPandas Numpy 기반으로 만들어진 데이터 조작, 분석을 위한 프레임워크 Data Wrangling Tool, 데이터를 불러와 합치고, 간단한 전처리하고, 기초통계 분석하는 프레임워크 Pandas로 할 수 있는 2가지 1231. 기초통계분석 (EDA)2. 전처리- 반정형 데이터를 정형데이터로 바꿔준다 ETL vs Munging ETL(Extract Transform Load)는 개발자 입장에서 하는 파이프라인이고 Munging은 통계분석가 입장에서 하는 파이프라인이라고 생각하면 된다.{: .notice} 데이터 종류1231. 정형 데이터 : Dataframe 객체에 정확하게 컬럼에 집어 넣을 수 있는 데이터2. 비정형 데이터3. 반정형 데이터 데이터 타입 만드는 방법Numpy 방식 (structured array)12345678import numpy as npx = np.array([('jihyuk',25,73.0),('thor',35,85.0),('lion',10,30.0)],dtype=[('name','U10'),('age','i4'),('weight','f4')]) x[0]: ('jihyuk',25,73.0)x[0]['name'] # dict의 key값으로 접근: 'jihyuk' Python 방식 (namedtuple)123456789from collections import namedtuplex = namedtuple('Address',['name','age','weight'])a = x('jh',25,'73.0')a.name # attributea.age: 'jh' 25 Pandas로 기초통계분석하기[첫번째] 데이터 불러들이기123456789import pandas as pddata = pd.read_csv('/Users/SAMSUNG/Desktop/개인공부/AI/AI 이노베이션 스퀘어 기본과정/수업 내용/abc.csv',engine='python')type(data): pandas.core.frame.DataFrame# read 메소드는 flat file 또는 sql format을 dataframe형태로 불러들인다# 첫번째 인자는 불러올 파일의 경로인데 현재 작업파일과 동일한 위치에 있다면 파일이름만 적어줘도 된다# engine = 'python' 이나 encoding = 'cp949'를 인자로 넣어주지 않으면 unicodeerror가 뜬다 filepath_buffer는 read_csv 메소드의 첫번째 인자로 파일경로나, url이 올 수 있다{: .notice} Dataframe 객체는 Numpy에서 structured array방식을 따라 데이터 타입을 생성한다. pandas는 벡터, 행렬연산으로 속도를 빠르게 하기 위해 Numpy방식을 그대로 이어받아 사용한다. 그리고 DataFrame에서 각 열은 단일 데이터 형식만을 저장한다. 따라서 타입체크를 하지 않아 속도가 빠르다. 또한 DataFrame은 dict, attr 두가지 방법으로 모두 접근 가능하다. ex) dataframe.column, dataframe[‘column’]{: .notice} Series 객체는 Dataframe에서 1차원 데이터 한 행이나 한 열, 1차원이기 때문에 방향은 없다. Series는 dataframe 처럼 dictionary 형태로 구성되어 있고 key값으로 index가 자동 생성이 된다.{: .notice} 1234567891011121314import pandas as pddata = np.read_csv('abc.csv', engine='python')data.values: array([['절도', ' 129 ', ' 217 ', ..., ' 1 ', ' - ', nan], ['불법사용', ' - ', ' - ', ..., ' - ', ' - ', nan], ['침입절도', ' 29 ', ' 38 ', ..., ' - ', ' - ', nan], ..., ['화재예방·소방시설설치유지및안전관리에관한법률', ' - ', ' - ', ..., ' - ', ' - ', nan], ['화학물질관리법', ' 1 ', ' - ', ..., ' 3 ', ' - ', nan], ['기타특별법', ' 26 ', ' 226 ', ..., ' 4 ', ' - ', nan]], dtype=object)# dict으로 접근해서 values를 사용하면 numpy format인것을 확인할 수 있다 Series , Vector 차이점Series, Vector 둘다 1차원 데이터에 방향도 없지만 Series는 index가 붙는다 [두번째] 분석하고 그래프 그리기분석하기전 5가지 확인 사항 데이터를 분석하기 전에 분석할 가치가 있는 데이터인지 부터 판단해야 한다! 데이터의 갯수가 충분한지 여부도 체크하고, 내가 불러들일 수 있는 크기의 데이터 양인지 체크하고 편향된 데이터값이 많은지 등등 알고서 분석에 적합한 데이터를 판별해야한다. (데이터가 많으면 많을 수록 분석, 예측시 성능이 좋아진다! 123451. info : 데이터의 기본 정보를 보여준다2. describe : 숫자형태인 데이터에 대해서 기본 통계값을 보여준다3. head : default로 앞에서 5개 데이터만 불러온다 (앞에서부터 보고싶은 데이터 갯수 입력 가능)4. tail : head와 반대로 뒤에서 부터 데이터를 불러온다5. sample : 랜덤으로 하나의 데이터를 불러온다 info, describe로 데이터의 숨겨진 의미 찾기 column 갯수 확인 =&gt; 차원의 저주 고려 데이터 갯수 확인 =&gt; 큰 수의 법칙 고려 미싱 데이터 찾기 =&gt; 미싱데이터를 포함하고 있으면 정확도 데이터 타입 확인 =&gt; 적절한 타입을 썻는지 체크 (category, object는 각각 지원하는 기능이 다르다) data (도로교통공단_시도_시군구별_도로형태별_교통사고(2018) 공공데이터) pandas로 불러오면 rangeindex가 붙는다 info123456789101112131415161718192021import pandas as pddata = pd.read_csv('load.csv', engine = 'python')data.info(): &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 2001 entries, 0 to 2000 Data columns (total 9 columns): 시도 2001 non-null object 시군구 2001 non-null object 도로형태 2001 non-null object 발생건수 2001 non-null int64 사망자수 2001 non-null int64 부상자수 2001 non-null int64 중상 2001 non-null int64 경상 2001 non-null int64 부상신고 2001 non-null int64 dtypes: int64(6), object(3) memory usage: 140.8+ KB# 교통사고 공공데이터 describe1234import pandas as pddata = pd.read_csv('load.csv', engine = 'python')data.describe() head, tail, sample123456import pandas as pddata = pd.read_csv('load.csv', engine = 'python')data.head(3)data.tail(3)data.sample(3) # replace = True 옵션을 주면 복원추출 표준편차 표로 보기 (boxplot) 왜도(skewness), 첨도(kurtosis)왜도 왜도는 데이터가 대칭이 아닌 정도를 나타낸다 왜도의 값이 음수이면 오른쪽으로 치우친 정도를 나타내고 왜도의 값이 양수이면 왼쪽으로 치우친 정도를 나타낸다 첨도 첨도는 데이터가 중간값의 분포도의 정도를 나타낸다 첨도의 값이 3보다 작으면 완만한 분포를 나타내고 첨도의 값이 3보다 크면 뾰족한 분포를 나타낸다 123456789101112131415161718192021import pandas as pddata = pd.read_csv('load.csv', engine = 'python')data.skew()data.kurtosis() # kurt: 발생건수 3.765094사망자수 3.820251부상자수 3.778984중상 3.541237경상 3.847238부상신고 5.351853dtype: float64발생건수 17.881821사망자수 18.509412부상자수 17.783772중상 15.962331경상 18.220330부상신고 40.538785dtype: float64 열 뽑는 4가지 방법12341. dictionary2. attribute3. fancy indexing4. data type Pandas Tip1 데이터 분석시 데이터 조작을 하기위해 할당을 하는 경우에 view방식으로 접근하게되면 원본 데이터도 변경될 수 있으므로 copy방식을 사용해야 한다{: .notice} 행 뽑는 방법121.loc # index 명으로 접근2.iloc # index 숫자로 접근 문제해결 그리고 예측많은 데이터 확보 =&gt; 기초 통계분석 및 전처리 =&gt; 기계학습 및 딥러닝으로 예측 Exploratory Data Analysis 수집한 데이터가 들어왔을 때, 이를 다양한 각도에서 관찰하고 이해하는 과정. 한마디로 데이터를 분석하기 전에 그래프나 통계적인 방법으로 자료를 직관적으로 바라보는 과정이다. nan값 제거1234import pandas as pddata = pd.read_csv('abc.csv',engine='python')data.iloc[4].dropna() 복습 시간 2시간으로 추정{: .notice} 2019년 5월 26일 일요일 Jupyter Notebook 오류 Numpy 예제 100선을 풀기 위해 파일을 불러오는 도중 해당 파일이 Not trusted 문제가 발생했다 Not trusted내가 작성한 파일이 아닌 다른 사람에 의해 만들어진 파일이라서 보안상 문제가 될 수 있어 발생한 오류 인것 같다그래서 열고자 하는 파일이 믿을만하다는 것을 알려주기 위해서 명령 프롬프트를 통해 신뢰할만한 파일이라고 직접 알려줘야 한다 1jupyter trust name.ipynb 위 명령어를 입력하자 not trusted 오류는 발생하지 않았다 페이지를 열기 위한 메모리가 충분하지 않음크롬 브라우저에서 메모리가 부족하다는 것이다. 그래서 쿠키정보를 삭제해보았다. 해결! 그러나 힌트파일이 아닌 정답파일은 파일 자체 내용이 많아서 그런지 아직도 안열린다… 2019년 5월 27일 월요일 16th유니콘이 되려면… Data Wrangling Raw data를 또 다른 형태로 수작업으로 전환하거나 매핑하는 과정. 즉, 여러가지 데이터 포멧을 내가 원하는 데이터 포멧으로 전환하여 사용하기 위한 과정. (Data Munging 이라고도 불린다){: .notice} 그래프 그리기describe로 나오는 값들 그래프로 그리기123456import numpy as npimport pandas as pdimport seaborn as snsdata = pd.read_csv('file.csv', engine='python')pd.plotting.boxplot(data) 정규분포가 되는지 확인하는 그래프 그리기123456import numpy as npimport pandas as pdimport seaborn as snsdata = pd.read_csv('file.csv', engine='python')pd.plotting.scatter_matrix(data) matplotlib inline &amp; notebook12345%matplotlib inlinedata.boxplot()%matplotlib notebookdata.boxplot() inline notebook seaborn으로 그래프 이쁘게 그리기1234import seaborn as snsdata = pd.read_csv('file.csv', engine='python')sns.pairplot(data) Header name 바꾸기 (전처리 과정중 일부)123456import pandas as pddata = pd.read_csv('file.csv', engine='python')data.rename(&#123;0:'sl',1:'sw',2:'pl',3:'pw','class':'class_'&#125;,axis=1,inplace=True)# inplace True하면 자기자신이 바뀜 짝을 이뤄 그래프 그리기 열(column)에 object가 있을 때 12345import pandas as pddata = pd.read_csv('file.csv', engine='python')data.rename(&#123;0:'sl',1:'sw',2:'pl',3:'pw','class':'class_'&#125;,axis=1,inplace=True)sns.pairplot(data,hue='class_') Tidy DataWide format ⇒ Long format 분석하기 좋은 데이터. Tidy data 형태로 만들면 차원도 줄고, 유지보수하기도 좋다 Tidy Data 특징 12341. 각 변수는 개별의 열(column)로 존재한다2. 각 관측치는 행(row)으로 구성한다3. 각 표는 단 하나의 관측기준에 의해서 조작된 데이터를 저장한다4. 만약 여러개의 표가 존재한다면, 적어도 하나이상의 열이 공유되어야 한다 위 원칙들은 관계형 데이터베이스 원칙과 유사하다 ※ 예시 변수 : 키, 몸무게, 성별 값 : 175, 73, 남자 관측치 : 사람 (값을 측정한 단위가 되는 기준) 1234import pandas as pddata = pd.read_csv('file.csv')data.melt(['iso2','year'], var_name='sp', value_name='값').dropna() 주의 Tidy Data화 하지 않으면 info, describe, 등.. 초기 작업시 엉망으로 값이 나온다 ### 행 뽑기 1tb.loc[5:7] 1tb.iloc[1:3] # 파이썬 방식 상관성 체크하기 (correlation) 두 변수간에 어떤 선형적 관계를 갖고 있는지 분석하는 방법이 상관 분석. 그렇다면 상관성 있다는 것은 얼마나 관계가 있는지에 대한 정도라고 볼 수 있다. 만약 상관성이 1에 가깝다면 두 변수는 매우 관련 이 있다. 예를 들어 키가 크면 몸무게가 많이 나가는 것처럼 서로 관계가 가까운것. 양의 상관성: 기준이되는 변수가 커지면 상대 변수도 같이 커진다 음의 상관성: 기준이되는 변수가 커지면 상대 변수는 작아진다 상관 분석은 왜 하는거야?데이터 분석시 column이 많아지면 계산이 복잡해지는데 상관관계를 따져 상관성이 높은 것들은 분석 데이터에서 제외시켜 계산 복잡도를 크게 줄일 수 있기 때문이다. 12345import pandas as pddata = pd.read_csv('file.txt')data.rename(&#123;0:'sl',1:'sw',2:'pl',3:'pw','class':'class_'&#125;,axis=1,inplace=True)data.corr() # method = &#123;'pearson', 'kendall', 'spearman'&#125; 공분산 1data.cov() 문자열에 사용하는 것들Series에서 object(문자열) 빈도수 체크하기1234567891011121314import pandas as pddata = pd.read_csv('file.txt')data.rename(&#123;0:'sl',1:'sw',2:'pl',3:'pw','4':'class_'&#125;,axis=1,inplace=True)data['class_'].value_counts(): Iris-versicolor 50 Iris-setosa 50 Iris-virginica 50 Name: class_, dtype: int64data['class_'].value_counts().plot.pie()data['class_'].value_counts().plot.bar() nlargest, nsmallest, unique1234567891011121314151617x = data['class_'].value_counts()x.nlargest()x.nsmallest()data['class_'].unique(): Iris-versicolor 50 Iris-setosa 50 Iris-virginica 50 Name: class_, dtype: int64 Iris-versicolor 50 Iris-setosa 50 Iris-virginica 50 Name: class_, dtype: int64 array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object) 기초 통계 분석시 알아두면 좋은 원칙 및 정리1234567891. Occam&#39;s Razor (오캄의 면도날)- 같은 성능을 보일 때 간단한것을 택한다2. Curse of dimensionality (차원의 저주)- 차원이 커지면 커질수록 필요한 데이터의 양이 커져야 한다3. Law of large numbers (큰 수의 법칙)- 큰 모집단에서 무작위로 뽑은 표본의 평균이 전체 모집단의 평균과 가까울 가능성이 높다- 모집단이 커지면 표본평균은 모평균을 더 정확히 추정할 수 있다4. Central limit theorem (중심 극한 정리)- 동일한 확률분포를 가진 독립 확률 변수 n개의 평균의 분포는 n이 적당히 크다면 정규분포에 가까워진다는 정리 Indexing &amp; Slicing (Select data)내가 필요한 통계값 구하기 위해 MultiIndex Pandas Tip1 예측 분석을 하려면 문자열을 숫자로 바꿔줘야한다 (Encoding){: .notice} 예시에 나오는 데이터 출처 : archive 복습시간 18시 30분 ~ 21시 / 총 2시간 30분{: .notice} 2019년 5월 28일 화요일 17thloc, iloc + lambda1234567891011121314151617181920212223242526272829303132333435363738394041424344import pandas as pdimport numpy as npdata = pd.DataFrame(np.random.randn(6,4), index = list('abcdef'), columns = list('ABCD')data: A B C Da 0.427092 1.122736 1.064223 -0.724660b 0.091881 1.049868 1.263243 -0.193525c 0.224007 -1.128729 -1.261087 2.461563d -0.859961 -0.450851 -0.098474 0.456542e 0.339599 -0.946570 0.892721 -0.331624f 1.691290 -0.565636 0.905357 -0.301717data.loc[lambda x: x.B&gt;0, :]: A B C Da 0.427092 1.122736 1.064223 -0.724660b 0.091881 1.049868 1.263243 -0.193525data.loc[:, lambda x:['D','A']]: D Aa -0.724660 0.427092b -0.193525 0.091881c 2.461563 0.224007d 0.456542 -0.859961e -0.331624 0.339599f -0.301717 1.691290data.iloc[:,lambda x:[0,3]]: A Da 0.427092 -0.724660b 0.091881 -0.193525c 0.224007 2.461563d -0.859961 0.456542e 0.339599 -0.331624f 1.691290 -0.301717data[lambda x: x.columns[3]]: a -0.724660 b -0.193525 c 2.461563 d 0.456542 e -0.331624 f -0.301717Name: D, dtype: float64 columns12345678910111213141516import seaborn as snstips = sns.load_dataset('tips')tips: total_bill tip sex smoker day time size0 16.99 1.01 Female No Sun Dinner 21 10.34 1.66 Male No Sun Dinner 32 21.01 3.50 Male No Sun Dinner 33 23.68 3.31 Male No Sun Dinner 2tips.melt(tips.columns[:3]) # 열만 따로 뽑기: total_bill tip sex variable value0 16.99 1.01 Female smoker No1 10.34 1.66 Male smoker No2 21.01 3.50 Male smoker No3 23.68 3.31 Male smoker No index123456789101112import pandas as pddata = pd.read_csv('billboard.csv',engine='python')data.melt(data.columns[:7]).set_index('genre').loc['Rock']: year artist.inverted track time date.entered date.peaked variable valuegenre Rock 2000 Destiny's Child Independent 3:38 2000-09-23 2000-11-18 x1st.week 78.0 Women Part I Rock 2000 Santana Maria, Maria 4:18 2000-02-12 2000-04-08 x1st.week 15.0Rock 2000 Savage Garden I Knew I Loved You 4:07 1999-10-23 2000-01-29 x1st.week 71.0Rock 2000 Madonna Music 3:45 2000-08-12 2000-09-16 x1st.week 41.0` Intersection123456789a = &#123;1,2,3&#125;b = &#123;3,4&#125;a.intersection(b): &#123;3&#125;a.intersection([3,4]): &#123;3&#125;a.intersection(range(3)):&#123;1,2&#125; 새로운 연산자 만들기123456class x(int): def __add__(self, other): print('안더해줌')x(3) + x(4): 안더해줌 isin (predicate)1234567891011121314s = pd.Series(np.arange(5), index=np.arange(5)[::-1], dtype='int64')s.isin([2, 4, 6]): 4 False 3 False 2 True 1 False 0 True dtype: bools[s.isin([2, 4, 6])] : 2 2 0 4 dtype: int64 wheresplit, strip복습시간 12시 ~ 1시 30분 / 총 1시간 30분{: .notice} 2019년 5월 30일 목요일 18th기초통계 분석시 그래프 그리는 3가지1231. boxplot2. pairplot3. heatmap boxplot1234567import pandas as pdimport seaborn as snstips = sns.load_dataset('tips')tips.boxplot() # tips Dataframe의 attribute로 내장하고 있음# orpd.plotting.boxplot(tips) pairplot 짝을 이뤄 그리는 그래프 1234567import pandas as pdimport seaborn as snstips = sns.load_dataset('tips')sns.pairplot(tips) # tips Dataframe의 attribute로 내장하고 있지 않다sns.pairplot(tips, hue='sex') heatmap 상관 분석시 그리는 그래프 12345import seaborn as snstips = sns.load_dataset('tips')sns.heatmap(tips.corr())sns.heatmap(tips.corr(), cbar = False, annot = True) # 오른쪽 사이드바 제거, 평면에 상관계수 표시 Dataframe은 Iterator/Generator 처럼 next연산을 할 수 있다1234567891011121314151617181920212223242526import seaborn as snstips = sns.load_dataset('tips')x = tips.items() # or x = tips.iteritems()y = tips.iterrows()type(x)type(y)next(x)next(y): generator generator ('total_bill', 0 16.99 1 10.34 2 21.01 3 23.68 4 24.59 5 25.29 (0, total_bill 16.99 tip 1.01 sex Female smoker No day Sun time Dinner size 2 Name: 0, dtype: object) Pandas data type 종류1231. 숫자 &#x3D;&gt; int64, float642. 문자 &#x3D;&gt; object, category3. 시간&#x2F;날짜 Dask는 메모리의 제한으로 dataframe을 만들 수 없는 경우 도움을 줄 수 있는 패키지 이다. 파이썬으로 작성한 작업을 병렬화 할 수 있다.{: .notice} 12345678910111213!dir: 2019-05-25 오후 10:01 4,173 pandas.ipynb 2019-05-25 오후 08:49 139,785 pandas2.ipynb 2019-05-26 오후 02:51 220,247 pandas3.ipynb 2019-05-27 오후 09:18 749,763 pandas4.ipynb----------------------------------------------------------# 오늘 받은 패키지!pip install vincent!pip install -q pdvega # -q 옵션은 설치시 나오는 메시지 생략 # -U 옵션은 최신 버전이 아닐 경우 업데이트 Jupyter Tip1 jupyter에서 !(느낌표) 뒤에 cmd에서 작동하는 명령어를 치면 작동한다{: .notice} pdvega 1234import pdvegas = tips.groupby('smoker')s.vgplot.bar() Aggregation analysis (집합 분석)Groupby의 내부적 구현 순서12341. iterrow 순회2. split &#x3D;&gt; groupby3. apply &#x3D;&gt; mean, max ... (통계적으로 대표할 수 있는 값 설정)4. combine &#x3D;&gt; 결과 묶기 Group 3총사1231. groupby2. pivot table3. crosstab (pd로 접근) 2. pivot table123456789101112import seaborn as snstips = sns.load_dataset('tips')tips.pivot_table(index='smoker', columns = 'sex', aggfunc = np.sum, margins = True)# margin은 부분합을 보여줌: size tip total_billsex Male Female All Male Female All Male Female Allsmoker Yes 150 74 224 183.07 96.74 279.81 1337.07 593.27 1930.34No 263 140 403 302.00 149.77 451.77 1919.75 977.68 2897.43All 413 214 627 485.07 246.51 731.58 3256.82 1570.95 4827.77 3. crosstab123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import seaborn as snstips = sns.load_dataset('tips')a = pd.crosstab(tips.smoker, tips.sex, tips.tip, aggfunc = np.max)a.index# smoker가 index, sex가 column, tip이 value, aggfunc는 value의 대푯값:sex Male Femalesmoker Yes 10.0 6.5No 9.0 5.2CategoricalIndex(['Yes', 'No'], categories=['Yes', 'No'], ordered=False, name='smoker', dtype='category')b = pd.crosstab(tips.smoker,[tips.sex,tips.time],tips.tip,aggfunc=np.max)b.index# multi columns:sex Male Femaletime Lunch Dinner Lunch Dinnersmoker Yes 5.0 10.0 5.00 6.5No 6.7 9.0 5.17 5.2CategoricalIndex(['Yes', 'No'], categories=['Yes', 'No'], ordered=False, name='smoker', dtype='category')c = pd.crosstab([tips.smoker,tips.sex],tips.time,tips.tip,aggfunc=np.max)c.index: multi index time Lunch Dinnersmoker sex Yes Male 5.00 10.0 Female 5.00 6.5No Male 6.70 9.0 Female 5.17 5.2MultiIndex(levels=[['Yes', 'No'], ['Male', 'Female']], codes=[[0, 0, 1, 1], [0, 1, 0, 1]], names=['smoker', 'sex'])d = pd.crosstab([tips.smoker,tips.sex],tips.time,tips.tip,aggfunc=np.max).indexd.labels # or d.codes: FrozenList([[0, 0, 1, 1], [0, 1, 0, 1]]) 1234567891011121314151617# sequnce 방식x.codes: FrozenList([[0, 0, 1, 1], [0, 1, 0, 1]])x.labels[0]# attribute 방식from collections import namedtuplen = namedtuple('Jung', ['x','y'])a = n(1,2)a: Jung(x=1, y=2)a.xa.y: 1 2 Pandas Tip1 데이터 형태가 []를 포함하면 sequence 방식 , xx = yy 가 있으면 attribute 방식{: .notice} reindex &amp; resetindex reindex는 수동으로 index변경, resetindex는 0부터 자동으로 index 변경 resetindex1234567891011121314151617181920212223242526272829303132333435import seaborn as snstips = sns.load_dataset('tips')n = tips[tips.sex == 'Male'].loc[:15] # 맨처음 index부터 15 index까지 행 뽑기n.reset_index(drop=True) # 기존 index 버리고 0부터 새로 생성: total_bill tip sex smoker day time size0 10.34 1.66 Male No Sun Dinner 31 21.01 3.50 Male No Sun Dinner 32 23.68 3.31 Male No Sun Dinner 23 25.29 4.71 Male No Sun Dinner 44 8.77 2.00 Male No Sun Dinner 25 26.88 3.12 Male No Sun Dinner 46 15.04 1.96 Male No Sun Dinner 27 14.78 3.23 Male No Sun Dinner 28 10.27 1.71 Male No Sun Dinner 29 15.42 1.57 Male No Sun Dinner 210 18.43 3.00 Male No Sun Dinner 411 21.58 3.92 Male No Sun Dinner 2n.reset_index() # 기존의 index 삭제 X: index total_bill tip sex smoker day time size0 1 10.34 1.66 Male No Sun Dinner 31 2 21.01 3.50 Male No Sun Dinner 32 3 23.68 3.31 Male No Sun Dinner 23 5 25.29 4.71 Male No Sun Dinner 44 6 8.77 2.00 Male No Sun Dinner 25 7 26.88 3.12 Male No Sun Dinner 46 8 15.04 1.96 Male No Sun Dinner 27 9 14.78 3.23 Male No Sun Dinner 28 10 10.27 1.71 Male No Sun Dinner 29 12 15.42 1.57 Male No Sun Dinner 210 13 18.43 3.00 Male No Sun Dinner 411 15 21.58 3.92 Male No Sun Dinner 2 행, 열 위치 변환하기기준 데이터123456789tips.groupby(['sex','smoker']).mean()[['tip']] tipsex smokerMale Yes 3.051167 No 3.113402Female Yes 2.931515 No 2.773519 stack12345678910tips.groupby(['sex','smoker']).mean()[['tip']].stack()sex smoker Male Yes tip 3.051167 No tip 3.113402Female Yes tip 2.931515 No tip 2.773519dtype: float64# 1차원으로 바뀜 unstack1234567tips.groupby(['sex','smoker']).mean()[['tip']].unstack() tipsmoker Yes Nosex Male 3.051167 3.113402Female 2.931515 2.773519 Column이 2개 이상일 때 그래프Stacked = True (Column값을 쌓는다)1tips.groupby(['day','sex']).mean()[['tip']].unstack().plot.bar(stacked=True) unstack(0) (index와 열의 조합)1tips.groupby(['day','sex']).mean()[['tip','total_bill']].unstack(0).plot.bar(stacked=True) Stacked = False (Column값을 쌓지 않는다)1tips.groupby(['day','sex']).mean()[['tip']].unstack().plot.bar(stacked=False) unstack(1) (header와 열의 조합)1tips.groupby(['day','sex']).mean()[['tip','total_bill']].unstack(1).plot.bar(stacked=True) sci Stack은 Column을 Index로 바꿔주고, Unstack은 Index를 Column으로 바꿔준다{: .notice} 복습시간 18시 13분 ~ 20시 21분/ 총 2시간 8분{: .notice} 2019년 5월 30일 금요일 19thData Visualization 문자나, 숫자 보다 그림으로 혹은 그래프로 시각적인 정보가 사람에게는 더 명확하고 효율적으로 전달 되기 때문에 데이터 분석 결과를 시각화 할 수 있어야 한다 시각화 라이브러리 Python 시각화 라이브러리 분류 Costumize하려면 Matplotlib을 사용해야 한다 matplotlib, seaborn matplotlib는 python, numpy format으로 데이터를 처리하고 seaborn은 pandas format으로 데이터를 처리한다. .value는 pandas 데이터 형태를 numpy format으로 바꿔준다{: .notice} Matplotlib pyplot pylab 이제 pylab은 쓰지 않는다 구성요소 그래프 커스터마이징 하기123456789101112import matplotlib.pyplot as plt# canvas, figure, axes는 생략하면 자동으로 생성해서 그래프를 그려준다# 단 생략하지 않으면 커스텀 할 수 있다plt.figure(figsize=(10,5), facecolor='yellow') plt.axes(xlim=(0,10),ylim=(0,10)) # xlim,ylim은 최대 범위를 지정plt.title('Title')plt.xlabel('Time')plt.ylabel('Rate')plt.grid(axis='y')plt.plot([1,2,3,4,5,6],[2,0,4,7,3,10], color='black', marker='o') matplotlib에서 제공해주는 스타일12345678910111213141516171819202122232425262728plt.style.available['bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark-palette', 'seaborn-dark', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'seaborn', 'Solarize_Light2', 'tableau-colorblind10', '_classic_test'] 예시 12345import seaborn as snsiris = sns.load_dataset('iris')plt.style.use('ggplot')sns.pairplot(iris, hue='species') 복습시간 22시 ~ 22시 40분 / 총 40분{: .notice} 2019년 6월 3일 월요일 20thFolium 지도 그리는 python 패키지 또는 라이브러리. 분석에 필요한 단계구분도를 하기 위해서 사용한다.Google map에서 갖고옴. Folium 설치1pip install folium Folium Map123456789101112131415161718import foliummymap = folium.Map(location=[37.332268, 127.180961], zoom_start = 11, tiles='Stamen Toner')folium.Marker([37.332268, 127.180961], popup='&lt;i&gt;Ji hyeok home&lt;/i&gt;',icon=folium.Icon(icon='cloud')).add_to(mymap)folium.Marker([37.543148,126.949866], popup='&lt;b&gt;My location&lt;/b&gt;').add_to(mymap)folium.CircleMarker(location=[37.332268, 127.180961],radius=80,popup='My area',color='#3186cc',fill=True,fill_color='#3186cc' ).add_to(mymap)mymap.add_child(folium.LatLngPopup()) # 지도위 클릭시 위도, 경도 보여줌mymap.add_child(folium.ClickForMarker(popup=\"ClickPoint\")) # 지도위 클릭시 클릭위치에 표시됨 file 불러오기보통 pandas로 파일을 불러오지만파일 구성이 복잡하여 불러오지 못하는 파일은 open으로 불러와야 한다open으로 불러온 데이터는 text(객체의 의미를 갖지 못함)형태로 불러오고 이 text를 csv나 json형태로 불러와 의미 부여해줘야 한다 (csv, json만 가능) 나머지는 pickle로? 1234567891011121314151617181920212223import jsonfrom pprint import pprintwith open('seoul_municipalities_geo_simple.json', encoding='utf-8') as f: x = json.load(f)pprint(x)len(x)len(x['features'])x['features'][0]['properties']['name']x['features'][0]['geometry']['type']: &#123;'features': [&#123;'geometry': &#123;'coordinates': [[[127.11519584981606, 37.557533180704915], [127.11879551821994, 37.557222485451305], [127.12146867175024, 37.55986003393365], [127.12435254630417, 37.56144246249796] 2 25 '강동구' 'Polygon' 단계구분도1234567891011121314151617181920212223242526272829303132333435import json, foliumimport pandas as pdseoul_geo_json = open('seoul_municipalities_geo_simple.json',encoding='utf-8')seoul_geo_json = json.load(seoul_geo_json)data = pd.DataFrame.from_dict(seoul_geo_json['features']).propertieskeys = data[0].keys()data_list = &#123;&#125;for key in keys: temp_list = [] for inst in data: temp_list.append(inst[key]) data_list[key] = temp_listseoul_df = pd.DataFrame.from_dict(data_list) seoul_df.to_csv('seoul_map.csv')seoul = folium.Map(location=[37.5665, 126.9780], tiles='Mapbox Bright')seoul_geo_df = pd.read_csv('seoul_map.csv')seoul.choropleth( geo_data=seoul_geo_json, # json name='choropleth', data=seoul_geo_df, # pandas columns=['name', 'code'], key_on='feature.properties.name', # geo data와 pandas data 맞춰준다? fill_color='YlGn', fill_opacity=0.7, line_opacity=0.2, legend_name='population')seoul map 사용하여 특정 열 값 뽑아내기12345678910111213141516171819202122232425import jsonseoul_geo_json = open('seoul_municipalities_geo_simple.json',encoding='utf-8')seoul_geo_json = json.load(seoul_geo_json)data=pd.DataFrame.from_dict(seoul_geo_json['features'])t=pd.DataFrame.from_dict(data.properties)t: properties0 &#123;'code': '11250', 'name': '강동구', 'name_eng': '...1 &#123;'code': '11240', 'name': '송파구', 'name_eng': '...2 &#123;'code': '11230', 'name': '강남구', 'name_eng': '...3 &#123;'code': '11220', 'name': '서초구', 'name_eng': '...4 &#123;'code': '11210', 'name': '관악구', 'name_eng': '...t.properties.map(lambda x:x['name']):0 강동구1 송파구2 강남구3 서초구4 관악구 pandas format으로 불러들이는 방법 3가지1231. pd.read_csv2. pd.DataFrame3. pd.DataFrame.from_dict ※ 보충 필요 Machine Learning기계학습시 거치는 단계1234567891011121. 방법 (알고리즘)2. 하이퍼 파라미터컴퓨터에게 방법(알고리즘)을 알려주고 스스로 학습을 하고학습한 데이터를 기반으로 예측을 할때 비슷한걸 찾는다이때 기계학습에는 전부 숫자데이터로 하기 때문에 근처 숫자 값을찾아 예측하게 된다 (KNN 알고리즘)하이퍼 파라미터는 근처 값 몇개를 찾아보고 예측을 할지 정해주는 것이다하이퍼 파라미터를 몇개로 줘야 하는지는 성능이 좋은 것에 따라 지정해주면 된다그리고 알고리즘, 하이퍼 파라미터 둘다 컴퓨터가 알아서 성능 좋은걸로 선택하게 할 수도 있다 KNN K-Nearest Neighbor 최근접 이웃 알고리즘{: .notice} 12345678910111213141516171819202122232425262728293031323334353637383940import pandas as pdimport seaborn as snsfrom sklearn.datasets import load_irisfrom sklearn.neighbors import KNeighborsClassifierdata = load_iris()print(data.DESCR) # 데이터 이해를 위해 보는 것data_pd = pd.DataFrame(data.data, columns=data.feature_names) # 인스턴스 방식data_target = pd.DataFrame(data.target, columns=['target'])iris = pd.concat([data_pd, data_target], axis = 1) # data_pd + data_target 결합knn = KNeighborsClassfier(3) # 근처 3개를 확인해라knn.fit(iris.iloc[:,:-1], iris.iloc[:,-1]): KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=3, p=2, weights='uniform')data.target_namesknn.predict([[3,3,4,3]])knn.predict_proba([[3,3,4,3]]): array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10') array([1]) # versicolor로 예측 array([[0. , 0.66666667, 0.33333333]]) # 가까운 값이 versicolor 2개, virginica 1개가 있었음※ Bunch# dictionary + attributetype(data): sklearn.utils.Bunchdata.datadata['data']# 둘다 접근 가능한 데이터 타입dir(data): ['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names'] Folium 활용 : pythonhow 복습시간 18시 30분 ~ 21시 / 2시간 30분{: .notice} 2019년 6월 4일 화요일 21th기계학습 분류 지도 학습 123456789101112131415161718정답을 알려주며 학습시킨다.예를 들어 &#39;바퀴 4개, 문짝 4개, 도로위를 시속 0~200km(input data) 달릴 수 있는 것은 자동차(label data or target data)야&#39;라고 학습 시키고 학습을 바탕으로 모델이 예측할 수 있도록 하는 방법이다.지도학습은 크게 Classification, Regression으로 나눈다.Classification은 또 이진분류, 다중분류로 볼 수 있다.이진분류 같은 경우 생존자 or 비생존자와 같이 둘 중 하나로 분류 가능한 것을 말한다.LogisticRegression 알고리즘이 대표적인 이진 분류 알고리즘이다.다중 분류는 어떤 데이터에 대해 여러 값 중 하나로 분류 가능한 것을 말한다.예를 들어 축구공, 야구공, 농구공 등 Label data가 여러개로 나뉠 수 있는 경우를 말한다.이때는 KNN알고리즘으로 분류 가능하다.KNN알고리즘은 데이터가 많아지거나 Label data가 많아지면 성능이 떨어질 가능성이 높다.Regression는 어떤 데이터들의 특징을 토대로 값을 예측하는 것을 말한다.예를 들어 키가 170cm인 사람의 몸무게는 65kg이다와 같이 Label data가 실수 값을 갖거나연속적, 범위가 정해지지 않은 경우 무한대인 경우이다.분류인지 회귀인지는 label data가 유한개인지 무한개인지 생각해보면 된다. 비지도 학습 12345678910111213141516171819정답을 알려주지 않고 비슷한 데이터들 끼리 군집화하여 학습한다.예를 들어 &#39;남자, 여자 사진을 무작위로 입력값으로 줬을 때 사진을 보고 공통적으로 보이는특성들을 찾아 비슷한 특성끼리 묶어 남자, 여자를 학습 시킨 데이터를 기반으로 분류하는 것을 말한다.비지도학습은 크게 Clustering, Visualization &amp; Dimensionality Reduction, Association으로 나뉜다.Clustering은 비슷한 것끼리 묶는 방법이다.Clustering 방법중 대표적인 알고리즘인 k-means는 예를 들어 3가지로 묶는다고 했을 때 데이터에서 무작위로 임의의 값을 3개 찍고랜덤한 데이터 값에서 가까운 값을 찾아 평균을 낸다. 그러면 평균낸 값에서 가까운 값을 또 찾고 그 값에서 평균을 낸다.이와 같은 작업을 반복하여 평균값이 변하지 않는 때를 찾아 그 평균 값을 기준으로 군집화 하면 그것이 클러스터링 방법이다.Visualization &amp; Dimensionality Reduction은 데이터간의 상관성을 분석하여 포함시키지 않아도 예측하는데 큰 지장 없는데이터 열을 줄임으로써 차원을 축소하는 방법이다.대표적으로 pca 방법이 있다. pca알고리즘은 데이터 분포에서 variance가 큰 방향의 벡터에 데이터를 정사영하여차원을 축소시킨다. 이렇게 했을 때 데이터의 구조는 크게 바뀌지 않으면서 차원은 감소시킬수 있기 때문이다.Association은 유사한 요소를 찾아 묶는 것이다. 이때 유사성을 파악할때 데이터간의 차이를 측정하는 방법인유클리드 거리 측정 방법과 비-유클리드 거리 측정법으로 나눌 수 있다.예를 들어 &#39;근처에 사는 사람은 비슷한 성격을 갖고 있을 것이다&#39; 처럼 묶거나&#39;피자를 사는 사람은 꼭 콜라를 산다&#39; 처럼 묶을 수 있다. 지도학습, 비지도학습 : tistory 차원 축소 (pca): tistory, &nbsp; wikidocs 기계학습 목적Data로 부터 Specific문제 해결을 위한 최적의 모델 만들기 Data수집부터 예측까지 과정123456789101112131415161718192021222324250. Data 불러들이기- 적합한 데이터 format으로 변환1. Tidy data인지 확인하기2. info- missing datat 체크 (mino.matrix)- object, category type은 숫자 타입으로 변환- 차원의 저주 (필요없는 열 삭제)- 데이터 갯수 확인 (데이터 갯수가 충분한가)- 메모리 크기 확인 (내가 불러들일 수 있는 사이즈인가)- label(target,class) data 포함 여부 확인3. describe- 지도학습을 하는 경우 pairplot으로 분류 가능한지 확인- label data가 유한개인지 무한개인지 확인- label data 유한 --&gt; classifications- label data 무한 --&gt; regression- 상관성 확인해야 하는 경우 heatmap- boxplot- 비지도학습을 하는 경우 label data가 없이 즉, 기준이되는 답이 없이 학습해야함.- 비지도학습의 경우 클러스터링, 시각화와 차원축소, 연관 규칙 학습등의 알고리즘을 사용4. 왜도, 첨도- skew- kurtosis5. 5총사중 나머지 3개 (head, tail, sample)6. 목적에 맞게 평가 척도에 따라 최적의 모델 생성7. 성능 테스트 label이 유한일때, 무한일때유한일때1234import seaborn as snsiris = sns.load_dataset('iris')iris 무한일때 mpg(연비)를 예측한다고 가정했을 때 연비는 정해져 있는 label이 아니기 때문에 무한 label임으로 regression 즉, 연속된 값을 예측해야 한다. 1234import seaborn as snsmpg = sns.load_dataset('mpg')mpg masking 기법으로 missing data 보기123456789101112import seaborn as snsmpg = sns.load_dataset('mpg')mpg.horsepower[mpg.horsepower.isnull()] # or mpg.horsepower[mpg.horsepower.isna()]:32 NaN126 NaN330 NaN336 NaN354 NaN374 NaN missing data 그래프로 확인하기1234567# pip install missingnoimport missingno as minoimport seaborn as snsmpg = sns.load_dataset('mpg')mino.matrix(mpg) data의 양이 충분하지 않을때 missing data가 있으면 적당한 값으로 채워 넣어 성능을 높여주고,적당한 값을 채우기 애매할 때는 missing data가 있는 row를 지워야 한다. 데이터를 쪼개 성능 비교하기123456789101112131415161718192021222324252627282930313233343536373839404142434445import seaborn as snsfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import confusion_matrixiris = sns.load_dataset('iris')iris.species = iris.species.map(&#123;'setosa': 0, 'versicolor':1,'virginica':2&#125;)knn = KNeighborsClassifier()iris_data = iris[iris.columns[:-1]]iris['species']knn.fit(iris_data, iris['species'])# 관례상 행렬은 대문자, 벡터는 소문자로 표기X_train, X_test, y_train , y_test = train_test_split(iris[iris.columns[:-1]], iris.species)len(X_train.index)len(X_test.index): 112 38 # 75 : 25 비율로 쪼갬knn.fit(X_train, y_train)knn.predict(X_test)y_test.values: array([2, 1, 2, 1, 2, 1, 0, 1, 2, 2, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 2, 1, 2, 2, 2, 0, 0, 0, 1], dtype=int64) array([2, 1, 2, 1, 2, 1, 0, 1, 2, 2, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 2, 1, 1, 2, 2, 0, 0, 0, 1], dtype=int64) knn.predict(X_test) == y_test.values :array([ True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True])confusion_matrix(y_test, knn.predict(X_test)):array([[10, 0, 0], [ 0, 10, 0], [ 0, 1, 17]], dtype=int64)# virginica를 예측한 test에서는 한번은 versicolor이라고 잘못 예측 했기 때문에 0 , 1 , 17 Model 학습이 끝난 알고리즘 + 데이터를 Model 이라고 한다{: .notice} 복습시간 18시 50분 ~ 19시 45분 / 총 55분{: .notice} 2019년 6월 5일 수요일 22thOne hot encoding &amp; Label encoding 기계학습으로 예측분석을 하기 위해서는 문자를 숫자로 변환 해야하기 때문에 Encoding을 해야한다그런데 문자를 숫자로 encoding할때 성능에 영향을 미치기 때문에 상황에 따라 encoding 방식을 달리 해야 한다 One hot encoding 하나의 값만 True이고 나머지는 모두 False인 인코딩 방식 Scikit1234567891011121314151617181920212223from sklearn.preprocessing import OneHotEncoderohe = OneHotEncoder()t = ohe.fit(data[['species']])t.array(): array([[1., 0., 0.], [1., 0., 0.], [1., 0., 0.], [1., 0., 0.], [1., 0., 0.], [1., 0., 0.], [1., 0., 0.], [1., 0., 0.], .....# ohe.fit_transform(data[['species']]).toarray() 한번에 가능ohe.inverse_transform([[1., 0., 0.]]): array([['setosa']], dtype=object)# 숫자로 인코딩 되기 전 문자 Scikit’s onehotencoder의 장점은 인코딩 되기 전 문자를 알 수 있다는 것. 밑의 경우에는 어떻게 해야 할까..? 12345678910pd.DataFrame(ohe.fit_transform(data[['species']]), columns=['target']):target0 (0, 0)\\t1.01 (0, 0)\\t1.02 (0, 0)\\t1.03 (0, 0)\\t1.04 (0, 0)\\t1.05 (0, 0)\\t1.0 Pandas1234567891011121314import seaborn as snsimport pandas as pddata = sns.load_dataset('iris')pd.get_dummies(data.species): setosa versicolor virginica0 1 0 01 1 0 02 1 0 03 1 0 04 1 0 05 1 0 0 LabelEncoderScikit1234567891011121314from sklearn.preprocessing import LabelEncoderle = LabelEncoder()le.fit_transform(data.species):array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) pandas map1234import seaborn as snsiris = sns.load_dataset('iris')iris.species = iris.species.map('setosa': 0, 'versicolor':1,'virginica':2&#125;) Label encoding시 주의 거리기반 알고리즘을 사용할 때 라벨 인코딩된 값으로 학습을 하게되면 숫자간의 격차로 인해 오차가 생길 위험이 있다. 예를 들어 0, 1, 2로 라벨 인코딩 되었다고 했을 때 0과 1사이 1과 2사이는 둘다 1간격만 있어 상관 없지만 0과 2사이에는 2간격이 생겨 학습시 주의해야 한다. 따라서 label encoding 해야할 때와 하지 말아야 할때를 잘 구분해야 한다.{: .notice} Bias , Variance Bias가 높으면 값이 편향되어 있어서 값이 모여있고 Variance가 높으면 값이 퍼져있게된다.현실에 적용할 수 있는 모델을 만들기 위해서는 Bias와 Variance가 만나는 지점을 목표로 삼고 모델을 만들어야 한다. Trade off 다양한 데이터를 학습시키지 않게 되면 bias가 높아져 정확도가 떨어지는 대신 학습하지 않은 데이터중 일부는 어쩌다 맞추는 경우는 Underfit이다.다양한 데이터를 학습시키긴 했지만 데이터 양이 많지 않아 bias는 낮지만 variance가 높아 학습한 데이터에 대해서만 정확도가 높고 전혀 보지 못한 데이터에 대해서는 정확도가 현저히 낮게 되는 경우는 Overfit이다. Underfit의 경우 training시 정확성은 떨어지지만 test에서 오차범위가 크지 않게 예측을 할 수 있지만, Overfit의 경우 training시에 정확성은 높지만 test에서 오차범위가 크게 예측을 할 수 가 있다.예를 들어 Underfit인 경우 사과를 맞추는 로봇이 있다고 가정했을 때 ‘사과는 동그랗고 빨갛다’ 라고만 학습시키고 테스트를 했을 때 석류나 자두같이 동그랗고 빨간 과일을 보게되어도 사과라고 예측할 것이다. Overfit의 경우는 ‘지름이 10cm이며 동그랗고 빨간색이다’ 라고 학습 시킨 경우에는 자두같이 작지만 빨간 과일에 대해서는 사과라고 예측하지는 않겠지만 10cm가 넘는 사과이거나 초록색 사과인 경우를 사과라고 판단하지 못하는 오류를 범할 수 있다 Model 성능 평가하는 2가지 방법Hold out Train-test-split Data leakage training data에는 있지만 test data에는 없어 overfitting된경우 발생하는 문제{: .notice} Cross Validation (교차 검증) n등분 나누어 test, train을 n번 수행하여 평균을 내어 성능을 테스트한다. 보통 10등분으로 함. 모든 데이터가 최소 한번은 테스트 데이터로 쓰이도록 한다. 데이터가 적을때 대충의 성능평가를 할때 cross_val_score를 사용한다 data leakage현상을 방지할 수 있다.데이터의 양이 많으면 매우 느리다는 단점이 있다. Model의 성능이 좌우되는 요소 2가지121. 알고리즘2. 하이퍼 파라미터 복습시간 21시 10분 ~ 1시 / 2시간 50분{: .notice} 2019년 6월 10일 월요일 23thmap vs apply1231. map은 dictionary, 함수 방식 둘다 지원2. apply는 함수방식만 지원- apply방식은 args&#x3D;() 옵션으로 재활용 가능한 함수 방식을 사용할 수 있다 count vs size12count는 미싱데이터를 포함하지 않고size는 포함한다 count12345678a = [1,1,1,2,2,3,4]b = (1,1,1,2,2,3,4)a.count(1)b.count(2): 3 2 size12345import numpy as npc = np.arange(10)c.size: 10 cut &amp; qcutcut 최저값과 최대값의 간격을 n등분하여 나눔 123456789101112131415import pandas as pdimport numpy as npa = np.array([[0,0,2],[0,0,10],[0,0,20],[0,0,49],[0,0,30],[10,11,100]])x=pd.DataFrame(a)x.rename(&#123;0:'x',1:'y',2:'z'&#125;, axis=1, inplace=True)pd.cut(x.z,2):0 (1.902, 51.0]1 (1.902, 51.0]2 (1.902, 51.0]3 (1.902, 51.0]4 (1.902, 51.0]5 (51.0, 100.0] qcut 전체 데이터 갯수에서 n%로 나눔 123456789101112131415import pandas as pdimport numpy as npa = np.array([[0,0,2],[0,0,10],[0,0,20],[0,0,49],[0,0,30],[10,11,100]])x=pd.DataFrame(a)x.rename(&#123;0:'x',1:'y',2:'z'&#125;, axis=1, inplace=True)pd.qcut(x.z,2):0 (1.999, 25.0]1 (1.999, 25.0]2 (1.999, 25.0]3 (25.0, 100.0]4 (25.0, 100.0]5 (25.0, 100.0] Discriminative vs Generative 분류하여 예측 하는 모델에는 두 가지 방식이 있다. Discriminative, Generative Discriminative 입력 데이터들이 있을때 label data를 구별해내는 방식 어떤 입력값(input) x가 주어졌을 때 그 결과값(label) y일 확률을 알아내는 것 대표 알고리즘 12341. Logistic Regression2. Conditional Random Field3. Support Vector Machine4. Linear Regression 장점 데이터가 충분할 경우 성능이 좋음{: .notice} 단점 데이터가 실제 어떤 모습인지 본질을 이해하기 어려움{: .notice} #### SVM(Support Vector Machine) SVM은 수학적으로 증명 가능하고 초평면을 경계로 분류하는 알고리즘 이라고 볼 수 있다 선형, 비선형 둘다 성능 좋지만 최적화를 고려 안해 속도가 느리다는 단점이 있다 Generative 입력값과 결과값이 주어질때, 일정한 분포 규칙속에 존재한다는 가정을 한다. 관측 데이터 결합확률 분포를 통해 확률 모델을 만들어낸다. 즉 주어진 데이터를 보고 분포 규칙을 생성해 낸다. 대표 알고리즘 1231. Naive Bayes2. Gaussian discriminant Analysis3. Gaussian Mixture Model 장점 데이터 자체의 특성을 파악하기에 좋다, 데이터를 생성해 새로운 결과물을 얻어낼 수 있다.{: .notice} 단점 데이터가 많은 경우 Discriminative에 비해 성능이 떨어 질수 있다.{: .notice} Generative &amp; Discriminative: naver blog 선형, 비선형 모델 : blog LogisticRegression을 제일처음에 하는 이유123456789LogisticRegression은 데이터가 선형분류로 성능이 좋은지 안좋은지를 보고데이터가 선형 데이터인가 비선형 데이터인가 판별하는데기준이 될 수 있기 때문에 시간 절약을 할 수 있다선형분류와 비선형분류 알고리즘 둘다 성능이 비슷한 경우 선형데이터라고 간주하고선형분류 알고리즘 위주로 학습시키는데 사용하고선형분류 알고리즘의 성능이 현저하게 낮은 경우 비선형 데이터라고 간주하고그때부터는 비선형 알고리즘 위주로 학습시키는데 사용하면 시간을 절약할 수 있다 복습시간 18시 30분 ~ 22시 10분 / 총 3시간 40분{: .notice} 2019년 6월 12일 수요일 24thimport를 하지 않고 외부 객체의 메소드를 사용 하는 방법1234567891011121314151617181920212223242526import seaborn as snsiris = sns.load_dataset('iris')$whos:Variable Type Data/Info---------------------------------iris DataFrame sepal_length sepal_&lt;...&gt;n\\n[150 rows x 5 columns]sns module &lt;module 'seaborn' from 'C&lt;...&gt;s\\\\seaborn\\\\__init__.py'&gt;dir(iris):['T', '_AXIS_ALIASES', '_AXIS_IALIASES', '_AXIS_LEN', .... 'boxplot', 'iloc', 'index', 'infer_objects', 'info', 'insert', 'interpolate', 'isin', ..... DataFrame 객체는 Pandas 프레임워크에 정의된 클래스이다. 따라서 Pandas를 import하지 않고는 사용할 수 없다. 하지만 import seaborn만 했는데 iris 객체가 DataFrame 타입으로 나온다. 어떻게 된것일까? 123456789!pip install seabornRequirement already satisfied: seaborn in c:\\users\\samsung\\anaconda3\\lib\\site-packages (0.9.0)Requirement already satisfied: numpy&gt;=1.9.3 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from seaborn) (1.16.2)Requirement already satisfied: scipy&gt;=0.14.0 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from seaborn) (1.2.1)Requirement already satisfied: pandas&gt;=0.15.2 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from seaborn) (0.24.2)Requirement already satisfied: matplotlib&gt;=1.4.3 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from seaborn) (3.0.3)Requirement already satisfied: pytz&gt;=2011k in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from pandas&gt;=0.15.2-&gt;seaborn) (2018.9)..... seaborn을 설치하게되면 numpy, scipy, pandas 등 같이 설치하게 된다. 왜냐하면 seaborn을 사용하기 위해서는 모두 필요하기 때문이다. 설치가 되었다고 해서 import하지 않고 쓸수 있다는 말은 아니다. seaborn 패키지 자체에서 numpy든 pandas든 import해서 seaborn으로 dataset을 생성하면 DataFrame 형태로 반환하도록 설계되어 있어 DataFrame 객체가 네임스페이스에 들어 있게 되면 DataFrame이 사용할 수 있는 메소드는 전부 사용할 수 있게 되는 것이다. 상황에 따른 알고리즘 사용법 데이터의 양이 충분한지 판단하는 방법 데이터 분석시 info정보만으로 데이터의 양이 충분한지 안한지 가늠이 가지 않을때 Learning curve를 확인하여 데이터 양이 충분한지 판단한다. Learning curve란 학습시킬때마다 정확도가 어떻게 달라지는지 추세를 확인하여 training score와 cv score가 만나는 지점 즉, overfitting되기 전 적당한 trade-off 지점을 확인할 수 있는 데이터 양이라고 한다면 데이터가 충분하다는 말 1234567891011121314from sklearn.datasets import load_irisimport pandas as pdfrom sklearn.model_selection import learning_curvefrom sklearn.neighbors import KNeighborsClassifierfrom sklearn_evaluation import plot!pip install sklearn-evaluationiris = load_iris()data = pd.DataFrame(iris.data, columns=list('ABCD'))target = pd.DataFrame(iris.target, columns=['target'])iris2 = pd.concat([data, target], axis=1)knn = KNeighborsClassifier()train_size, train_score, test_score = learning_curve(knn, iris2.iloc[:,:-1], iris2.iloc[:,-1], cv = 10)plot.learning_curve(train_score, test_score, train_size) Learning curve &amp; LogisticRegression123456789101112from sklearn.datasets import make_classificationimport pandas as pdfrom sklearn.model_selection import learning_curvefrom sklearn.linear_model import LogisticRegressionlr = LogisticRegression()data = make_classification(1000,5)d = pd.DataFrame(data[0])ta = pd.DataFrame(data[1])train_size, train_score, test_score = learning_curve(lr, d, ta, cv=10)plot.learning_curve(train_score, test_score, train_size) 하이퍼 파라미터 찾기 (GridSearchCV) GridSearch를 활용하여 for문을 쓰지 않고 하이퍼 파라미터 찾기 123456789101112131415161718192021222324252627from sklearn.model_selection import GridSearchCV# iris2는 위에서 다룬 예제를 대체한다x_train, x_test, y_train, y_test = train_test_split(iris2.iloc[:,:-1], iris2.iloc[:,-1])para_grid = &#123;'n_neighbors': range(2,21), 'weights':['uniform', 'distance']&#125;gri = GridSearchCV(KNeighborsClassifier(), para_grid)gri.fit(x_train, y_train) # cross validation이기 때문에 전체 데이터로 fit 시켜야함gri.best_estimator_gri.best_params_gri.param_gridgri.best_score_pd.DataFrame(gri.cv_results_).T: GridSearchCV(cv='warn', error_score='raise-deprecating', estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform'), fit_params=None, iid='warn', n_jobs=None, param_grid=&#123;'n_neighbors': range(2, 21), 'weights': ['uniform', 'distance']&#125;, pre_dispatch='2*n_jobs', refit=True, return_train_score='warn', scoring=None, verbose=0)KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=13, p=2, weights='distance') &#123;'n_neighbors': 13, 'weights': 'distance'&#125;&#123;'n_neighbors': range(2, 21), 'weights': ['uniform', 'distance']&#125;0.9821428571428571 LogisticRegression LogisticRegression알고리즘은 target data가 2개 이상일때만 Learning curve가 가능하다.{: .notice} Cross-validation &amp; Learning curve Cross-validation으로 성능 체크할때 n개로 나누어 체크를 하는데 이때 자동으로 데이터를 섞고나서 평가를 하기 때문에 데이터가 정렬 되어 있어도 섞어서 평가를 한다. 그런데 Learning curve로 학습 추세를 확인 할때는 데이터를 순서대로 학습시키기 때문에 최소 클래스 2개가 필요한 LogisticRegression알고리즘을 사용할 때는 shuffle 옵션을 True로 줘야 한다.{: .notice} 복습시간 19시 ~ 22시/ 총 3시간{: .notice} 2019년 6월 13일 목요일 25thSupervised Learning Process Raw Data Collection 데이터 수집, 적합한 데이터 format으로 불러오기. 기초 통계분석하기 위해 보통 DataFrame 형태로 불러오거나 변환해준다. Pre-Processing Tidy Data인지 확인한다. Tidy Data가 아닐 경우 변수는 열로 관측치는 행으로 구성할 수 있도록 melt로 행, 열 변환해준다. Sampling Train-Test-Split 하거나 데이터 양이 많지 않아 대략적인 성능을 알고 싶을 때는 Cross Validation. 보통 Big Data를 다룬다는 가정이 있기 때문에 Train-Test-Split을 한다. Pre-Processing info를 통해 데이터 양이 충분한지, 열 이름에 공백이나 특수문자는 없는지, 데이터 타입이 모두 숫자인지, 불러드릴 수 있는 크기인지, label data를 포함하고 있는지 등을 체크한다. 이때 데이터 양이 충분한지 여부를 확인하고 싶을때는 Learning Curve를 확인한다. 데이터 양이 적다고 판단이 되어 데이터 수집을 해야하는데 데이터 수집할 형편이 되지 않는다면 차원 축소를 고려해본다. 차원 축소는 Scaling, 수작업 등으로 한다. &lt;/p&gt;Learning Algorithm Training Hyperparameter Optimization Post-Processing Final Model Pandas-Profiling설치1!pip install pandas-profiling 예제12345678910from sklearn.datasets import load_wineimport pandas as pdfrom pandas_profiling import ProfileReportimport seaborn as snsdata = load_wine()data1=pd.DataFrame(data.data, columns=data.feature_names)data2 = pd.DataFrame(data.target, columns=['target'])data3 = pd.concat([data1,data2], axis=1)ProfileReport(data3) ProfileReport를 사용해서 자기만의 전처리 방식을 자동화 할 수도 있다. 차원 축소 3가지 방법1231. Feature Scaling2. Feature Selection3. Dimensionality Reduction Feature Scaling13개 차원에서 5개 차원으로 축소1234567891011121314151617181920212223242526from sklearn.decomposition import PCAfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import cross_val_scorefrom sklearn.datasets import load_wineimport pandas as pddata = load_wine()wine = pd.DataFrame(data.data, columns=data.feature_names)target = pd.DataFrame(data.target, columns=['target'])wine_data = pd.concat([wine, target], axis=1)pca = PCA(5)wine_pca = pca.fit_transform(wine_data.iloc[:,:-1])wine2 = pd.DataFrame(wine_pca)wine2_data = pd.concat([wine2, wine_data.target], axis=1)# 13차원cross_val_score(KNeighborsClassifier(), wine_data.iloc[:,:-1], wine_data.iloc[:,-1], cv=10)# 5차원cross_val_score(KNeighborsClassifier(), wine2_data.iloc[:,:-1], wine2_data.iloc[:,-1], cv=10):array([0.68421053, 0.61111111, 0.66666667, 0.55555556, 0.66666667, 0.55555556, 0.77777778, 0.66666667, 0.82352941, 0.75 ])array([0.68421053, 0.61111111, 0.66666667, 0.55555556, 0.66666667, 0.55555556, 0.77777778, 0.66666667, 0.82352941, 0.75 ]) 차원 축소 전과 축소 후 성능 비교후 성능이 축소 전과 비슷하다면 상관성이 높다는 의미로 차원을 축소해도 괜찮다. 데이터의 양이 차원에 비해 작을때 차원 축소로 성능 향상을 하기도 한다. 밑에 부터는 복습 자세하게 다시하기 Pipeline pipeline은 … Pipeline만드는 두가지 방법Pipeline make_pipeline Pipeline1234567891011121314151617181920212223242526272829303132333435import numpy as npimport pandas as pdimport matplotlib as mplimport matplotlib.pyplot as pltimport seaborn as snsimport missingno as mino%matplotlib inlinefrom sklearn.datasets import load_breast_cancerfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import cross_val_scorefrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.pipeline import Pipelinedata = load_breast_cancer()X, y = pd.DataFrame(data.data), pd.DataFrame(data.target, columns=['target'])cancer = pd.concat([X, y], axis=1)t = cross_val_score(KNeighborsClassifier(), cancer.iloc[:, :-1], cancer.iloc[:, -1], cv=10)X_train, X_test, y_train, y_test = train_test_split(cancer.iloc[:, :-1], cancer.iloc[:, -1])pipe = Pipeline([('scaler', MinMaxScaler()), ('knn', KNeighborsClassifier())])pipe.fit(X_train, y_train): Pipeline(memory=None, steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform'))], verbose=False) 표준화GridSearchCV + Pipeline 하는 방법복습시간 19시 ~ 22시 / 총 3시간{: .notice} 2019년 6월 14일 금요일 26thUnsupervised Learnlingk-means 근처 값의 평균을 내어 n개로 묶는 clustering 방법 12345678910111213141516171819202122232425262728293031323334from sklearn.cluster import KMeansfrom sklearn.datasets import load_irisimport pandas as pdiris = load_iris()iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)km = KMeans(3) # 3가지로 묶는다vars(km.fit(iris_data.values)) :&#123;'n_clusters': 3, 'init': 'k-means++', 'max_iter': 300, 'tol': 0.0001, 'precompute_distances': 'auto', 'n_init': 10, 'verbose': 0, 'random_state': None, 'copy_x': True, 'n_jobs': None, 'algorithm': 'auto', 'cluster_centers_': array([[6.85 , 3.07368421, 5.74210526, 2.07105263], [5.006 , 3.428 , 1.462 , 0.246 ], [5.9016129 , 2.7483871 , 4.39354839, 1.43387097]]), 'labels_': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2]), 'inertia_': 78.85144142614601, 'n_iter_': 5&#125; k-means : github blog k-means로 cluster 성능 파악하기12345678910111213141516171819202122232425262728293031323334353637383940import numpy as npiris.target # target data (정답):array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])km.labels_ # cluster로 묶은 답:array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2])np.where(km.labels_==1) # 0 ~ 49 / 100% 맞춤:(array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], dtype=int64),)np.where(km.labels_==2) # 50 ~ 99 / 101,106,112 ~ 149 / 2개 틀림 :(array([ 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 106, 113, 114, 119, 121, 123, 126, 127, 133, 138, 142, 146, 149], dtype=int64),)np.where(km.labels_==0) # 100 ~ 149 / 52, 77 / 14개 틀림:(array([ 52, 77, 100, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 120, 122, 124, 125, 128, 129, 130, 131, 132, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 147, 148], dtype=int64),) dbscan 묶음 갯수 파악하기 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from sklearn.cluster import DBSCAN, dbscan # 둘다 같은 기능from sklearn.datasets import load_irisimport pandas as pdiris = load_iris()iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)dbs = DBSCAN()dbs.fit(iris_data.iloc[:,:-1])vars(dbs.fit(iris_data.iloc[:,:-1])):DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean', metric_params=None, min_samples=5, n_jobs=None, p=None)&#123;'eps': 0.5, 'min_samples': 5, 'metric': 'euclidean', 'metric_params': None, 'algorithm': 'auto', 'leaf_size': 30, 'p': None, 'n_jobs': None, 'core_sample_indices_': array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 61, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 110, 111, 112, 115, 116, 120, 121, 123, 124, 125, 126, 127, 128, 132, 133, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 149], dtype=int64), 'labels_': array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64), 'components_': array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], ...... 12min_samples는 영역 안의 최소 데이터 갯수eps는 영역 크기 Agglomerative ClusteringDendrograms12345678910111213from scipy.cluster.hierarchy import dendrogram, linkagelinkage_matrix = linkage(X, 'ward')figure = plt.figure(figsize=(7.5, 5))dendrogram( linkage_matrix, # color_threshold=0,)plt.title('Hierarchical Clustering Dendrogram (Ward)')plt.xlabel('sample index')plt.ylabel('distance')plt.tight_layout()plt.show() mglearn으로 clustering 시각화 해서 보기설치1!pip install mglearn k-means방식으로 clustering 하는 과정12import mglearnmglearn.plot_kmeans.plot_kmeans_algorithm() k-means boundaries12import mglearnmglearn.plot_kmeans.plot_kmeans_boundaries() agglomerative12import mglearnmglearn.plot_agglomerative.plot_agglomerative_algorithm() dbscan12import mglearnmglearn.plot_dbscan.plot_dbscan() dbscan + k-means 알고리즘 만들기는 다음시간에 계속 알고리즘 만들기Duck typing 방식1234567891011class MyEstimator: def __init__(self): print('a') def fit(self, X,y): print('b')my = MyEstimator()my.fit(data.iloc[:,:-1],data.iloc[:])from sklearn.dummy import DummyClassifierdum = DummyClassifier() # 사람처럼 분류하는 알고리즘 BaseEstimator 상속 방식Dummy 알고리즘 Dummy 알고리즘과 내가 만든 알고리즘과 비교해서 성능이 좋지 못하다면 자신만의 알고리즘을 만들 필요가 딱히 없음…{: .notice} 복습시간 19시 45분 ~ 24시 / 총 4시간 15분{: .notice} 2019년 6월 17일 월요일 27th영화 추천 모델 만들기Collaborative filtering 나와 비슷한 사람을 찾아 내가본 영화를 제외한 비슷한 사람이 본 영화 추천 필요한 데이터 불러오기1234567891011121314151617181920import pandas as pddata = pd.read_csv('u.data', delimiter='\\t', header=None, engine='python', usecols=range(3),names=['user_id','movie_id','ratings'])items=pd.read_csv('u.item', delimiter='|', header=None, engine='python', usecols=range(3), names=['movie_id','title','year'])data.head(4):user_id movie_id ratings0 196 242 31 186 302 32 22 377 13 244 51 2items.head(4): movie_id title year0 1 Toy Story (1995) 01-Jan-19951 2 GoldenEye (1995) 01-Jan-19952 3 Four Rooms (1995) 01-Jan-19953 4 Get Shorty (1995) 01-Jan-1995 DESCR, README 등 도메인 정보 확인하기123456789101112131415161718u.data -- The full u data set, 100000 ratings by 943 users on 1682 items. Each user has rated at least 20 movies. Users and items are numbered consecutively from 1. The data is randomly ordered. This is a tab separated list of user id | item id | rating | timestamp. The time stamps are unix seconds since 1&#x2F;1&#x2F;1970 UTCu.item -- Information about the items (movies); this is a tab separated list of movie id | movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children&#39;s | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western | The last 19 fields are the genres, a 1 indicates the movie is of that genre, a 0 indicates it is not; movies can be in several genres at once. The movie ids are the ones used in the u.data data set. 불러온 정보 필요한 형태로 변형하기12345# 유저 아이디 + 영화 아이디 + 평점 + 영화 이름 + 개봉년도 DataFrame 만들기user_movie_rate=pd.merge(data,items)# user index, item columns로 만들기user_item = data.set_index(['user_id','movie_id']).unstack().fillna(0) 회원간의 상관성 보기 (어떤 연관성 전략을 세울지 고민)12# user_item에서 user가 index이기 때문에 corr하기 위해 Transform 해야함user_item_corr = user_item.T.corr() 연관성이 높은 3명 뽑기 (세부 전략 세우기) 회원 번호 2를 나라고 가정 12345678user_item_corr.loc[2].sort_values(ascending=False)[:4]:user_id2 1.000000701 0.570307931 0.495166460 0.485913Name: 2, dtype: float64 나와 비슷한 사람 영화 목록 - 나의 영화 목록1234567891011121314# 나의 영화 목록my_movie_list = user_movie_rate[user_movie_rate.user_id==2]my_movie_list = my_movie_list.movie_idmy_movie_list=set(my_movie_list)my_movie_list.__len__():62# 나와 비슷한 사람 영화 목록other = user_movie_rate[user_movie_rate.user_id.isin([701]).movie_id.valueother_movie_list = set(other)# 나와 비슷한 사람 영화 목록 - 나의 영화 목록reco_movie_to_me = other_movie_list - my_movie_list 최종 추천 영화 목록 출력하기12345678910111213141516171819reco_movie_to_me=user_movie_rate[user_movie_rate.movie_id.isin(reco_movie_to_me)].sort_values('ratings', ascending=False)final_reco_movie_to_me = set(reco_movie_to_me.movie_id.values)final_my_reco_movie:&#123;124, 326, 328, 333, 344, 689, 690, 750, 751&#125;# 최종 추천 영화 목록list(map(lambda x:set(user_movie_rate.title[user_movie_rate.movie_id==x].values),final_my_reco_movie)):[&#123;'G.I. Jane (1997)'&#125;, &#123;'Conspiracy Theory (1997)'&#125;, &#123;'Game, The (1997)'&#125;, &#123;'Amistad (1997)'&#125;, &#123;'Tomorrow Never Dies (1997)'&#125;, &#123;'Jackal, The (1997)'&#125;, &#123;'Seven Years in Tibet (1997)'&#125;, &#123;'Apostle, The (1997)'&#125;, &#123;'Lone Star (1996)'&#125;] Pandas format 대표값 설정 없이 그대로 변형하는 4가지 방법12341. stack2. unstack3. melt4. pivot pivot123456import pandas as pddata = pd.read_csv('u.data', delimiter='\\t', header=None, engine='python')data.rename(&#123;0:'user_id',1:'movie_id',2:'ratings'&#125;, axis=1, inplace=True)data=data.pivot('user_id','movie_id','ratings')data.fillna(0) Surprise설치1!pip install surprise Surprise를 활용하여 예상 별점 예측하기123456789101112131415161718192021222324252627from surprise import Dataset, Reader, SVD, KNNBasicimport pandas as pddata = pd.read_csv('u.data', delimiter='\\t', header=None, engine='python', usecols=range(3),names=['user_id','movie_id','ratings']) sur_data = Dataset.load_from_df(data, Reader(rating_scale=(1,5)))kb = KNNBasic()svd = SVD()kb.fit(sur_data.build_full_trainset())svd.fit(sur_data.build_full_trainset())# &#123;124, 326, 328, 333, 344, 689, 690, 750, 751&#125; 위 예제에서 회원아이디 2인 사람의 영화 추천목록svd.predict(2,344):Prediction(uid=2, iid=344, r_ui=None, est=3.7619267139014876, details=&#123;'was_impossible': False&#125;)svd.predict(2,124):Prediction(uid=2, iid=124, r_ui=None, est=4.160187263892665, details=&#123;'was_impossible': False&#125;)kb.predict(2,124):Prediction(uid=2, iid=124, r_ui=None, est=4.065428928759065, details=&#123;'actual_k': 40, 'was_impossible': False&#125;)kb.predict(2,344):Prediction(uid=2, iid=344, r_ui=None, est=3.696881271344415, details=&#123;'actual_k': 40, 'was_impossible': False&#125;) Scikit으로 예상 별점 예측하기123456789101112131415161718192021222324252627282930313233from sklearn.neighbors import KNeighborsRegressorknn = KNeighborsRegressor(3)knn.fit(data.iloc[:,:-1],data.iloc[:,-1]):KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=3, p=2, weights='uniform')knn.predict([[2,344]]):array([3.33333333])knn.predict([[2,124]]):array([4.])#####################################knn = KNeighborsRegressor(40)knn.fit(data.iloc[:,:-1],data.iloc[:,-1]):KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=40, p=2, weights='uniform')knn.predict([[2,344]]):array([3.075])knn.predict([[2,124]]):array([3.9]) plot_knn_regression (mglearn)123import mglearnmglearn.plot_knn_regression.plot_knn_regression() recommendation.pdf 내용 추가복습시간 19시 10분 ~ 21시 17분 / 총 2시간 7분{: .notice} 2019년 6월 18일 화요일 28thSurprise vs Scikit차이점 2가지121. Train_test_split2. 평가척도 12345Scikit에서는 Train_Test_Split으로 데이터를 나누었지만 Surprise에서는 Fold로 랜덤하게 쪼개준다.그리고 Scikit에서 평가척도는 score하나 뿐이었지만 Surprise에서는 평가척도로 여러가지가 있다.예를 들어 rmse(root mean square error) &#x3D;&gt; 평균 제곱근 편차Fold &#x3D;&gt; train,test default로 5쌍으로 쪼개어진 generator를 반환한다. Surprise 예제12345678910111213141516171819202122232425262728import pandas as pdfrom surprise import SVD, KNNBasic, Dataset, Reader, dumpfrom surprise.accuracy import rmsedata = Dataset.load_builtin('ml-100k')for trainset, testset in data.folds(): algo_knn.fit(trainset) predictions_knn = algo_knn.test(testset) rmse(predictions_knn):Computing the msd similarity matrix...Done computing similarity matrix.RMSE: 0.9753 Computing the msd similarity matrix...Done computing similarity matrix.RMSE: 0.9685Computing the msd similarity matrix...Done computing similarity matrix.RMSE: 0.9870Computing the msd similarity matrix...Done computing similarity matrix.RMSE: 0.9858Computing the msd similarity matrix...Done computing similarity matrix.RMSE: 0.9739# 평균 제곱근 편차가 0.9739면 어떻다는 거니... 생각해보자.. os vs sys os는 파일관련 처리할 때 사용하고 운영체제 내 폴더파일을 다룰때도 사용한다. 참고로 os는 위험한애임.. sys는 파이썬 관점에서 경로를 확인할때 등에 사용되는 모듈 이다. 자세한건 더 공부하면서 추가해보자. 123456789101112import osos.path.expanduser: &lt;module 'ntpath' from 'C:\\\\Users\\\\SAMSUNG\\\\Anaconda3\\\\lib\\\\ntpath.py'&gt;import syssys.path: ['C:\\\\Users\\\\SAMSUNG\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\SAMSUNG\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\SAMSUNG\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\SAMSUNG\\\\.ipython'] Validation_curve GridSearchCV로 하이퍼 파라미터를 찾을때 같이 사용함으로써 적절한 하이퍼 파라미터를 찾기 위해 참고하면 좋다. 1234567from sklearn.model_selection import validation_curvefrom sklearn.neighbors import KNeighborsClassifierfrom sklearn_evaluation import plotknn = KNeighborsClassifier()train_scores, test_scores=validation_curve(knn, iris.iloc[:,:-1], iris.iloc[:,-1], 'n_neighbors', [3,4,5,6,7], cv=10)plot.validation_curve(train_scores, test_scores, [3,4,5,6,7], 'n_neighbors') Statsmodel로 regression분석하기 Linear regression 분석은 머신러닝에서 해설분야를 담당하고 예측하는데 쓰지는 않는다. R방식설치1!pip install statsmodels 예제1234567891011import numpy as npimport statsmodels.api as smimport statsmodels.formula.api as smfdata = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").dataresults = smf.ols('Lottery ~ Literacy + np.log(Pop1831)',data=data).fit()results2 = smf.ols('Lottery ~ Literacy + Instruction',data=data).fit()results.summary()results2.summary() results summary results2 summary Python 방식12345678910111213import numpy as npimport statsmodels.api as smnobs = 100X = np.random.random((nobs, 2))X = sm.add_constant(X)beta = [1, .1, .5]e = np.random.random(nobs)Iy = np.dot(X, beta) + eresults = sm.OLS(Iy, X).fit()print(results.summary()) 복습시간 19시 ~ 22시 / 총 3시간{: .notice} 2019년 6월 19일 수요일 29th버전관리 2가지 방법121. version-information2. watermark version-information123456# 설치 방법!pip install version-information%load_ext version_information # import 처럼 version_information을 쓰겠다고 명시해주는 구문%version_information numpy, pandas, seaborn, scikit-learn, statsmodels # numpy, pandas, seaborn, 등의 버전 명시 watermark 방식보다 이쁘게 나온다 watermark123%load_ext watermark%watermark -a 지혁 -d -p numpy,pandas,seaborn version_information은 한글이 깨지지만 watermark는 한글도 지원한다 Feature-selection pre-processing의 일종으로 column을 줄여야겠다는 판단이 들었을때 하는 전처리. 성능을 높이기 위한 전처리로, 연산 속도를 향상 시키는 방법으로 사용한다. 이때 정확도 성능을 낮추지 않는 선에서 feature-selection을 진행한다. 3가지 방식1231. Filter2. Embeded3. Wrapper Filter 통계값을 보고 경험적으로 도메인 지식을 통해 column을 걸러낸다. 예시1234567891011121314151617181920212223242526from sklearn.datasets import load_bostonimport pandas as pdfrom sklearn.model_selection import cross_val_scorefrom sklearn.linear_model import LinearRegression# 데이터 불러와서 DataFrame 형태로 만들기data = load_boston()boston = pd.DataFrame(data.data, columns=data.feature_names)target = pd.DataFrame(data.target, columns=['target'])boston_target = pd.concat([boston, target], axis=1)# 기초 통계분석 생략# pairplot으로 clustering 경향 살피거나 도메인 지식 활용하여 영향력이 가장 없는 column 걸러내기boston_target_raw=boston_target.copy() # 원본 데이터 copy해두기boston_target.drop(columns=['AGE']) # 가구당 나이는 집값에 영향이 크지 않다고 판단하여 걸러 내본다.cross_val_score(LinearRegression(), boston_target.iloc[:,:-1], bost_target2.target, cv=10).mean(): 0.20252899006055775# 원본 데이터의 정확도cross_val_score(LinearRegression(), boston_target_raw.iloc[:,:-1], bost_target_raw.target, cv=10).mean(): 0.20252899006055775 AGE column을 걸러냈을 때와 걸러내기 전의 정확도가 같기 때문에 age는 영향력이 없는 column! 따라서 빼도 되는 feature! wrapper 통계값과 머신러닝 기법을 동시에 사용하여 기준을 두고 ranking을 구해 n개 column 뽑는 방법. 123456789101112131415161718192021222324252627282930313233343536from sklearn.feature_selection import RFEfrom sklearn.linear_model import LinearRegressionmodel = LinearRegression()rfe = RFE(model, 7)X_rfe = rfe.fit_transform(boston_target_raw.iloc[:,:-1], boston_target_raw.target) # filter 예시에 있는 boston data 사용X_rfe:array([[ 0. , 0.538, 6.575, ..., 1. , 15.3 , 4.98 ], [ 0. , 0.469, 6.421, ..., 2. , 17.8 , 9.14 ], [ 0. , 0.469, 7.185, ..., 2. , 17.8 , 4.03 ], ..., [ 0. , 0.573, 6.976, ..., 1. , 21. , 5.64 ], [ 0. , 0.573, 6.794, ..., 1. , 21. , 6.48 ], [ 0. , 0.573, 6.03 , ..., 1. , 21. , 7.88 ]])model.fit(X_rfe, boston_target_raw.target):LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)vars(rfe):&#123;'estimator': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'n_features_to_select': 7, 'step': 1, 'verbose': 0, 'estimator_': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), 'n_features_': 7, 'support_': array([False, False, False, True, True, True, False, True, True, False, True, False, True]), 'ranking_': array([2, 4, 3, 1, 1, 1, 7, 1, 1, 5, 1, 6, 1])&#125; Embeded 알고리즘으로 자동으로 영향력이 어느 정도인가 분류 해주는 방법. 12345678910111213141516171819from sklearn.tree import DecisionTreeClassifierimport seaborn as snsiris = sns.load_dataset('iris')dt = DecisionTreeClassifier()dt.fit(iris.iloc[:,:-1], iris.iloc[:,-1]) # classification에 한정해서 숫자로 바꾸지 않았을때 자동으로 바꿔줌:DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best')dt.predict([[3,3,3,3]]): array(['virginica'], dtype=object)dt.feature_importances_: array([0. , 0.01333333, 0.06405596, 0.92261071]) # 각각의 숫자는 영향력의 크기를 나타낸다 Ensemble 여러가지 알고리즘을 동시에 사용하여 최적의 성능을 낼수 있는 알고리즘을 생성한다 RandomForest 랜덤포레스트는 분류, 회귀 분석 등에 사용되는 앙상블 학습 방법의 일종으로, 훈련 과정에서 구성한 다수의 결정 트리로부터 분류 또는 평균 예측치를 출력함으로써 동작한다.성능이 좋고 overfitting이 잘 안일어난다. 1234567891011121314from sklearn.ensemble import RandomForestClassifierrf=RandomForestClassifier()rf.fit(iris.iloc[:,:-1], iris.iloc[:,-1]): RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=None, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None, oob_score=False, random_state=None, verbose=0, warm_start=False)rf.feature_importances_: array([0.03122967, 0.02095218, 0.57202362, 0.37579453]) MLxtend설치1!pip install mlxtend StakingData부터 Model 학습까지Cross-validate 3가지1231. Cross_val_score2. Cross_validate3. Cross_val_predict Fit_transform 하는 3가지1231. pre-processing2. feature-extraction3. RFE Column 줄이는 3가지 방법1231. filter2. PCA3. RFE 복습시간 18시 45분 ~ 22시 20분 / 총 3시간 35분{: .notice} 2019년 6월 20일 목요일 30thDeep Learning2개 이상의 Perceptron 을 연결하여 많은 Layer 로 구성된 기계학습 을 Deep Learning이라고 부른다 인공지능 발전에 기여한 인물들사진 출처: brunch Frank Rosenblatt’s Perceptron123451957년 Frank Rosenblatt에 의해 고안된 인공신경망의 한 종류로써 Perceptron이 발표되었습니다이 Perceptron은 뉴런의 행동 방식을 모방하여 만들어졌습니다.Single Perceptron은 입력값의 연산 결과가 1이면 activate되고 0이되면 deactivate하는 방식의 선형 모델입니다.이렇게 하면 OR ,AND 연산이 가능하지만 XOR 연산을 할 수 없는 문제가 발생합니다XOR 연산을 하기 위해서는 Perceptron을 하나 더 연결하여 다층 퍼셉트론을 통해 해결 할 수 있습니다 Perceptron 학습 방법 입력값의 결과값을 1과 0으로 분류하고 실제값과 예측값의 활성함수 리턴값이 다를 경우 가중치를 조정하며 최적의 가중치를 찾아간다 12345678910111213141516171819202122232425AND Gate를 만든다고 가정하자Data &#x3D;&gt; (0,0) &#x2F; Result &#x3D;&gt; 0 (0,1) &#x2F; Result &#x3D;&gt; 0 (1,0) &#x2F; Result &#x3D;&gt; 0 (1,1) &#x2F; Result &#x3D;&gt; 1위와 같은 dataset이 있을때 Perceptron 학습방법은 다음과 같다활성함수: y &#x3D; 1 (x1*w1 + x2*w2 + w0 &gt;&#x3D; 0) or 0 (otherwise)# x1, x2는 입력값 w1,w2는 가중치 w0는 bias(절편)(0,0)일때w0 &lt; 0 이 되어야 결과값이 0이 나오기 때문에w0 값을 임의로 -1를 찾았음(0,1)일때w2 -1 &lt; 0을 만족하는 가중치를 임의로 0.5라고 한다(1,0)일때w1 -1 &lt; 0을 만족하는 가중치를 임의로 0.5라고 한다(1,1)일때0.5 + 0.5 - 1 &#x3D; 0 결과값이 0이기 때문에 y &#x3D; 1을 만족하므로학습된 Perceptron의 coefficient또는 weight값은 0.5, 0.5, intercept 또는 bias는 -1 Bernard Widrow’s Adaline Adaline(Adptive Linear Neuron)은 신경세포의 초기 모델. Adaline 입력값의 결과값과 실제 결과값을 비교하여 오차가 최소가 되도록 가중치를 찾아간다 예시1234567891011121314151617181920구구단에서 2단을 학습시키기 위한 딥러닝 이라고 가정 했을때data: 2 &#x3D;&gt; 2 X 0.5(가중치) &#x3D;&gt; result: 1result &#x3D; 1real_result &#x3D; 2 X 2 &#x3D; 4오차 : real_result - result &#x3D; 3가중치를 높여야 겠군!data: 3 &#x3D;&gt; 3 X 3(가중치) &#x3D;&gt; result: 9result &#x3D; 9real_result &#x3D; 3 X 2 &#x3D; 6오차: real_result - result &#x3D; -3가중치를 낮춰야 겠군!data: 4 &#x3D;&gt; 4 X 2(가중치) &#x3D;&gt; result: 8result &#x3D; 8real_result &#x3D; 4 X 2 &#x3D; 8오차: real_result - result &#x3D; 0오차가 없군! 학습을 멈춰야겠어! 정확도가 100%네 ?!(실제로는 정확도 100%나오기 힘듦) Perceptron vs Adaline요약하면 Perceptron은 임계값을 1로 잡고 입력값의 결과가 1이 넘어가면 활성함수에 의해 예측값이 나오고 실제값과 예측값이 다를 경우 가중치를 조정한다.Adaline은 입력값의 결과가 예측값이 되고 활성함수(실제값-예측값)의 리턴값을 최소화 하는 방향으로 가중치를 찾아간다는 점에서 차이가 있다. Neuron’s communication12345678910뉴런이 휴지상태일때 막전류가 -70mv 극성을 띄는데 뉴런에 자극이 가해지면 이온통로가 열리고이온이 세포 안으로 들어오면 막전위의 변화를 알립니다.그러면서 막전류가 -55mv에 도달하게 되면 수 천개의 나트륨 통로가 열리면서 뉴런 내부에엄청난 양의 나트륨 이온이 세포 내부로 들어와 급격하게 양전하가 되거나 혹은 극성이 없어집니다.엄청난 나트륨 이온의 유입으로 뉴런의 내부가 +30mv가 될때, 뉴런은 항상성 유지를 위해 나트륨 통로는 닫히고칼륨 이온 통로가 열리면서 칼륨을 세포 밖으로 내보냅니다.이러한 방식으로 뉴런 가지안에서 연쇄 반응을 통해 탈분극과 재분극을 반복하여 활동 전위가 전도 됩니다.이때 활동 전위는 한 방향만으로 전도됩니다.그리고 끝에 시냅스라는 부분에서 신경 전달물질을 세포 밖으로 내보내 다른 세포를 자극하기 위해 이동합니다 이렇게 휴지상태 &#x3D;&gt; 활동전위 &#x3D;&gt; 신경전달 물질 &#x3D;&gt; 다른 세포 자극 사이클을 반복하여 뉴런과 소통하게 됩니다. Adaline과 NeuronAdaline | NeuronInput Data | 타 뉴런들의 자극들Weight | 수상돌기Node | 세포체Activation Function | 축삭돌기(휴지 상태=&gt;활동전위)Output Data | 축삭돌기 말단, 신경전달 물질 Paul Werbos’s MLP12341974년 하버드대 폴 워보스는 다층 퍼셉트론환경에서 학습을 가능하게 해주는back-propagation 알고리즘을 고안해냈습니다.그러나 신경망에 대해 냉랭했던 분위기 때문에매장 당할까바 발표하지 못하고 8년 후 1982년에 저널에 발표하게 됩니다. Yann LeCun &amp; David Rumelhart &amp; Geoffrey Everest Hinton123456저널에 발표되고 2년뒤 1984년에 신경망 연구로 박사논문을 준비하던 얀 레쿤이논문을 발견하여 다시 세상에 나왔고, 1986년 럼멜하트와 힌튼교수에 의해 다시 부활하게 되었습니다힌튼 교수는 홉필드 네트워크에 신경망 알고리즘을 결합시켜 볼츠만 머신을 만들어냅니다.그리고 마침내 1998년 힌튼 교수 밑에서 박사과정을 밟고있던 얀쿤과 요수아 벤지오가볼츠만 머신에 back-propagation을 결합하여 CNN(Convolutional Neural Networks)알고리즘 만들어 냅니다. Scikit Perceptron123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import seaborn as snsfrom sklearn.linear_model import Perceptronfrom sklearn.preprocessing import MinMaxScalermms = MinMaxScaler()pct = Perceptron()iris = sns.load_dataset('iris')iris.iloc[:,:-1] = mms.fit_transform(iris.iloc[:,:-1])iris.species = iris.species.map(&#123;\"setosa\":0,\"versicolor\":1,\"virginica\":2&#125;)pct.fit(iris.iloc[:,:-1],iris.iloc[:,-1]) # 옵션 early_stopping =&gt; overfitting 막기위한 방법 / fit_intercept 가중치를 사용할지 말지vars(pct):&#123;'loss': 'perceptron', 'penalty': None, 'learning_rate': 'constant', 'epsilon': 0.1, 'alpha': 0.0001, 'C': 1.0, 'l1_ratio': 0, 'fit_intercept': True, 'shuffle': True, 'random_state': 0, 'verbose': 0, 'eta0': 1.0, 'power_t': 0.5, 'early_stopping': False, 'validation_fraction': 0.1, 'n_iter_no_change': 5, 'warm_start': False, 'average': False, 'n_iter': None, 'max_iter': None, 'tol': None, 'class_weight': None, 'n_jobs': None, '_tol': None, '_max_iter': 5, 'coef_': array([[-0.80555556, 1.54166667, -1.57627119, -1.75 ], [ 0.11111111, -5.75 , 1.45762712, -2.70833333], [ 0.52777778, -2.41666667, 4.13559322, 5.875 ]]), 'intercept_': array([ 1., 1., -6.]), 't_': 751.0, 'classes_': array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10'), '_expanded_class_weight': array([1., 1., 1.]), 'loss_function_': &lt;sklearn.linear_model.sgd_fast.Hinge at 0x242aef05770&gt;, 'n_iter_': 5&#125; loss, cost, objective functionloss, cost : 실제값 - 예측값 즉, 값이 작아질 수록 정확해진다는 의미 objective : 유사도 즉, 비슷하면 비슷할 수록 값이 커지고 값이 크면 정확해진다는 의미 오차를 구하는 방법도 여러가지이다. Feed-forward vs Back-PropagationFeed-forward: 벡터연산(행렬), 앞으로 나아가는 연산 Back-Propagation: 미분(편미분) Vanishing gradient problem 기울기 값이 사라져 학습이 안되는 문제 relu 알고리즘으로 이러한 문제 해결! Neural network 표현방식121. 전통적인 머신러닝 방식으로 표현2. Graphical neural network Graphical neural network Tensorflow절차1234560. import1. Data 불러오기2. train-test-split3. 학습 가능하도록 차원 변환 (n차원 &#x3D;&gt; 1차원)4. Sequence 만들기 (Layer)5. 학습 (어떻게 학습시킬까 : compile) 예시12345678910111213141516171819202122232425!pip install tensorflow==2.0.0b1 # 설치import matplotlib.pyplot as pltimport numpy as npfrom sklearn.neighbors import KNeighborsClassifierimport tensorflow as tfknn = KNeighborsClassifier()mnist = tf.keras.datasets.mnist # 가장많이 쓰이는 손글씨 데이터data=mnist.load_data() # 데이터 불러오기 / numpy 처럼 보이지만 tuple임data[0][0].shape # x: (60000, 28, 28)data[0][1].shape # y: (60000,)plt.imshow(data[0][0][0], cmap='gray')data[0][1][0]: 5(X_train, y_train),(X_test, y_test) = mnist.load_data()# 2차원 데이터 1차원으로 바꿔주기# temp, result 방식 둘 중 원하는 방식으로temp = [x.flatten() for x in X_train]result = np.array(list(map(lambda x:x.flatten(), X_train))) Keras쓰는 4가지 방식 아직 완벽하게 복습이 되지 않아 부정확한 내용이 있을 수 있음을 알려드립니다… Perceptron : tistoryAdaline, gradient descent : m_blog Vanishing gradient problem : tistoryReLu: tistory인공지능 그림으로 배우기: brunchCNN: tistory 복습시간 19시 10분 ~ 22시, / 총 2시간 50분{: .notice} 2019년 6월 27일 목요일 34thPandas 시계열 분석Deep Learning에서 Overfitting 막는 방법123451. 앙상블2. Regularization3. Drop out4. Early stopping5. 데이터 양을 많이 Deep Learning에서 중요한것은?Data &nbsp; vs &nbsp; Algorithm 출처: Peter Norvig’s The Unreasonable Effectiveness of Data 논문 Peter Norvig의 논문에서도 알 수 있듯이 복잡한 문제에서 딥러닝의 성능이 좋으려면 좋은 알고리즘 보다는 더 많은 데이터가 중요하다는 것을 알 수 있다. 하지만 데이터 확보가 어려운 경우도 많고 중간 규모의 데이터는 매우 흔한 일 이기 때문에 알고리즘의 중요성 또한 무시할 수 없다. 당신의 데이터는 일반적입니까? Machine Learning, Deep Learning에서 학습시키는 Label data는 항상 정답이라는 가정을 했었습니다. 그런데 과연 그 정답 데이터가 진짜 현실세계에서 정답 데이터 인지 확신할 수 있을까요? 그리고 데이터를 수집한 사람이 혹은 시스템이 편향된 데이터를 수집하지는 않았을까요? 좋은 데이터를 갖고 있다고 가정하더라도 학습을 시키는 사람에 따라서 편향된 모델이 나올 수 있다는 것을 명심하자 데이터는 공정한 데이터 여야 한다. 공정한 데이터… 기준이 불명확하고 사람마다 공정성의 기준이 다를 수 있으니 사람이 저지르는 편향 유형을 살펴보고 편향된 데이터인지 판단하는 눈을 기르도록 하자. 편향의 유형123451. 보고편향2. 자동화 편향3. 표본 선택 편향4. 그룹 귀인 편향5. 내재적 편향 1. 보고 편향1234보고 편향은 수집된 데이터의 속성 및 결과의 빈도가 실제 빈도를 정확하게 반영하지 않을때 나타납니다.예를 들어 쇼핑몰 리뷰가 이러한 특징을 갖고 있다.사람들은 무언가 물건을 사고 정말 마음에 들때 혹은 정말 마음에 들지 않을때 리뷰를 남기는특징이 있다. 보통 정말 좋을때와 정말 나쁠떄 중간 지점의 리뷰는 수집되기 힘든걸 볼 수 있다. 2. 자동화 편향12345자동화 편향은 두 시스템의 오류율과 관계없이 자동화 시스템이 생성한 결과를 비 자동화 시스템이생성한 결과보다 선호하는 경향을 말합니다.예를 들어 병아리 성별을 감별하는 자동화 시스템과 사람이 직접 감별하는 것 두 가지가 있다는 사실을 알려 줬을 때 어느 것이 정확도가 높을까? 라고 질문을 한다면 보통 사람들은자동화 시스템을 더 신뢰할 것이다. 하지만 실제로는 병아리 성별 감별하는 전문가 즉 감별사는자동화 시스템의 부정확성 때문에 고액의 연봉을 받는 직종이라고 한다. 3. 표본 선택 편향1234567891. 포함 편향- 선택된 데이터가 대표셩을 갖지 않는 경우- ex) A 고등학교의 영어 성적 데이터를 갖고 전국의 고등학생 영어 성적의 분포를 알려고 하는 경우2. 무응답 편향- 데이터 수집시 참여도의 격차로 인해 데이터가 대표성을 갖지 못하는 경우- ex) 대선운동 할때 유선전화로 여론조사를 시행한 결과로 대선 후보의 당선 예측을 하는 경우3. 표본 추출 편향- 데이터 수집 과정에서 적절한 무작위 선택이 적용되지 않았을 경우- ex) 4. 그룹 귀인 편향1234561. 내집단 편향- 자신이 소속된 그룹 또는 본인이 공유하는 특성을 가진 그룹의 구성원을 선호하는 경향을 나타내는 경우- ex) 유유상종, XX대를 졸업한 A라는 사람이 동문인 B를 만났을 때 A가 B를 더 챙겨주고 싶어하고 친해지려하는 심리2. 외부 집단 동질화 편향- 자신이 속하지 않은 그룹의 개별 구성원에 관해 고정 관념을 갖거나 그들이 모두 동일한 특징을 가진다고 판단하는 경향을 나타내는 경우- ex) 어떤 A라는 사람이 컴퓨터를 전공했고 어떤 B라는 사람은 영문과를 전공했다고 했을 때 B라는 사람이 A라는 사람을 보고 &quot;컴퓨터 수리 잘하겠네?&quot; 라는 생각을 갖는 경향 5. 내재적 편향123456781. 확증 편향- 자신의 신념과 일치하는 정보는 받아들이고, 일치하지 않는 정보는 무시하는 경향- ex) 듣고싶은 것만 듣고 보고싶은 것만 보는 심리, 담배를 피는것은 몸에 해롭다는 것을- 알지만 일부 담배를 피고 오래 사는 사람을 보고 &#39;담배 아무리 적게 펴도 병걸릴 사람들은- 다 걸리고 안걸릴 사람은 아무리 많이펴도 안걸린다,- 100살 넘게 담배펴도 건강한 할아버지 봐라!&#39;라는 식의 사고방식2. 실험자 편향- 실험자가 바라는 방향대로 되기를 바라는 마음에서 발생되는 편향 머신러닝 단기집중과정 (편향 출처) : google Tensor board12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849%load_ext version_information%load_ext tensorboardversion_information tensorflow:Software VersionPython 3.7.3 64bit [MSC v.1915 64 bit (AMD64)]IPython 7.4.0OS Windows 10 10.0.17134 SP0tensorflow 2.0.0-beta1Thu Jun 27 17:01:13 2019 ¢¥eCN©öI¡¾©ö C¡ÍA¨ª¨öAimport tensorflow as tfimport datetimemnist = tf.keras.datasets.mnist(x_train, y_train),(x_test, y_test) = mnist.load_data()x_train, x_test = x_train / 255.0, x_test / 255.0def create_model(): return tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(512, activation='relu'), tf.keras.layers.Dropout(0.2), tf.keras.layers.Dense(10, activation='softmax') ])model = create_model()model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])log_dir=\"log\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # 현재시간을 문자열로 바꿔서 저장tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)model.fit(x=x_train, y=y_train, epochs=5, validation_data=(x_test, y_test), callbacks=[tensorboard_callback] )%lsmagic # %load_ext tensorboard를 하면 %tensorboard가 생긴다: Available line magics:%alias %alias_magic %autoawait %autocall ....%tensorboard.....%tensorboard --logdir log/ 2019년 6월 28일 금요일 35th (마지막 수업)","categories":[{"name":"AI","slug":"AI","permalink":"http://jungjihyuk.github.io/categories/AI/"},{"name":"Machine Learning","slug":"AI/Machine-Learning","permalink":"http://jungjihyuk.github.io/categories/AI/Machine-Learning/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://jungjihyuk.github.io/tags/Python/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://jungjihyuk.github.io/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://jungjihyuk.github.io/tags/Deep-Learning/"},{"name":"AI","slug":"AI","permalink":"http://jungjihyuk.github.io/tags/AI/"},{"name":"Lecture","slug":"Lecture","permalink":"http://jungjihyuk.github.io/tags/Lecture/"},{"name":"Data Analysis","slug":"Data-Analysis","permalink":"http://jungjihyuk.github.io/tags/Data-Analysis/"}]},{"title":"Each part summary of TOEIC","slug":"toeic","date":"2019-04-16T15:00:00.000Z","updated":"2020-02-24T15:19:13.334Z","comments":true,"path":"2019/04/17/toeic/","link":"","permalink":"http://jungjihyuk.github.io/2019/04/17/toeic/","excerpt":"산타토익으로 공부하고 파트별 공부 정리하기","text":"Part1보기중 Being이 들리면 사람이 있는지 체크 그림에 사람이 없는데 being이 들린다면 90% 오답! 12345678910예외)Display, Cast, Arrange, Block1. 다른 크기의 꽃병들이 진열되어 있다.- Vases of different sizes are being displayed2. 모래에 그림자가 드리워져 있다.- Shadows are being cast on the sand3. 보수작업을 위해 차선 하나가 폐쇠되어 있다.- A lane is being blocked for a maintenance work4. 진열용 선반들이 몇개 놓여있다.- Some shelves are being arragned for display ## Part2 when 의문문의 정답 표현123456789101112┌── in, by, not util + 시점│└── after, before, when, as soon as not for another + 기간 &#x3D; 기간 from now (today) &#x3D; 최소기간동안 &#x3D; 기간 이후로1. Yes&#x2F;No로 시작되는 보기는 오답2. 질문과 유사한 발음, 형태가 들리면 오답 &#x3D;&gt; 아닌 경우도 있기 때문에 정확히 못들었을 때만 소거!3. 질문에 사람, 직책명이 들리지 않았을 경우 보기에 인칭대명사가 들리면 오답 ### where vs who 질문 123456where로 질문하고 답으로 장소가 아닌 사람으로도 나올 수 있으니 주의!who 역시 답으로 사람이 아닌 where로 나올 수 있으니 주의!ex) Q: 지혁이 어디갔어요? A: 지혁이가 누구죠? or 아 사장님 말씀이신가요? Q: 지혁이가 누구에요? A: 편의점 앞에 있는 사람이요 ### 일반의문문/부가의문문/간접의문문/부정의문문 * Yes/No로 시작할 경우 정답확률 90%이상 ※부가의문문의 억양 자신의 의견이 옳다고 생각하여 상대의 동의를 바랄 때 This assignment doesn’t look easy, does it? (끝을 내려준다) 자신의 말이 맞는지 아닌지 상대방에게 확일할 These are your gloves, aren’t they? (끝을 올려준다) ※부정의문문, 부가의문문의 답긍정일 때: Yes부정일 때: No 부정의문문 한국어 영어 한국인이 아닌가요? Aren’t you Korean? 네, 한국인이 아니에요 No, i am not Korean 아니오, 한국인이에요 Yes, i am Korean 부가의문문 한국어 영어 춥지? 그렇지 않아? It’s cold, isn’t it? 응, 안추워 No, it’s not cold 아니, 추워 Yes, it’s not cold 추가 (Would you mind~?)Q. 실례지만 제가 이 책상 좀 사용해도 될까요?Q. Would you mind if i use this table?A1. 아뇨 사용하지마세요A1. Yes i do A2. 네 사용하세요A2. No i don’t ## Part3 Part3, 4 듣기 포인트1231. 듣기 전 문제 분석2. 문제 유형 파악 -&gt; 주제를 묻는구나 or 미래행동 문제구나 등등.. ## Part4 ## Part5 주어 앞에 올 수 있는 한정사 a, an the its, my, your, his, her, their, our을 포함하는 소유격 some, any, other등… 부정형용사 specific plan about the project’s reach as well as its duration will be kept under wraps until the next week’s meeting. ### 2형식 123456789주어 + 동사 + 보어 &#x3D;&#x3D;&gt; 명사 (동격) &#x3D;&#x3D;&gt; 형용사 (상태)All client&#39;s files consulted with the lawyers must remain _________as a matter of the federal privacy act1. confidential2. confidentially3. confidentiality4. confidence 문두의 분사구문1234567891011121314자동사 --&gt; ing타동사 --&gt; 목적어 O --&gt; ing --&gt; 목적어 X --&gt; p.p단, 4,5 형식 동사는 목적어가 있어도 p.p 가능ex)Employing more than 1,000 people locally, Stratus Inc.,is the leading company in the northwest region.The high costs of implementing a drainage system can be a major problem for countires _______a reliable supply of clean drinking water1. lack2. lacking3. laked4. lacks ### 전치사 뒤 명사구가 올때 123456전치사 뒤에는 목적어가 와야하므로 명사, 대명사, 동명사구, 명사절이 와야 한다따라서 전치사 뒤에 빈칸이 있을때 빈칸뒤에 명사나 관사+명사가 있다면 빈칸 뒤 명사를 포함하는 명사구가 와야한다!ex)The high costs of ________ a drainage system ~1. implementing2. implemented c.f 명사를 수식하는 형용사의 위치 관사 --- 형용사 --- 명사 형용사가 명사를 수식할때 관사 앞에 오지 않는다! 동명사동사 + ing&nbsp;&nbsp;+ 전치사구&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ 형용사&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ 명사=&gt; 원래 동사 형태일때 성질 만족시켜야함 문제 출제 유형1231. 전치사 + ________ + 관사 + 명사2. ________ + 관사 + 명사 + 단수동사 ~3. 주어 + 동사 + ________ + 관사 + 명사 ※ 빈칸 뒤 명사가 관사를 취하지 않는 경우 의미를 따져 봐야 함ex)purchasing train ticketspurchased train tickets 동명사의 관용 표현 Look forward to ~ ing be subject to ~ ing object to ~ing be opposed to ~ ing spend 시간/돈 ~ing be busy ~ing be used to ~ing be accustomed to ~ing be dvoted to ~ing be dedicated to ~ing be committed to ~ing have difficulty ~ing keep ~ing ## Part6 ## Part7","categories":[{"name":"English","slug":"English","permalink":"http://jungjihyuk.github.io/categories/English/"}],"tags":[{"name":"정리","slug":"정리","permalink":"http://jungjihyuk.github.io/tags/%EC%A0%95%EB%A6%AC/"},{"name":"산타 토익","slug":"산타-토익","permalink":"http://jungjihyuk.github.io/tags/%EC%82%B0%ED%83%80-%ED%86%A0%EC%9D%B5/"},{"name":"토익","slug":"토익","permalink":"http://jungjihyuk.github.io/tags/%ED%86%A0%EC%9D%B5/"}]},{"title":"Conversation in English","slug":"conversationinenglish","date":"2019-04-08T15:00:00.000Z","updated":"2020-02-24T15:11:26.583Z","comments":true,"path":"2019/04/09/conversationinenglish/","link":"","permalink":"http://jungjihyuk.github.io/2019/04/09/conversationinenglish/","excerpt":"일상에서 대화하는 문장 영어로 번역하기","text":"영어 회화는 일상대화에서 영어로 번역하자중요!! 일상에서 자주 쓰는 표현들 위주로, 한국어 -&gt; 영어 로 바꾸고 싶은 표현이 생각날 때, 궁금할 때 영어가 더 재밌어 진다!!{: .notice} 동사 어휘 청구하다 charge 청구 되었다 had been charged 기소 되었다 have been charged ex) 545명의 운전자들이 과속으로 잘못 유죄 판결을 받은 후 3명의 경찰관이 직권남용으로 기소되었다. ex) Three cops have been charged with misconduct after 545 motorists were wrongly convicted of speeding 두고온다, 두고가다, 출발하다, 놓고온다, 맡기고 간다 leave ex1) 나는 내 키를 두고 가지 않았어요 ex1) I didn’t leave my key ex2) 여기 두고가시면 됩니다 ex2) You can leave it here 놓고 갔어요 left ~하게 해줄 것이다 will enable 이제 할 수 있어 be able to ex1) 나 이젠 기타 잘 쳐 ex1) Now i’m able to play the guitar well ex2) 어제 날씨 정말 좋았어, 그래서 우리 이제 밖에서 먹을 수 있을 거야 ex2) The weather was great yesterday, so we were able to eat outside 할 수 있어 can ex1) 나 기타 잘 쳐 (원래부터) ex1) I can play the guitar ex2) 내가 5살 이었을 때 자전거를 탈 수 있었어 ex2) I could ride a bike when i was five 이다, 입니다, 이에요, 있다 be ex1) 물입니다 ex1) Be water ex2) 여기 있다 ex2) Be here ex3) 여기 있었다 ex3) was here ex4) 여기 있을 거야 ex4) will be here 내가 ~ 하는 that i ~ ex1) 내가 좋아하는 ex1) that i like ex2) 내가 타는 ex2) that i take 해보다 try 이미 해봤다 have tried 끝내다 finish has 역시 연습해야함 이미 끝냈다 have finished have done 보내다 send 벌써 보냈다 have sent 계산하다 pay 벌써 계산 했어요 have paid 받는다, 구하다 get 벌써 받았어요 have got ex1) 저 잔돈 받았어요 ex1) I have got the change ex2) 아이폰 이미 구했어요 ex2) I have got I-phone ex3) 그는 이미 답을 알고 있어요 ex3) He has got the answer 모으다 gather 이미 모았어요 have gathered ex) 이미 여권들을 모았어요 ex) I have gatherd the passport 달라고 하다 ask for 이미 달라고 했어요 have asked for ex) 그가 정답을 달라고 했어요 ex) He has asked for the answer 산다 buy 이미 샀다 have bought 먹는다 eat 이미 먹었어요 have had ex) 저 이미 먹었어요 ex) I have had 본다 see 이미 봤다 have seen ex) 그는 이미 봤대 ex) He has seen 다녀온다 go 이미 갔다 왔어요 have been ex1) 저 전에 거기 다녀왔어요 ex1) I have been there before ex2) 저 일본 갔다 왔어요 ex2) I have been to Japan 바꾸다 change 이미 바꿨어요 have changed 내려 놓는다 put down 이미 내려 놨어요 have put down ex) 저 이미 총 내려 놨어요 ex) I have put the gun down 꺼내 놓는다 take out 미리 꺼내 놨어요 have taken out ex) 내 돈 전부다 꺼내 놨어요 ex) I have taken out all my money 왔다 come 이미 왔다(와서 계속 있는 상태) have come ~이 딸려오다 come with ex) 저녁 식사에 샐러드가 나오나요? ex) Does the dinner come with a salad? 이미 떠났어요 have left ex) 저 이미 출발 했어요 ex) I have left 끄다 turn off 이미 꺼두다 have turned off ex) 저 핸드폰 이미 껐는데요 ex) I have turned off my cell phone 완화되게 하다 ease 완화 시킬 것이다 will ease ex) 고속도로가 공항으로 가는 길의 교통체증을 완화 시킬 것이다 ex) The highway will ease traffic congestion on routes leading to the airport 변화/이동 관련 동사 (get 동사의 여러가지 의미) 사다 buy 얻다 obtain 받다 receive 가져오다 bring ~한 상태가 되다 become 도착하다, 이동하다 arrive/move 이해하다 understand have 동사의 여러 가지 의미 소유 own 먹다/마시다 eat/dring 경험하다 experience 병이들다 disease ex) 나 감기 걸렸어 ex) I’ve got a cold 생각이 들다 idea ex1) 나도 몰라 ex1) I have no idea ex2) 나 이번주에 계획 없어 ex2) I don’t have any plans for the week [시원스쿨 강의](https://www.youtube.com/watch?v=yMwOU7u--h8&&t=52s) Today’s conversation4월 7일 일요일 카드 가지고 오셨나요? me:&nbsp;&nbsp;Did you bring your card? papage:&nbsp;&nbsp;Did you bring your card? 이것도 좀 데워주세요 me:&nbsp;&nbsp;Please 데우다 this. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Would you please 데우다 this. papage:&nbsp;&nbsp;Could you heat this up for me? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Please warm this up. 네? 뭐라구요? me:&nbsp;&nbsp;what? come again? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;what? pardon me? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;what? what did you say? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Excuse me sir? papage:&nbsp;pardom me? 나 지금 나가야해 me:&nbsp;&nbsp;I have to go now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I’m just going to go now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I’m gonna go papage:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I have to go now 응 지금 버스 있어 me:&nbsp;&nbsp;yes, 저랑 근무 시간 바꿔주실 수 있나요? me:&nbsp;&nbsp;could you change the job schedule for me? 네이버도 계속 발전해서 좋은 회사지만 조금 청렴했으면 좋겠어요.. me:&nbsp;&nbsp;I’d like to be 청렴 for naver even good company that keep developing papage:&nbsp;&nbsp;Naver is a good company because it has continued to develop, but i hope Naver will be a little integrity 그럴시간 있으면 밖에 나가서 뛰어 노는 걸 추천한다. (속마음) me:&nbsp;&nbsp;I would recommand you to go out for playing a ground if you have many time. papage:&nbsp;&nbsp;If you have time for that, i recommend you to go out and play. 두 명의 학생이 왔어요. me:&nbsp;&nbsp;Two students came. papage:&nbsp;&nbsp;There are two students &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Two students showed up 4월 8일 월요일 밥 먹으러 가? (점심) me:&nbsp;&nbsp; Do we go for a lunch? papage:&nbsp;&nbsp; Are we going to have lunch? 네 시간 돼요, 가능합니다. me:&nbsp;&nbsp; yes, i can , it’s possible &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yes, i do 시간 끌지마! (연관 검색..) blog:&nbsp;&nbsp; Don’t stall for time 언제 시간 되세요? blog:&nbsp;&nbsp; When are you available? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; When are you free? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; When can we meet you? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Do you have any plans for this weekend? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Are you free tonight? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Do you have time for that day? 언제든 괜찮습니다 x날 제외하고. blog:&nbsp;&nbsp;Any day will be fine except x 이번주는 스케줄이 꽉 차있어. blog:&nbsp;&nbsp;I’m all dated up this week. 배가 불러서 밥 생각이 없어. me:&nbsp;&nbsp;I’m full, so i don’t want to eat. papage:&nbsp;&nbsp;I’m so full that i don’t want to eat. 저번에 말했던 밥집에서 가족들이랑 밥 먹었거든. me:&nbsp;&nbsp;I have a lunch at restaurant that i told you with my family. papage:&nbsp;&nbsp;I ate with my family at the restaurant i told you last time 4월 12일 금요일 너 이거 해볼래? blog: &nbsp;&nbsp; Do you wanna try this? 응, 하고 싶어blog: &nbsp;&nbsp; I’m down with it(that)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I’m down for it 나 지금 기분 안좋아 blog: &nbsp;&nbsp; I’m feeling down","categories":[{"name":"English","slug":"English","permalink":"http://jungjihyuk.github.io/categories/English/"}],"tags":[{"name":"영어","slug":"영어","permalink":"http://jungjihyuk.github.io/tags/%EC%98%81%EC%96%B4/"},{"name":"회화","slug":"회화","permalink":"http://jungjihyuk.github.io/tags/%ED%9A%8C%ED%99%94/"},{"name":"시원스쿨","slug":"시원스쿨","permalink":"http://jungjihyuk.github.io/tags/%EC%8B%9C%EC%9B%90%EC%8A%A4%EC%BF%A8/"}]},{"title":"알고리즘","slug":"algorithm","date":"2019-04-03T15:00:00.000Z","updated":"2020-02-24T15:39:52.070Z","comments":true,"path":"2019/04/04/algorithm/","link":"","permalink":"http://jungjihyuk.github.io/2019/04/04/algorithm/","excerpt":"알고리즘 정리","text":"목차1234&#96;&#96;&#96;#### 레드 블랙 트리 이진 트리의 불균형문제를 해결하여 균형있게 탐색할 수 있도록 정렬하는 알고리즘. #### 조건 1. 루트노드는 항상 블랙. 2. 새로 추가되는 노드는 항상 레드. 3. 모든 깊이의 차수는 항상 동일해야 한다. 4. 레드 노드가 연속되어서는 안된다. #### 연속된 레드 노드를 바꿔주는 방법 1. 연속된 레드 노드의 부모 노드를 기준으로 양쪽에 레드 노드가 있을 때 - 레드는 블랙으로 블랙은 레드로 바꾼다. 단 루트 노드는 항상 블랙 2. 연속된 레드 노드의 부모 노드를 기준으로 한쪽에 블랙 노드가 있을 때 - 회전시킨다 - 일자일때, 자식-자식-부모 형태라고 한다면 가운데 자식 노드를 부모 노드로 올려 놓는다. - 꺾인 모양일때, 자식-자식-부모 형태라고 한다면 맨 밑 자식을 부모 노드로 올려 놓는다. 정렬 알고리즘 애니메이션 =&gt; [toptal](https://www.toptal.com/developers/sorting-algorithms)","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://jungjihyuk.github.io/categories/Algorithm/"}],"tags":[]},{"title":"Django","slug":"django","date":"2019-03-24T15:00:00.000Z","updated":"2020-02-24T15:40:57.522Z","comments":true,"path":"2019/03/25/django/","link":"","permalink":"http://jungjihyuk.github.io/2019/03/25/django/","excerpt":"Two scoops of Django 책 정리 및 구글링 정보","text":"Two scoops of DjangoDjango Structure 출처 바로가기 Django Project 시작전 환경 세팅 (최적화된 장고 환경을 꾸미자) python3 설치 (python 3.1.4v 이후 버전은 pip가 내장되어 있다) pip는 python 패키지를 가져오는 도구 pip upgrade =&gt; python -m pip install –upgrade pip python2를 사용하는 경우 easy_install을 이용하여 pip 설치 virtualenv 설치 virtualenv는 python package 의존성을 유지할 수 있게 독립된 python 환경을 제공하는 도구 pip install virtualenv virtualenvwrapper 설치(virtualenv 사용을 더 편하게 해주는 도구) pip install virtualenvwrapper-win windows virtualenv-wrapper install: tistory node.js 개발자의 python 도전기: blog mkvirtualenv 가상환경 이름 ex) mkvirtualenv myvenv 앞으로 생성할 가상환경을 위한 환경설정 setx WORKON_HOME 경로 ex) setx WORKON_HOME C:\\dev\\project 개인 프로젝트를 위한 가상환경 설치 mkvirtualenv myvenv ex) (myvenv) C:\\dev\\project\\myvenv 가상환경 나오기 deactivate 가상환경 들어가기 workon 가상환경 이름 ex) workon myvenv git bash에서 켜기: source Scripts/activate python packgage 확인 pip list Django 설치하기 (가상환경 안에서) pip install django~=버전 ex) pip install django~=2.0.0 root directory 생성 mkdir root_dir_name ex) mkdir mysite requirements.txt 파일 생성 pip freeze &gt; requirements.txt 프로젝트 생성 django-admin.py startproject 쿠키커터 설치 pip install cookiecutter cookiecutter https://github.com/pydanny/cookiecutter-django 쿠키커터 설치 방법 =&gt; Tistory 쿠키커터 설정 =&gt; settings Cookiecutter란? 유연한 확장성과 편의를 추구하기위해 만들어진 프로젝트 템플릿 ,어플리케이션 사이즈가 계속해서 커지면 곤란한 상황이 올수 있는데 이를 방지할 수 있다고 한다.Cookiecutter의 어떤점 때문인지는 확실하지 않기 때문에 더 찾아보자{: .notice}Django와 Cookiecutter 설명: blog Django Application Structure git bash tree command on windows cmd //c tree 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566$ tree└─── My_Awesome_Project # [repository_root] ├── .gitignore ├── .gitattributes ├── .pylintrc ├── .coveragerc ├── .editorconfig ├── README.rst ├── docs ├── manage.py ├── requirements │ ├── base.txt │ ├── local.txt │ └── production.txt ├── config # [configuration_root] │ ├── __init__.py │ ├── urls.py │ ├── wsgi.py │ └── settings │ ├── __init__.py │ ├── base.py │ ├── local.py │ ├── production.py │ └── test.py ├── docs │ ├── __init__.py │ ├── conf.py │ ├── index.rst │ ├── Makefile │ └── make.bat ├── locale │ └── README.rst ├── utility └── My_Awesome_Project_App # [django_project_root] ├── __init__.py ├── conftest.py ├── contrib │ ├── __init__.py │ ├── sites │ │ ├── __init__.py │ │ └── migrations ├── templates │ ├── account │ ├── pages │ ├── users │ ├── base.html │ ├── 404.html │ └── 500.html ├── static │ ├── css │ ├── fonts │ ├── images │ ├── js │ └── sass └── users ├── __init__.py ├── admin.py ├── forms.py ├── models.py ├── urls.py ├── views.py ├── apps.py ├── adapters.py ├── migrations └── tests ## Field manual of Coding style Refactoring =&gt; tistory Postgresql 설치 및 사용법user 생성 및 수정, 삭제: userpostgresql 비밀번호를 모를 때: stackoverflowpostgresql user 삭제: wiki postgresql 자동로그인: tistoryTablespace 개념: blog makemigrations vs migratemakemigrations: models.py에서 적용한 변경사항이나 추가된 혹은 삭제된 사항들을 감지하여 파일로 생성 migrate: 적용되지 않은 migratinos(설정값)들을 적용시키는 역할 makemigrations는 장고에서 제공하는 모델의 변경사항들을 감지하고 기록하는 역할을 하며 migrate는 그러한 기록된 파일들과 설정값들을 읽어서 그 변경사항을 db에 저장하는 역할을 한다 참고 모델 수정후 migrations을 해주지 않고 admin page에 접속하게 되면 오류가 난다 {: .notice} Django 개발 순서1234567891. Settings.py를 이용해 기본 세팅하기2. Models.py를 이용해 필요한 model 만들기3. 변경된 model migration, migrate하기4. Model 생성후 superuser 등록하기 &#x3D;&gt; 한번만5. Url.py를 이용하여 경로 설정하기6. Views.py를 이용하여 데이터 받고 처리하기7. Templates 만들기8. Form.py를 이용해 사용자 데이터 입력받아 저장하는 경우 만들기9. 서버 켜서 확인하기 Django Rest FrameworkDjango Rest Framework란?: &nbps; tistory Googling InfoDjango structure: blogDjango install: tistoryDjango Tutorial: DjangoprojectDjango with Machine Learning: codementorDjango with MongoDB: Djongo githubNoSQL DB의 종류: incodomDjango 공부내용 정리: wikiDocsPostgresql 연동: tistory1, &nbsp;tistory2Django 참고하기 좋은 글: hannalDjango admin 계정 패스워드 리셋하는 방법: blog 공부하다가 모르는 용어, 개념 정리 하드코딩 복잡하고 정리되지 않은 코드?? 개발 환경/스테이징 환경/테스트 환경/운영 환경 구체적인 차이와 실제 예시로 이해하기 쿠키커터가 템플릿 그 이상의 기능이 있는지 찾기 쿠키커터 vs 삼단 저장소 구조(root/project/conf) virtualenv, pipenv 차이 Django + Postgresql + MongoDB 구조 가능?? 관계형 DB와 문서형 DB 동시 연동 절대적 임포트, 명시적 상대, 암묵적 상대 비교, 이해하기 환경변수 정확하게 이해하기 앱 하나에 모델이 많을 때 일어나는 일, 부작용등을 알아보자 앱 분리하는 방법 터득 모델 상속","categories":[{"name":"Web","slug":"Web","permalink":"http://jungjihyuk.github.io/categories/Web/"},{"name":"Django","slug":"Web/Django","permalink":"http://jungjihyuk.github.io/categories/Web/Django/"}],"tags":[{"name":"정리","slug":"정리","permalink":"http://jungjihyuk.github.io/tags/%EC%A0%95%EB%A6%AC/"},{"name":"Django","slug":"Django","permalink":"http://jungjihyuk.github.io/tags/Django/"}]},{"title":"IT 용어 정리","slug":"IT-Terms","date":"2019-03-15T15:00:00.000Z","updated":"2020-02-24T15:16:25.541Z","comments":true,"path":"2019/03/16/IT-Terms/","link":"","permalink":"http://jungjihyuk.github.io/2019/03/16/IT-Terms/","excerpt":"정보처리기사 실기 및 알아두면 좋은 용어들","text":"정보처리기사 실기를 위한 용어 Data warehouse 정보에 입각한 의사 결정을 내릴 수 있도록 분석 가능한 정보의 중앙 저장소 DW vs DM Big data 의사결정에 필요한 아주 방대한 데이터들 그리고 데이터를 활용하는 기술 Data warehose vs Big data Data mining Data warehouse에 저장된 데이터 집합에서 사용자의 요구에 따라 유용하고 가능성 있는정보를 발견할 수 있도록 해주는 기술 Triger 입력, 갱신, 삭제 등의 이벤트가 발생할 때마다 자동적으로 수행되는 사용자 정의 프로시저 DSMS(Data Stream Management System) 무선 센서 네트워크나 인터넷 같은 통신사에서 발생하는 대량의 스트림 데이터를 처리하고 관리하는 시스템. DC(Dublin Core) ISO 15836으로 표준화된 메타데이터 요소 집합, 네트워크 환경에서 각종 전자 정보를 기술하는 메타데이터. MDR(Meta Data Registry) 메타 데이터의 등록과 인증을 통해 메타 데이터를 유지, 관리하며 메타 데이터의 명세를 공유하는 레지스트리. Database Tuning 데이터베이스 시스템을 최적화하는 방안, DB application, OS, DB 등의 조정을 통하여 DB System 성능 향상. EA(Enterprise Architecture) 정보화를 체계적으로 추진하기 위해 조직 및 업무 활동, 정보화 종합설계도EA ERP(Enterprise Resource Planning) 인사, 재무, 생산 등 기업의 전 부문을 하나의 통합 시스템으로 재구축함으로써 생산성 극대화 기법. EAI(Enterprise Application Integration) DW나 ERP등 기업에서 운영하는 서로 다른 어플리케이션을 통합하여 업무의 효율성을 높이려는 시도. DRM(Digital Rights Management or Digital Restrictions Managment) 출판자 또는 저작권자가 그들이 배포한 디지털 자료나 하드웨어의 사용을 제어하고 이를 의도한 용도로만 사용하도록 제한하는 모든 기술. OLAP(Online Analytic Processing) 의사결정 지원 시스템. DW로 부터 정보를 추출하여 온라인으로 다차원 분석을 하는 기술 OLAP OLTP(Online Transaction Processing) 주 컴퓨터와 통신 회선으로 접속되어 있는 복수의 사용자 단말에서 발생한 트랜잭션을 주 컴퓨터에서 처리하여 그 결과를 즉석에서 사용자 단말 측으로 되돌려 보내 주는 처리 형태. OLAP vs OLTP 시간복잡도(Big-O) 알고리즘이 수행되는 시간 공간복잡도 프로그램 실행후 종료시까지 필요로하는 자원공간의 양(메모리) as-is 현재 업무 프로세스 분석 to-be 미래 업무 프로세스 분석 AR(Augmented reality) 증강현실, 실제 존재하는 환경에 가상의 사물이나 정보를 합성하여 마치 원래의 환경에 존재하는 사물처럼 보이도록 하는 컴퓨터 그래픽 기법 ex) 포켓몬고 임계영역 공유자원에 접근하는 프로세스의 영역 상호배제 동시에 실행되는 프로세스들이 임계영역에 동시에 들어가지 않도록 하는 것 ex) 파일이 열려 있으므로 이 작업을 완료할 수 없습니다 bi-modal 혁신을 추진하는 특별팀을 만드는 동시에 기존 핵심 시스템도 잘 유지해야 한다 CRM(Customer Relationship management) 소비자들을 자신의 고객으로 만들고, 이를 장기간 유지하고자 하는 경영 방식 CUI(Conversational user interfaces) 인공지능 대화형 인터페이스 스마트 캠퍼스 인간-기기가 상호작용하여 시스템을 통해 대학의 구성원이 더 몰일할 수 있고 자동화된 경험을 만들어낸다 넛지기술 클라우드와 모바일, 소셜, 데이터 관련 기술의 모음, 개인화된 소통을 통해 서비스 제공 ex)aws 쇼핑몰 홈페이지, 쳇봇 BYOD(Bring your own device) 컴퓨터나 모바일 기기 속 자료를 프로젝터 같은 유선 기기 연결 없이 무선 네트워크를 사용해 스크린에 보여줄 수 있다 HIP(Hybrid integration platform) 기존의 IT 환경들을 통합하여 환경 구축 ex)software ag SLA(Service Level Agreement) 서비스를 제공함에 있어서 공급자와 사용자간에 서비스에 대하여 측정지표와 목표등에 대한 협약서 PaaS(Platform as a Service) 클라우드 컴퓨팅 서비스중 하나, 앱 개발에 필요한 인프라 대여 플랫폼 ex)aws, 공개 API, 구글의 앱 엔진 SaaS(Software as a Service) 기존의 ASP를 확장한 개념으로 소프트웨어 및 관련 데이터는 중앙에 호스팅되고 사용자는 웹 브라우저 등의 클라이언트를 통해 접속하는 형태의 소프트웨어 전달 모델 (주문형 소프트웨어) ex) CRMKorea IaaS(Infrastructure as a Service) 서버, 스토리지, 네트워크를 가상화 환경으로 만들어, 필요에 따라 인프라 자원을 사용할 수 있게 서비스를 제공한다 ex) aws’s EC2, microsoft azure ASP(Application Service Provider) 네트워크 인프라를 이용하여 다양한 정보화 솔루션을 사용할 수 있는 애플리케이션 임대 서비스, SaaS와 유사하지만 동적으로 컴퓨팅 자원을 할당하는 분산처리 등과 같은 기술 제공이 제한적이다는 면에서 차이가 있다 APaaS / DPaaS / IPaaS PaaS에서 파생된 것들 BCI(Brain-Computer Interface) 컴퓨터 방식을 이용해 정보를 추출한 후 뇌에 다시 자극을 적용하는 것 및 손상된 청각, 시각 및 운동을 복원하는 것을 목표로 하는 신경기능 대체 분야에 초점을 맞추고 있다 Ad-hoc 무선 통신 및 네트워킹 능력을 갖춘 두 개 이상의 장비로 구성된 네트워크, 별도의 AP(Access point) or Infrastructure 없이 모바일 디바이스만으로 구성가능하다 WPAN(Wireless Personal Area Network) 무선 개인지역망, 블루투스 등의 개인 디바이스 WLAN(Wireless Local Area Network) 무선 근거리 통신망, 802.11 프로토콜 통신을 하며 와이파이가 이에 해당한다 WMAN(Wireless Metropolitan Area Network) 무선 도시지역망, 와이브로가 이에 해당한다, 그 지역 내부에서 어디든지 인터넷이 잘 되지만 다소 느리다는 단점이 있다 WWAN(Wireless Wide Area Network) 무선 광대역 통신망, 휴대폰이 이에 해당한다, 일부 지역을 제외하고 어디서든 통신이 가능하다는점, 2G~4G 스마트 카(Smart car) or 커넥티드 카(COnnected car) 자동차와 IT 기술을 융합하여 인터넷 접속이 가능항 자동차 크라우드 소싱(Crowd Sourcing) 인터넷을 통해 일반 대중이 기업 내부 인력을 대체하는 것을 의미 SAN(Storage Area Network) ‘광저장장치영역 네트워크’라고 불린다, 특수 목적용 고속 네트워크로서 대규모 네트워크 사용자들을 위하여 이기종 간의 데이터 저장장치를 관련 데이터 서버와 함께 연결해 별도의 네트워크를 구성해 관리한다 지그비(ZigBee) 버튼 하나의 동작으로 집안 어느 곳에서나 전등 제어 및 홈 보안 시스템을 제어 관리할 수 있고 인터넷을 통한 전화 접속으로 가정 자동화를 더욱 편리하게 달성하려는 것에서부터 출발한 기술, Ad-hoc 방식 네트워크, 낮은 수준의 전송 속도만 필요로 하면서 긴 베터리 수명과 보안성을 요구하는 분야에서 사용 멀웨어(Malware) 악성 소프트웨어, 사용자가 멀웨어를 설치하게되면 컴퓨터에 대한 액세스 권한을 얻도록 설계되어 컴퓨터에서 액세스한 내용을 추적할 수 있으며 사용자가 인식하지 못 할 수도 있는 피해를 일으킬 수도 있다(키로거, 바이러스, 웜, 스파이웨어) 랜섬웨어(Ransomware) 컴퓨터 시스템을 감염시켜 접근을 제한하고 일종의 몸값을 요구하는 악성 소프트웨어의 한 종류이다 MC-Finder 악성코드 은닉 사이트 탐지 프로그램 MOTP(Moblie One Time Password) 모바일 일회용 비밀번호 Network Neutrality 통신망 제공사업자는 모든 콘텐츠를 동등하고 차별 없이 다뤄야 한다는 원칙 ICP(Internet Contents Provider) 인터넷 콘텐츠 서비스 업체 ex) 네이버, 구글, 페이스북 ISP(Internet Service Provider) 인터넷 서비스 업체 ex) SKT, KT, LG VPN(Virtual Private Network) 가상 사설망, 사용자의 인터넷 트래픽을 암호화하여 망 제공자로부터 안전하게 인터넷을 사용할 수 있도록 해준다 Smishing(SMS phishing) 문자메시지를 이용한 피싱, 신뢰할 수 있는 사람 또는 기업이 보낸 것처럼 가장하여 개인비밀정보를 요구하거나 휴대폰 소액 결제를 유도한다 Sniffing 패킷 가로채기 공격, 네트워크 상에 떠돌아다니는 패킷이나 데이터 등을 훔쳐보는 것, 암호화 되지 않은 패킷들을 수집하여 순서대로 재조합 후 중요한 정보를 유출하는 수동적인 형태의 공격 Snooping 네트워크 상의 정보를 염탐하여 불법적으로 얻는 것 Spoofing 네트워크 트래픽 흐름을 임의로 변경하고 시스템 권한 탈취 등의 공격, 그 대상은 MAC, IP, Port 주소가 될 수 있다 ICMP Sweep 해당 네트워크를 탐색하면서 살아있는 호스트, 포트를 찾는다, 목표 네트워크나 시스템에 ICMP Echo_Request 패킷을 순차적으로 전송한 후, 응답 패킷을 기반으로 해당 시스템의 동작 여부와 운영체제 종류 등을 파악한다 Scanning 시스템의 상태, 사용하는 서비스 등을 찾아 취약점을 찾는 사전 주비 단계 ICMP(Internet Control Message Protocol) 호스트 서버와 인터넷 게이트 웨이 사이에서 메시지를 제어 하고 에러를 알려주는 프로토콜 트로이 목마 정상적인 프로그램으로 위장한 악성코드, 트로이 목마의 99.99%는 불법 파일이나 프로그램 다운시 전파된다, 트로이 목마는 개인정보 유출, 운영체제 파괴, 속도 느려짐, 시스템 파일 삭제, 부팅 오류, 컴퓨터 하드웨어 자체를 먹통으로 만들 정도로 손상시키기도 한다, 포멧을 해도 복구가 불가능할 수도 있다 Tvishing 스마트 TV의 약점을 이용하여 몰래 악성코드를 심어 TV 기능을 악용하는 피싱 방법 Pharming 웹 브라우저에서 정확한 웹 페이지 주소를 입력해도 가짜 웹 페이지에 접속하게 하여 개인 정보를 훔치거나 금전적 피해를 입히게 하는 피싱방법 USIM(Universal Subscriber Identity Module) 휴대전화에 끼워서 쓰는 일종의 스마크카드, 3G, 4G, WiBro, 데이터 쉐어링 기기를 사용하고 있다면 기기에 하나 씩 들어 있다, 보통 개인 정보를 담고 있어 보안에 신경써야 한다 ISP(Information Strategy Planning) 정보 시스템 구축의 출발점인 계획 단계 SCM(Supply Chain Management) 공급망 관리, 고객이 사용하고자 하는 시점에 원하는 제품을, 원하는 수량만큼 공급하는 것을 목표로함 Balanced Scorecard(균형 성과표) 얼마나 돈을 벌었냐보다, 여러가지 기준을 추가해서 업무의 성과를 판단함 BPR(Business Process Reengineering) 기업 경영 내용이나, 경영 과정을 분석하여 경영 목표 달성에 가장 적합하도록 재설계하고, 그 설계에 따라 기업 형태, 사업 내용, 조직을 재구성 하는 것 Strategic Information System(전략적 정보 시스템) 이전의 정보 시스템이 업무의 합리화나 효율성에 초점을 두었던 것에 반하여, 기업이 경쟁에서 승리하여 살아남기 위한 필수적인 시스템 Point of Sale(판매 시점) 물품 거래가 완료되는 장소, 판매와 관련된 데이터를 일괄적으로 관리하고, 고객 정보를 수집하여 부가 가치를 향사시키는 시스템 Decision Support System(결정 지원 시스템) 회사의 경영층의 의사결정자의 계산 부담을 줄여주고, 정보를 도식화 하여 분석모형과 데이터를 제공함으로써 의사결정자의 의사 결정을 보다 효율적으로 도와주는 응용프로그램 Executive Information System(경영 정보 시스템) DSS의 일종으로 최고 경영진에게 전략적인 의사 결정에 필요한 정보를 제공하는 체계를 일컫는 사업 용어 Product Data Management(제품 데이터 관리) 소프트웨어나 다른 툴을 이용하여 특정 제품과 관련된 데이터를 추적하고 관리하는 것을 지칭한다 Chief Knowledge Officer(지식 총괄 책임자) 지식의 보존을 통해 기업 가치가 최대로 되도록 하는 책임자를 일컫는다 Six Sigma 기업 내에서 전략적으로 완벽에 가까운 제품이나 서비스를 개발하고 제공하려는 목적으로 정립된 품질 관리 기법 5-Forces 기존 경쟁자 간의 경쟁 정도, 공급자들의 교섭력, 구매자들의 교섭력, 잠재적 진입자들의 위협, 대체제의 위협 이 다섯 가지 요소들의 강약에 의해 산업 내 잠재적 이윤의 수준이 결정되며 산업 분석을 이용하면 전반적 산업의 경쟁강도 파악이 가능하며 특히 산업 내 어느 부분에서 경쟁이 일어나는지 파악 할 수 있다 7S 조직 개발 측면에서 꼭 필요하다고 생각한 일곱가지 요인 Strategy, Structure, Systems, Staff, Shared Value, Skills, Style Community of Practice 열정과 지식을 공유하는 학습 공동체 Work Breakdown Structure(작업 분해도) 프로젝트의 범위와 최종산출물을 세부 요소로 분할한 계층적 구조 Corporate Performance Management(기업 성과 관리) 경영계획-성과분석- 예측- 전략분석- 시뮬레이션 / 예측 경영을 통한 최적의 의사 결정을 내릴 수 있게 해주는 시스템 Groupware 집단으로 서의 작업을 지원하기 위해 만들어진 소프트웨어 Business Process Management(생애 주기) 프로세스 설계-시뮬레이션-구현-실행-모니터링-최적화 @anywhere(앳애니웨어) 뉴욕타임즈 같은 언론사나 야후 같은 유명 사이트와 제휴를 해서 트위터 사이트로 이동하지 않고도 해당 사이트상에서 최근의 트위터 글을 바로 확인할 수 있는 새로운 플랫폼 5G 네트워크 슬라이싱 5G의 핵심 기술인 네트워크 슬라이싱, 하나의 물리적 ‘코어 네트워크’를 독립된 다수 가상 네트워크로 분리한 뒤 고객 맞춤형 서비스를 제공한다 아이엠티 2020(International Mobile Telecommunications-2020,IMT-2020) 5G 이동통신, 이용자에게 초당 최고 20Gbps의 데이터 전송 속도를 제공할 것을 규정한다, 최고 전송속도 20Gbps, 사용자 체감 전송속도 100Mbps, 전송 지연 시간 1ms 등… EMBB(enhanced Mobile BroadBand) 초광대역 이동 통신 URLLC(Ultra-Reliable and Low Latency Communications) 초고신뢰 저지연 통신 mMTC(massive Machine Type Communications) 대규모 사물통신 4C 분석 Customer, Competitor, Company, Channel (고객, 경쟁사, 자사, 유통) ERM(Enterprise Risk Management) 기업이 직면하고 있는 주요 위험들을 식별하고 관리하기 위한 위험 관리 방식 PLM(Product Lifecycle Management) 기업이 제품의 원가를 낮추고 부가가치를 높일 수 있도록 기획부터 설계, 생산, 서비스, 폐기에 이르는 수명주기를 관리하는 것 MDM(Master Data Management) 기업의 내, 외부에 산재해 있는 마스터 데이터의 단일화를 통해 활용도를 높이고 오류를 줄이기 위한 모든 활동 VRM(Vendor Relationship Management) 개인이 기업에게 제공할 개인정보, 선호도, 패턴 등을 관리하는 기술로, 기업이 고객의 정보를 분석 및 통합하여 관리하는 CRM에 반대되는 개념, 개인이 기업에 제공할 정보와 선호도를 관리, 보안이 중요시됨. VRM vs CRM Escrow 서비스 전자상거래 시 판매자와 구매자의 거래가 문제없이 이루어질 수 있도록 제 3자가 도와주는 매매 보호 서비스 OPE(Order Preserving Encryption) 암호화된 수치 데이터들이 원본 수치 데이터와 동일한 순서로 정렬될 수 있도록 해주는 암호화 기술 QKD(Quantum Key Distribution) 양자 통신을 위해 비밀키를 분배하고 관리하는 기술 마이핀 법적 근거 없는 주민번호 수집이 금지되면서 도입된 13자리의 무작위 번호로 온라인상에서 사용되는 아이핀과 달리 오프라인 상에서 주민번호를 대신한다, 유출시 폐기 가능하며 5회까지 변경이 가능하고 유효기간은 3년이다 CAPTCHA(Completely Automated Public Turing test to tell Computers and Humans Apart) 자동 계정 생성 방지 기술은 웹 페이지에서 악의적으로 회원가입을 하거나 스팸 메시지를 보내기 위해 사용되는 프로그램인 봇을 차단하기 위해 만들어졌다. 독싱(dropping docs) ‘문서를 떨어뜨리다’에서 파생된 용어로, 특정 개인이나 조직을 해킹하여 빼낸 정보를 온라인에 공개하는 행위 독스웨어 독스와 랜섬웨어의 합성어 스파이웨어 적절한 사용자 동의 없이 사용자 정보를 수집하는 프로그램 웜 네트워크를 통해 연속적으로 자신을 복제하여 시스템의 부하를 높임으로써 결국 시스템을 다운시키는 바이러스 크래킹 어떤 목적을 가지고 타인의 시스템에 불법으로 침입하여 정보를 파괴하거나 정보의 내용을 자신의 이익에 맞게 변경하는 행위 혹스 악성코드인척하는 소프트웨어, 실제로 악성코드로 행동하지 않음 버퍼 오버플로 공격 버퍼의 크기보다 많은 데이터를 입력하여 프로그램이 비정상적으로 동작하도록 만드는 것 NR(New Radio) 5세대 이동통신의 실현을 위한 무선 접속 기술 Force Touch 애플에서 개발한 트랙패드와 터치스크린에 적용되는 기술로, 패털에 가해지는 힘의 강도를 감지한다 GNSS(Global Navigation Satellite System) 인공위성을 이용하여 위치를 파악하는 항법 시스템. ex) GPS, GLONASS, 갈릴레오, Compass SBAS(Satellite-Based Augmentation System) GNSS의 위치 오차를 보정한 정보를 위성을 통해 사용자에게 전달하는 광역의 위성 항법 보정 시스템. SNG(Satellite News Gathering) 현장에서 촬영한 영상을 위성을 통해 방송사로 전송하는 방식 MNG(Mobile News Gathering) 야외에서 촬영한 영상을 3G, LTE, WiBro, Wi-Fi 등 다양한 무선망 접속 장비를 이용해 전송하는 방식 ENG(Electronic News Gathering) 카메라와 녹화부가 탑재된 일체형 카메라 시스템을 말한다. Brute force attack(무작위 대입 공격) 특정한 암호를 풀기 위해 가능한 모든 값을 대입하는 것을 의미한다 DES(Data Encryption Standard) 56비트를 사용하는 키 Backdoor os나 프로그램 등을 만들 때 정상적인 인증 과정을 거치지 않고 접근할 수 있도록 만든 일종의 뒷구멍 같은 개념,네트워크에 허가받지 않고도 들어갈 수 있을 만큼 허술한 부분, 의도적으로 만들어진 보안구멍, 프로그래머의 실수로 만들어진 취약점(익스플로잇) RPO(Recovery Point Objective) 목표 복구 시점, 허용할 수 있는 데이터의 손실양과 관계가 있다 RTO(Recovery Time Objective) 목표 복구 시간, 최대 허용 다운타임 NAS(Network Attached Storage) 네트워크 결합 스토리지, LAN으로 연결하는 외장 하드디스크 ex) Github DAS(Direct Attached Storage) 직접 연결 저장장치, ex) 하드디스크 HA(High Availability) 고가용성, 서버와 네트워크, 프로그램 등의 정보 시스템이 상당히 오랜 기간 동안 지속적으로 정상 운영이 가능한 성질, 가용성이 높다는 뜻은 오류가 거의 없고 고장이 잘 안나는 상태를 의미한다 ISO 20000 IT 서비스를 제공하는 기업들이 고객에게 IT 서비스를 제공하고 관리하기 위한 통합된 관리체계를 적용하고 고객에게 적절한 통제, 개선된 효과성 및 개선의 기회를 제공하게 하는 규격, IT 서비스의 수준을 객관적으로 평가하고 서비스 중심의 프로세스, 견고하고 통합화된 프로세스 프레임 워크를 제공하기 위해 만들어졌다 디지털 프로슈머 생산자와 소비자의 합성어, 생산자인 동시에 소비자이고 소비자이면서 생산을 하는 사람들, ex) Github블로그를 운영하면서 광고로 수익을 얻는 사람 ITSM(IT Service Management) 고객에게 제공하는 정보기술 서비스들을 계획, 설계, 전달, 운영하기 위해 단체에 의해 수행되는 활동 전반을 가리킨다 ITIL(IT Infrastructure Library) IT 서비스 관리에 대한 프레임워크 구현을 돕기 위한 문서들의 집합 SYN(Synchronization) 연결요청플래그, 신호를 전달하는 플래그 SDN(Software Defined network) 소프트웨어 정의 네트워크, 소프트웨어 프로그래밍을 통해 네트워크 경로 설정과 제어 및 복잡한 운용관리를 편하게 처리할 수 있는 차세대 네트워킹 기술 설명 QoS(Quality of Service) 다른 응용 프로그램, 사용자, 데이터 흐름 등에 우선 순위를 정하여, 데이터 전송에 특정 수준의 성능을 보장하기 위한 능력을 말한다, 통신 서비스 품질, KMS(Knowledge Management System) 지식 관리 시스템, 조직 내의 지식을 관리하는 분산 하이퍼미디어 시스템, 분산되어 있는 다양한 데이터를 효과적으로 저장, 관리, 활용하여 관리자의 의사결정을 지원하는 정보시스템, OLAP, 데이터마이닝 기술을 이용한다 SOA(Service Oriented Architecture) 서비스 지향 아키텍쳐, 업무상의 일처리에 해당하는 소프트웨어 기능을 네트워크 상에 연동하여 시스템 전체를 구축해 나가는 방법론 EAI &amp; SOA Data Mart DW 환경에서 정의된 접근계층으로, DW에서 데이터를 꺼내 사용자에게 제공하는 역할을 한다, 특정 사용자가 관심을 갖는 데이터들을 담은 비교적 작은 규모의 DW Ontology 사람이 인식하고 있는 사물을 기술한 것, 컴퓨터는 온톨로지로 표현된 개념을 이해하고 지식처리를 할 수 있다, 일종의 규칙이라고 생각하면 된다, 컴퓨터는 온톨로지를 토대로 판단을 할 수가 있다. Semantic Web 컴퓨터가 이해하는 웹, 정보와 자원 사이의 관계-의미 정보를 기계가 처리할 수 있는 온톨로지 형태로 표현하고 이를 자동화된 기계가 처리하도록 하는 프레임워크이자 기술 시맨틱웹과 온톨로지 GAN(Generative Adversarial Network) 생성적 적대 신경망, 비지도 학습에 사용되는 인공지능 알고리즘, 제로섬 게임 틀 안에서 서로 경쟁하는 두 개의 신경 네트워크 시스템에 의해 구현된다(제로 섬 게임: 게임이나 경제이론에서 여러 사람이 서로 영향을 받는 상황에서 모든 이득의 총합이 항상 제로 또는 그 상태를 말한다) Deepfake 인공지능 기술을 활용해 기존에 있던 인물의 얼굴이나, 특정한 부위를 영화의 CG 처럼 합성한 영상편집물 DeepMind 영국의 AI 프로그램 개발 회사, 구글이 인수하여 구글 딥마인드가 되었다, 심층 인공지능 기술인 ‘심층 큐 네트워크’를 독자적으로 개발하였다. 이 기술은 Deep Neural Network와 Q-Learning을 조합한 기술이다. 규칙을 알지 못하는 상태에서 점수와 픽셀 디스플레이 정보를 활용하여 최고점을 만들기 위해 이전 게임 세션으로부터 학습하는 능력만을 갖추었다. 알파고를 만든 회사이기도 하다 TTA 정보통신용어 =&gt; 신기술 용어2018년 1차 정처기 실기 =&gt; blog2018년 2차 정처기 실기 =&gt; blog2018년 3차 정처기 실기 =&gt; blog이동통신 =&gt; 1~5G정처기 실기 기출 정리 블로그 =&gt; blog","categories":[{"name":"IT Terms","slug":"IT-Terms","permalink":"http://jungjihyuk.github.io/categories/IT-Terms/"}],"tags":[{"name":"IT","slug":"IT","permalink":"http://jungjihyuk.github.io/tags/IT/"},{"name":"용어","slug":"용어","permalink":"http://jungjihyuk.github.io/tags/%EC%9A%A9%EC%96%B4/"},{"name":"정리","slug":"정리","permalink":"http://jungjihyuk.github.io/tags/%EC%A0%95%EB%A6%AC/"}]},{"title":"Git-Flow","slug":"gitflow","date":"2019-03-13T15:00:00.000Z","updated":"2020-02-24T15:15:26.912Z","comments":true,"path":"2019/03/14/gitflow/","link":"","permalink":"http://jungjihyuk.github.io/2019/03/14/gitflow/","excerpt":"Git을 이용한 협업 구조","text":"Git-FlowGit Repository 구성Repository는 Upstream Remote Repository, Origin Remote Repository, Local Repository 이렇게 세가지로구성됩니다. Upstream은개발자들이 공유하는 저장소로 최신 소스코드가 저장되어 있는 원격 저장소입니다.Origin은 Upstream을 Fork한 원격 개인 저장소 입니다.Local은 내 컴퓨터에 저장되어 있는 개인 저장소입니다. 위 그림을 보면 Local에서 각자 맡은 일을 하고 작업 브랜치를 Origin으로 push합니다. 그리고 다시 Origin에서Upstream으로 merge하는 Pull Request를 생성합니다. Pull Request가 발생하면 팀원과 코드리뷰를 거친후 merge합니다. 그리고 다시 작업을 시작하기 전 Upstream을 pull하여 작업을 하면 됩니다. 작업할 때 지켜야할 약속 작업을 시작하기전 꼭 Upstream에서 pull을 한다. reset명령어는 Local에서만 사용한다. 약속한 commit 규칙을 따른다 서로 공유하는 브랜치의 커밋 그래프는 함부로 변경하지 않는다. 자신의 Pull Request는 스스로 merge 한다. Git-Flow 개발 흐름Git-Flow를 사용했을 때 작업을 어떻게 하는지 살펴보기 전에 먼저 5가지 종류의 브랜치를 소개하겠습니다.항상 유지되는 메인 브랜치들(master, develop)과 일정 기간동안만 유지되는 보조 브랜치들(feature, release, hotfix)이 있습니다. master: 제품으로 출시될 수 있는 브랜치 develop: 다음 출시 버전을 개발하는 브랜치 feature: 기능을 개발하는 브랜치 release: 이번 출시 버전을 준비하는 브랜치 hotfix: 출시 버전에서 발생한 버그를 수정하는 브랜치 우아한 형제들’s blog (위 글 출처)출처 바로가기 생활코딩 유튜브 강의출처 바로가기 Git을 이용한 다양한 협업 워크플로우출처 바로가기 SSH-Key 생성후 Gitlab에 등록하기출처","categories":[{"name":"Git","slug":"Git","permalink":"http://jungjihyuk.github.io/categories/Git/"}],"tags":[{"name":"협업","slug":"협업","permalink":"http://jungjihyuk.github.io/tags/%ED%98%91%EC%97%85/"},{"name":"Git","slug":"Git","permalink":"http://jungjihyuk.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"http://jungjihyuk.github.io/tags/Github/"},{"name":"Gitlab","slug":"Gitlab","permalink":"http://jungjihyuk.github.io/tags/Gitlab/"},{"name":"Git-Flow","slug":"Git-Flow","permalink":"http://jungjihyuk.github.io/tags/Git-Flow/"}]},{"title":"git 명령어 정리","slug":"git","date":"2019-03-11T15:00:00.000Z","updated":"2020-02-24T15:15:17.177Z","comments":true,"path":"2019/03/12/git/","link":"","permalink":"http://jungjihyuk.github.io/2019/03/12/git/","excerpt":"learngitbranching.js.org 사이트 정리","text":"Git을 이용한 프로젝트 생성12345678910111213141516171819(1) 로컬에서 시작할 때1. 프로젝트 폴더로 이동2. git init &#x3D;&gt; 앞으로 이 폴더에 있는 모든 파일들을 git 프로그램으로 추적 하겠다, 버전 관리하겠다.3. 작업하기 (파일 생성, 수정, 삭제 등..) &#x3D;&gt; 코딩4. git add &#x3D;&gt; 작업 파일이 추가되었음 알리기, source tree 같은 경우 스테이지 올리기.5. git commit &#x3D;&gt; add되어 있는 파일들의 버전생성, 작업 단위, 커밋은 자주 해주는 것이 좋다. (커밋 규칙을 만들어둘 것)6. git config --global user.name &quot; &quot; &#x3D;&gt; 버전관리시 사용할 이름.7. git config --global user.email &quot; &quot; &#x3D;&gt; 이메일# git config 명령어는 한번만 수행한다.8. git remote add origin https:&#x2F;&#x2F;github.com&#x2F;Jungjihyuk&#x2F;JH_Life.git &#x3D;&gt; 원격저장소와 로컬저장소 연결(origin 뒤 주소는 본인 주소로)9. git push -u origin master(git push --set-upstream origin master) &#x3D;&gt; 로컬저장소의 변경내용들(커밋) 원격저장소에 업데이트 하기.(2) 원격저장소에서 clone하고 시작할 때1. git clone https:&#x2F;&#x2F;github.com&#x2F;Jungjihyuk&#x2F;JH_Life.git &#x3D;&gt; clone 뒤 주소는 클론할 주소입력2. 작업하기3. git add4. git commit5. git config --global user.name &quot; &quot;6. git config --global user.email &quot; &quot;7. git push -u origin master 기타 Git 사용시 유용한 명령어1234567891011121314151617181920211. vim 파일명 &#x3D;&gt; vim 프로그램으로 파일 열기 및 생성2. rm -r .git &#x3D;&gt; git파일 삭제3. git remote remove origin &#x3D;&gt; 원격저장소 해제4. cat 파일명 &#x3D;&gt; 파일내용 보기5. cp file1 file2 &#x3D;&gt; file1 파일을 file2 이름의 파일로 복사6. git log -p &#x3D;&gt; 이전상태 상세내용 확인7. git log --reverse &#x3D;&gt; 맨처음 커밋부터 보기8. git log --decorate --graph &#x3D;&gt; 커밋 내용을 좀 더 시각적으로 보기9. git log --decorate --all --online &#x3D;&gt; 모든 브랜치에 대한 로그를 한줄로 자세히 보여주기10. git log --branches --graph --decorate --oneline &#x3D;&gt; 브랜치 정보 확인11. ctrl + insert &#x3D;&gt; commit 고유번호 복사할때12. shift + insert &#x3D;&gt; 붙여넣기 할때13. git diff 고유번호1..고유번호2 &#x3D;&gt; 고유번호1,2는 commit고유번호&#x2F; 1과 2 차이점 보여주기14. git diff &#x3D;&gt; 전에 작업한 것과 지금 작업한 것의 차이 보여주기15. git commit --amend &#x3D;&gt; 커밋 내용을 정정한다.16. git config --unset --global user.name &#x3D;&gt; 사용자 이름 삭제17. git config --unset --global user.email &#x3D;&gt; 사용자 이메일 삭제18. git config --list &#x3D;&gt; 사용자 리스트 확인19. git status &#x3D;&gt; 현재 상태 확인20. git remove -v &#x3D;&gt; 원격저장소 연결url 확인21. git tag -a xxx -m &quot; &quot; &#x3D;&gt; 특정 커밋 지점까지 무슨 버전인지 태그를 달아준다. (xxx는 버전 숫자를 &quot; &quot;사이에는 버전 정보) Git 명령어123456781. commit2. branch3. checkout4. merge5. reset6. revert7. cherry-pick8. rebase Commit커밋은 git 저장소에 여러분의 디렉토리에 있는 모든 파일에 대한 스냅샷을 기록하는 것입니다.각 커밋은 저장소의 이전 버전과 다음 버전의 변경내역을 저장합니다.그래서 대부분의 커밋이 그 커밋 위의 부모 커밋을 가리킵니다.쉽게 말해 어떠한 작업을 마치고 변경된 파일 내용을 작업 단위별로 관리하기 위해 기록하는 행위 입니다. 커밋하기 (1) git commit -m “index.html 수정” [d27b] commit d27b8bb4d1f1949594592agbaskdjwkldsf Author: JH &#x77;&#108;&#103;&#x75;&#x72;&#x32;&#x37;&#56;&#x40;&#x67;&#x6d;&#97;&#105;&#108;&#46;&#x63;&#111;&#109; Date: Sun Mar 10 11:32:17 2019 +0900 index.html 수정 (2) git commit -m “main.html 추가” [d482] commit d4828s8c89v9b999v0990cv9d9b900ds09d Author: JH &#x77;&#108;&#103;&#117;&#x72;&#50;&#x37;&#56;&#64;&#x67;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#x6d; Date: Sun Mar 10 11:33:34 2019 +09000 main.html 추가 d482 커밋의 부모 커밋은 d27b가 된다. Branch브랜치는 특정 커밋에 대한 참조에 지나지 않는다.브랜치를 많이 만들어도 메모리나 디스크 공간에 부담이 되지 않기 때문에,여러분의 작업을 커다란 브랜치로 만들기 보다, 작은 단위로 잘게 나누는 것이 좋습니다.단순히 브랜치를 ‘하나의 커밋과 그 부모 커밋들을 포함하는 작업 내역’이라고 생각하면 됩니다. 브랜치 생성 및 삭제 git branch bugFix (현재 HEAD는 master) =&gt; 생성 git checkout -b bugFix =&gt; 생성과 동시에 HEAD옮기기 git branch –delete bugFix =&gt; 삭제 git branch -D bugFix =&gt; 브랜치에 commit이 남아 있을때 강제 삭제 git push origin :bugFix =&gt; 원격저장소의 브랜치 삭제 bugFix 브랜치 CheckoutHEAD 이동 HEAD는 현재 작업중인 커밋을 가리킨다.일반적으로 HEAD는 브랜치의 이름을 가리키고 있지만 특정 커밋을 가르키도록 이동시킬 수 있다. git checkout 브랜치명 Merge두 개의 브랜치를 합치는 작업을 merge라고 한다. bugFix 브랜치를 master 브랜치에 merge (현재 HEAD위치 master) git merge bugFix master 브랜치에 bugFix를 merge (현재 HEAD위치 bugFix) git merge master bugFix 브랜치를 master 브랜치에 merge Merge 그림 Rebase브랜치 접목의 또다른 방법.커밋들을 모아서 복사한 뒤, 다른 곳에 떨궈 놓는 것.커밋들의 흐름을 보기 좋게 한 줄로 만들 수 있다는 장점이 있다.저장소의 커밋 로그와 이력이 한결 깨끗해진다. bugFix 브랜치를 master 브랜치에 merge (현재 HEAD 위치 bugFix) git rebase master master 브랜치를 bugFix 브랜치에 merge (현재 HEAD 위치 master) git rebase bugFix Merge vs Rebase Merge Rebase 상대 참조123456789101112(1) 커밋의 해시를 사용하는 방법. ex) fed2dkakdfladsfjkl34k234lkjlksfkl23k 라는 커밋해시가 있다고 했을 때 fed2만 입력해도 인식한다.(2) ^ 한번에 한 커밋 위로 움직인다. ex) git checkout master^(3) ~num 한번에 여러 커밋 위로 올라가는 git checkout HEAD~2 git branch -f master HEAD~3 &#x3D;&gt; 브랜치 강제 옮기기 (HEAD에서 세번 뒤로 옮겨짐) Reset브랜치로 하여금 예전의 커밋을 가리키도록 이동시키는 방식으로 변경 내용을 되돌립니다.애초에 커밋을 하지 않은 것처럼 예전 커밋으로 브랜치를 옮기는 것.각자의 컴퓨터에서 작업하는 로컬 브랜치의 경우 리셋을 잘 쓸 수 있다.하지만 다른 사람이 작업하는 리모트 브랜치에는 사용할 수 없다. Revert변경분을 되돌리고, 이 되돌린 내용을 다른 사람들과 공유하기 위해서는 revert를 사용한다. Cherry-pick합치고 싶은 커밋만 합친다.합치고 싶은 커밋의 해시값을 알때 유용하다. git cherry-pick …. Interactive rebase합치고 싶은 커밋의 해시값을 모를때 유용하다. git rebase -i HEAD~4 Pull vs Fetch Git 사용시 여러가지 에러 git add 에러 123$ git add .warning: LF will be replaced by CRLF in [xxx.txt or xxx.xml 등...]The file will have its original line endings in your working directory. CR(Carriage-Return)과 LF(Line Feed)=&gt; 윈도우는 CRLF CR=&gt; 현재라인에서 커서의 위치를 맨 앞으로 옮기는 동작 LF =&gt; 커서의 위치는 그대로 두고 종이를 한 라인 위로 올리는 동작=&gt; Mac과 Linux는 LF문자만 사용.=&gt; Git은 커밋할 때 자동으로 CRLF를 LF로 변환해주고 반대로 CheckOut할 때 LF를 CRLF로 변환해 주는 기능이 있다. git config –global core.autocrlf (true/input/false) 위 명령어로 에러 해결! 자세한 내용은 밑 url 참고 출처 Git 이해하는데 도움되는 : Git","categories":[{"name":"Git","slug":"Git","permalink":"http://jungjihyuk.github.io/categories/Git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://jungjihyuk.github.io/tags/git/"},{"name":"명령어","slug":"명령어","permalink":"http://jungjihyuk.github.io/tags/%EB%AA%85%EB%A0%B9%EC%96%B4/"}]},{"title":"python 문법 정리(자주 까먹는 것들)","slug":"python","date":"2019-01-22T15:00:00.000Z","updated":"2020-02-24T15:43:06.755Z","comments":true,"path":"2019/01/23/python/","link":"","permalink":"http://jungjihyuk.github.io/2019/01/23/python/","excerpt":"'Do it! 점프 투 파이썬' 책","text":"Python Do it! 점프 투 파이썬 책에 나온 까먹기 쉬운 내용들로 구성했습니다. 목차 자료형 클래스(변수와 객체) 제어문 자료형123456- 숫자- 문자열- 리스트- 튜플- 딕셔너리- 집합 클래스(변수와 객체 그리고 함수)1234567변수: 객체를 저장한 공간.객체: 메모리에 저장된 자료.클래스(class): Field(상태) + Method(행동) 객체를 생성하기 위한 설계도.인스턴스(instance): 클래스에 의해 생성된 객체함수: 프로그램의 동작 요소, 입출력 설계의 핵심. 보통 함수는 input -&gt; func -&gt; output 구조이다.(input, output은 있을수도 없을수도 있다.) 객체와 인스턴스 구분 12345678910# int(정수형 클래스)a&#x3D;3b&#x3D;5# a와 b는 서로 다른 객체, 같은 클래스의 인스턴스.a is b &#x3D;&gt; False (a와 b가 같은 인스턴스 입니까?&#x2F;No)isinstance(a,int) &#x3D;&gt; True (a가 int 클래스의 인스턴스 입니까?&#x2F;Yes)isinstance(b,int) &#x3D;&gt; True (b가 int 클래스의 인스턴스 입니까?&#x2F;Yes)※ a&#x3D;&#x3D;b a와 b가 같은 값을 가졌습니까? &#x2F; No 프로그래밍 언어에 클래스는 왜 있는걸까?c 언어 같은 경우 절차지향적 프로그래밍 언어로 클래스를 사용하지 않고도프로그래밍이 가능하다. (but 구조체와 함수 포인터를 활용하여 객체지향적 프로그래밍 가능)그렇다면 왜 굳이 객체지향적 프로그래밍을 위한 클래스가 필요한 것인가? 우선 절차지향과 객체 지향 프로그래밍부터 알아보자.절차지향123컴퓨터의 작업 처리 방식과 유사하게 순차적인 프로그래밍을 말합니다.프로그램 전체가 유기적으로 연결되어 있어 객체지향 언어에 비해처리 속도가 빠르다는 장점이 있지만 여러가지 불편한 점들이 있습니다. 객체지향12345실제 세계와 유사한 3차원적 개념을 표현해내기 위해 만들어진프로그래밍 방법으로 마치 로봇의 부품들을 따로 개발하여하나의 로봇을 만드는 것과 같은 원리의 프로그래밍 방식입니다.객체 지향 프로그래밍으로 인해 코드의 재사용성 및 이식성이 높아졌고유지 보수에 용이하며 데이터의 보호, 코드의 중복 제거의 긍정적인 효과를 가져왔습니다. 언어의 발전기계어(0,1) -&gt; 어셈블리어(최소한의 알파벳으로 치환한 언어) -&gt; 구조적 언어-&gt; 객체지향적 언어 클래스12345678객체지향적 프로그래밍과 클래스가 연관되어 있다는 느낌이 오는가?그래도 클래스는 도저히 감이 안온다.위에서 클래스를 객체를 생성하기 위한 설계도라고 했었다.예를 들어 로봇을 만든다고 가정했을 때로봇의 팔, 몸통, 다리, 머리 가 있다고 한다면팔 클래스, 몸통 클래스, 다리 클래스, 머리 클래스를 나누어팔 클래스에서는 팔만 찍어내고 몸통 클래스에서는 몸통만 찍어내는기계라고 생각하면 쉽게 이해할 수 있을 것이다. 123456789101112131415161718192021# python에서 class 형태class 클래스명 (self, 인수1, 인수2...): self.인수1=인수1 ..... ..... def __init__: # init함수는 인스턴스 생성시 항상 실행되는 함수. xxxxxxx def 함수명 : xxxxxxxclass 클래스명(상속) : def xxx:# 함수 호출xxx = 클래스명(xxx)xxx.함수명(xxx)클래스명.함수명(xxx,xxxx,...) self를 사용하는 이유. self는 python만의 독특한 특징이다. 왜 괜히 헷갈리게 self를 사용하는 것일까? 진짜 이유는 python을 만든사람만 알겠지만 python에서 self를 사용할 수 밖에 없는 이유는 self를 써 줘야만 해당 함수를 인스턴스의 함수로 사용할 수 있기 때문이다. 그리고 self를 간단히 말하면 함수를 부르는 객체가 해당 클래스의 인스턴스인지 확인헤 주기 위한 장치입니다. 또한 self를 이용하면 객체 내의 정보를 저장하거나 불러올 수 있습니다. 12class 예시 함수제어문123- if- for- while 제어문은 코드로 알아보자. if 문123456pocket = &#123;'money':3000,'cellPhone':01090618472&#125;bag = &#123;'note':'notebook','laptop':'samsung'&#125;if 'money' not in pocket and bag: passelse: print(\"버스를 탄다\") for 문123456789# 순회할 리스트가 있는 경우scores= [90, 25, 67, 45, 80]number=0for score in scores: number+1 if score&lt;60: continue print(\"%d번 학생 축하합니다.\"%number) print(\"&#123;&#125;점으로 합격입니다.\".format(score)) 1234567891011# 순회 횟수가 정해져 있는 경우for i in range(11172): print(chr(44032+i), end=\"\")# 가 부터 힣까지 11172자 한글출력for i in range(2,10): for j in range(1,10): print(i*j, end=\" \") print(\"\")# 구구단 2~9단 출력 while 문123456789101112131415161718coffee = 10money = 0while coffee != 0: print(\"남은 커피량 &#123;&#125;개\".format(coffee)) if coffee==1: print(\"커피를 채워주세요.\") coffee=int(input(\"채울 커피량을 입력해주세요.\")) continue money = int(input(\"동전을 넣어주세요\\n\")) if (money == 300): print(\"커피가 나왔습니다.\") coffee -= 1 elif (money &gt; 300): print(\"거스름돈:&#123;&#125;, 커피나왔습니다.\".format(money-300)) coffee -= 1 else: print(\"&#123;&#125;원이 반환됩니다, 300원을 넣어주세요.\".format(money)) txt file read error =&gt; blogpython input vs raw_input =&gt; tistoryatom editor 단축키 모음 =&gt; tistorypython 문자열 관련 함수 =&gt; itbaby","categories":[{"name":"Language","slug":"Language","permalink":"http://jungjihyuk.github.io/categories/Language/"},{"name":"Python","slug":"Language/Python","permalink":"http://jungjihyuk.github.io/categories/Language/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jungjihyuk.github.io/tags/python/"},{"name":"한눈에 정리","slug":"한눈에-정리","permalink":"http://jungjihyuk.github.io/tags/%ED%95%9C%EB%88%88%EC%97%90-%EC%A0%95%EB%A6%AC/"}]},{"title":"백준 알고리즘 문제 풀이","slug":"baekjoon-algorithm","date":"2019-01-12T15:00:00.000Z","updated":"2020-02-24T15:10:25.630Z","comments":true,"path":"2019/01/13/baekjoon-algorithm/","link":"","permalink":"http://jungjihyuk.github.io/2019/01/13/baekjoon-algorithm/","excerpt":"알고리즘 풀이 with python","text":"2439번(정답)별찍기-2123456n = int(input())for x in range(1, n+1): for y in range(x, n): print(\" \", end=\"\") print(\"*\"*x) 2441번(정답)별찍기-41234567n = int(input())for x in range(1, n+1): for y in range(x, n+1): print(\"*\", end=\"\") print(\" \") print(\" \"*x, end=\"\") 7489번(오답)팩토리얼123456789101112131415161718192021for test in range(int(input())): num = int(input()) facto = 1 i = 0 j = 0 array = [] if num == 1: print(1) break for i in range(2, num+1): facto = facto * i result = str(facto) array = list(result) array.reverse() length = len(array) for j in range(0, length): if array[j] == '0': continue elif array[j] != '0': print(array[j]) break 테스트 갯수 입력후 숫자 n 입력하면 factorial 결과에서 0이 아닌 가장 마지막 숫자 출력.이를 테스트 갯수만큼 실행. (실행은 되지만 백준online에서 오답이라고 표시함)왜 틀렸을까..? 10828번(정답)스택1234567891011121314151617181920212223n = int(input())stack = []for x in range(n): order = input().split() if order[0] == 'push': stack.append(int(order[1])) elif order[0] == 'pop': if len(stack) == 0: print(-1) else: print(stack[-1]) stack.pop() elif order[0] == 'empty': if len(stack) == 0: print(1) else: print(0) elif order[0] == 'top': if len(stack) == 0: print(-1) else: print(stack[-1])","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://jungjihyuk.github.io/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://jungjihyuk.github.io/tags/algorithm/"},{"name":"백준","slug":"백준","permalink":"http://jungjihyuk.github.io/tags/%EB%B0%B1%EC%A4%80/"}]},{"title":"영문법 정리","slug":"grammer","date":"2018-11-03T15:00:00.000Z","updated":"2020-02-24T15:15:38.584Z","comments":true,"path":"2018/11/04/grammer/","link":"","permalink":"http://jungjihyuk.github.io/2018/11/04/grammer/","excerpt":"'나도 영문법 잘하고 싶다' 책 정리","text":"Samsung Note 프로그램으로 필기했던 내용들을 사진으로 업로드 하였습니다.사진으로 첨부했기 때문에 폰트 크기가 작아 웹 브라우저 크기를 최대로 해서 보길 권장 드립니다. 목차1234567891011121314151617181. 의사소통을 위한 3가지 원칙- 원칙 3 가지- 그 외 의사소통에 도움되는 팁2. 명사- 명사의 종류- 한정사- 명사를 꾸며주는 품사들3. 동사- 동사의 위치- 일반동사 그리고 be 동사- 시제- 자동사와 타동사- 사역동사- 동사의 변산(to 부정사, 분사, 동명사)- 태- 조동사 그리고 가정문4. 전치사- 전치사가 갖고 있는 여러가지 이미지 위 그림에 대한 책 출처 영문법 공부에 도움이 될만한 사이트.Hakmalyoung tistory: https://hakmalyoung.tistory.com","categories":[{"name":"English","slug":"English","permalink":"http://jungjihyuk.github.io/categories/English/"}],"tags":[{"name":"영어","slug":"영어","permalink":"http://jungjihyuk.github.io/tags/%EC%98%81%EC%96%B4/"},{"name":"문법","slug":"문법","permalink":"http://jungjihyuk.github.io/tags/%EB%AC%B8%EB%B2%95/"},{"name":"한눈에 보기","slug":"한눈에-보기","permalink":"http://jungjihyuk.github.io/tags/%ED%95%9C%EB%88%88%EC%97%90-%EB%B3%B4%EA%B8%B0/"}]},{"title":"Jsp & Servlet","slug":"jspandservlet","date":"2018-07-27T15:00:00.000Z","updated":"2020-02-24T15:42:37.664Z","comments":true,"path":"2018/07/28/jspandservlet/","link":"","permalink":"http://jungjihyuk.github.io/2018/07/28/jspandservlet/","excerpt":"JSP & Servlet 한눈에 보기. '최범균의 JSP 2.3 웹 프로그래밍'책 정리","text":"Jsp &amp; Servlet 책을 바탕으로 이해하기 쉽게 재구성 하였습니다. 목차 Jsp와 Servlet 이란? Jsp 구성 요소 디렉티브 스크립트 표현언어(EL) 내장객체 정적 데이터 액션태그 커스텀 태그와 표준 태그 라이브러리 Model 1 &amp; Model 2 내장객체 &amp; 메소드 요청과 응답 출력 pageContext application 쿠키 세션 EL(Expression Language) JSTL(Java Standard Tag Library) JDBC(Java Database Connectivity) Jsp와 ServletJsp1234Jsp(Java Server Page)는 자바로 서버 페이지를 작성하기 위한 언어 및 파일.동적 데이터를 처리할 수 있는 HTML + Java 페이지 또는 언어라고 볼 수도 있다.Jsp는 웹 어플리케이션의 관점에서 봤을 때 View의 역할을 한다.물론! JSP도 Controller 역할을 할 수 있다. Servlet1234Servlet(Server + Applet)은 Applet의 단점을 극복하여 만들어진 java기반 서버 프로그램.Servlet을 사용하면 클라이언트가 웹 브라우저를 통해 요청을 하면 서버에서 실행한 후 결과값만 전송합니다.쉽게말해 동적 데이터 처리를 담당하여 결과값만 전송해주는 역할을 한다.Servlet은 웹 어플리케이션의 관점에서 봤을 때 Controller의 역할을 한다. 잠깐!! JSP도 controller 역할을 할 수 있는데 굳이 Servlet을 이용해서 MVC 패턴을 구성하는가? (MVC 패턴이 익숙하지 않다면 model1 &amp; model2 파트를 읽어보세요!){: .notice} 12345678910111213좋은 프로그래밍이란 무엇일까?먼저 객체 지향 프로그래밍에 있어서 코드의 재사용성, 가독성, 효율성은 굉장히 중요한 문제이다.정상적으로 프로그램이 동작하더라도 코드를 실행이 되는것에만집중하여 만든다면 나중에 분명 후회하게 될것이다.만약 누군가와 같이 협업을 하거나 비슷한 로직을 다시 구현해야 할 때가 오면코드가 복잡해서 유지보수 하기 힘들거나 개발 시간이 늘어나기 마련이다.그래서!!가독성, 재사용성, 효율성을 극대화 하기 위해서는 프로세스 단위를 적절하게 분리해 두는 것이 중요하다.따라서 대부분의 로직들을 Servlet으로 만들고 보여지는 부분을 JSP로 구현하면 코드의 가독성도 높아지고재사용성, 효율성이 높아진다.결과적으로 Servlet과 JSP의 분리로 프론트 엔드 개발자, 디자이너와 백엔드 개발자 작업환경이 쾌적해지는 것은 덤이다. JSP 구성 요소 디렉티브 page : jsp 페이지에 대한 정보를 지정한다. (문서 타입, 출력버퍼의 크기, 에러 페이지 등) taglib: jsp 페이지에서 사용할 태그 라이브러리 지정 (코어태그) include: jsp 페이지의 특정 영역에 다른 문서를 포함시킨다. 스크립트 스크립트 기반 태그들은 &lt;%로 시작해서 %&gt;로 끝나는 것이 특징입니다. 주석문(comment) jsp 주석문 &lt;%- -%&gt; html 주석문 &lt;!- -&gt; 지시자(directive) page: jsp 페이지에 종속적인 설정 정보를 알려준다. contentType: 웹 브라우저에 전송되는 문서의 타입과 문자코드를 지정한다. import: 내장 패키지를 사용할 때 해당 패키지를 사용할 수 있게 불러온다. errorPage, is ErrorPage: jsp 페이지에서 오류가 발생했을 때 오류를 처리하기 위한 속성. pageEncoding: jsp 소스 저장시 사용할 문자코드를 지정한다. session: 해당 jsp 페이지의 세션 관리 처리 여부를 지정할 때 사용된다. include: 다른 jsp 파일을 삽입한다. language: 페이지에서 사용되는 스크립트 언어를 지정한다. 스크립트릿(scriptlet) &lt;% %&gt; jsp 페이지 내에서 자바코드를 실행 하고 싶을 때 사용한다. 표현식(expression) &lt;%= %&gt; 동적 데이터를 응답 결과에 포함 시키기 위해 사용한다. 선언문(declaration) &lt;%! %&gt; jsp 페이지 내에서 사용할 멤버 변수를 선언하고 메소드를 정의하고자 할 때 사용된다. Model 1 &amp; Model 2JSP로 구성된 웹 어플리케이션을 개발하다 보면 빠질 수 없는 개념이 있다. 바로 Model 1, Model 2 그리고 MVC 패턴. Model1, 2은 웹 어플리케이션의 아키텍쳐이다. 브라우저와 서버, 그리고 데이터베이스 간의 소통을 어떤 패턴으로 하는지에 대한 정형화된 방식이라고 생각하면 된다.이해가 가지 않는다면 Model1과 2는 각각의 프로그래밍하는 방식이라고만 생각해도 된다.MVC 패턴은 Model, View, Controller의 약자로 Model 1과 2방식에서 사용되는 패턴이다.브라우저에서 url로 특정 어플리케이션을 요청하면 Controller가 어떤 행위인지 판단하고, 처리를 담당하는데 처리에 필요한 데이터를 Model에서 꺼내와 다시 Controller가 처리를 마치면 View를 통해 결과를 보여준다. 그렇다면 MVC패턴이 적용된 Model 1과 2는 정확히 무엇일까? Model 1 Model 2 위 그림을 보면 Model 1방식은 JSP가 View와 Controller의 역할을 하고 JavaBean이 Model역할을 한다. 그리고 Model 2방식은 Servlet이 Controller역할을, JSP가 View 역할을 하고 JavaBean이 Model역할을 한다.여기서 Database를 공부해 본사람이라면 의문이 들수 있다. Model에서 데이터를 갖고 온다면 Database가 Model인거 아닐까? 라고 생각할 수 있다. 그런데 Database에서 매번 데이터를 직접 꺼내오게되면 문제가 생긴다. 보안상의 문제가 될수 있고, 처리 속도측면에서 저하될 가능성이 있다. (확인되지 않은 추측이므로 이부분은 그냥 넘어가도 좋다. 확실히 하고 싶다면 추가적으로 공부하도록 하자!) 따라서 Model은 Database에서 필요한 데이터만 미리 저장해두고 이용하는 부분이라고 생각하면 된다. 내장객체 &amp; 메소드EL(Expression Language)JSTL(Java Standard Tag Library)JDBC(Java Database Connectivity) SAMSUNG NOTE에 필기했던 내용","categories":[{"name":"JSP & Servlet","slug":"JSP-Servlet","permalink":"http://jungjihyuk.github.io/categories/JSP-Servlet/"}],"tags":[{"name":"한눈에 보기","slug":"한눈에-보기","permalink":"http://jungjihyuk.github.io/tags/%ED%95%9C%EB%88%88%EC%97%90-%EB%B3%B4%EA%B8%B0/"},{"name":"Jsp","slug":"Jsp","permalink":"http://jungjihyuk.github.io/tags/Jsp/"},{"name":"Servlet","slug":"Servlet","permalink":"http://jungjihyuk.github.io/tags/Servlet/"}]}]}